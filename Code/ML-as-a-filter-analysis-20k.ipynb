{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import itertools\n",
    "from collections import Counter, OrderedDict\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/nfs/gns/literature/machine-learning/evaluation/20karticles/europePMC-NER/annotations_API/full_sentences/tagged_sentences/Europe_PMC_annotation.csv'\n",
    "annot_csv = pd.read_csv(file_path, names=['pmc_id', 'section', 'sentence', 'ner'],sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "import requests\n",
    "# from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "from requests.compat import urljoin\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-23 13:33:20,626 loading file /nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/manual_annotated_dataset/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "flair_models = '/nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/manual_annotated_dataset/'\n",
    "# load the model you trained\n",
    "model = SequenceTagger.load(flair_models+'best-model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for multi processing\n",
    "# import numpy as np\n",
    "# count = 0\n",
    "# for g, df in annot_csv.groupby(np.arange(len(annot_csv)) // 16):\n",
    "#     count = count+1\n",
    "#     list_sent = []\n",
    "#     print(df.shape)\n",
    "#     for index_, each_annotation in enumerate(df.itertuples(), 0):\n",
    "#         print(index_,each_annotation.sentence)\n",
    "#     if count ==1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pmc_id', 'section', 'sentence', 'ner'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1893974/1893974 [00:40<00:00, 46202.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "result_path = '/nfs/gns/literature/machine-learning/evaluation/20K-ML-NER/'\n",
    "result_file_name = '20K-GP-Data.csv'\n",
    "\n",
    "with open(result_path + result_file_name, 'a', newline='\\n') as f1:\n",
    "    public_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "    \n",
    "    for index_, each_annotation in tqdm(enumerate(annot_csv.itertuples()),total=len(annot_csv)):\n",
    "#         if index_ <10:\n",
    "        annot = []\n",
    "        pmc_id = each_annotation.pmc_id\n",
    "        section = each_annotation.section\n",
    "        epmc_sentence = each_annotation.sentence\n",
    "\n",
    "        for each_epmc_ner in literal_eval(each_annotation.ner):\n",
    "            if each_epmc_ner[2] == 'Gene_Proteins':\n",
    "                annot.append(each_epmc_ner[1])\n",
    "\n",
    "        if annot:\n",
    "            new_row = [pmc_id, section, epmc_sentence, annot]\n",
    "            public_writer.writerows([new_row])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, WordPunctTokenizer\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenizer based on word and punctuations only.\n",
    "    \"\"\"\n",
    "    tokens: List[Token] = []\n",
    "\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "\n",
    "    text = tokenizer.tokenize(text)\n",
    "\n",
    "    index = 0\n",
    "    for index, word in enumerate(text):\n",
    "        tokens.append(\n",
    "            Token(\n",
    "                text=word, start_position=index, whitespace_after=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_annot_csv = pd.read_csv(result_path + result_file_name, names=['pmc_id', 'section', 'sentence', 'ner'],sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_annot_csv_ = GP_annot_csv.head(32)\n",
    "# GP_annot_csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# count = 0\n",
    "# for g, df in annot_csv.groupby(np.arange(len(annot_csv)) // 16):\n",
    "#     count = count+1\n",
    "#     list_sent = []\n",
    "#     print(df.shape)\n",
    "#     for index_, each_annotation in enumerate(df.itertuples(), 0):\n",
    "#         print(index_,each_annotation.sentence)\n",
    "#     if count ==1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65314/65314 [8:52:12<00:00,  2.05it/s]   \n"
     ]
    }
   ],
   "source": [
    "result_path = '/nfs/gns/literature/machine-learning/evaluation/20K-ML-NER/'\n",
    "result_file_name = '20K-GP_PCSE-Annotations.csv'\n",
    "\n",
    "GP_data_annot = result_path + result_file_name\n",
    "\n",
    "with open(GP_data_annot, 'w', newline='\\n') as f1:\n",
    "    public_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "\n",
    "    for g, anno_df in tqdm(GP_annot_csv.groupby(np.arange(len(GP_annot_csv)) // 16)):\n",
    "        \n",
    "        epmc_sentence = []\n",
    "        pmc_id = []\n",
    "        section = []\n",
    "        epmc_ner = []\n",
    "        sentences = []\n",
    "        \n",
    "#         for index_, each_annotation in tqdm(enumerate(anno_df.itertuples()),total=len(anno_df)):\n",
    "        for each_annotation in anno_df.itertuples():\n",
    "            pmc_id.append(each_annotation.pmc_id)\n",
    "            section.append(each_annotation.section)\n",
    "            epmc_sentence.append(each_annotation.sentence)\n",
    "            epmc_ner.append(each_annotation.ner)\n",
    "            sentences.append(Sentence(each_annotation.sentence, use_tokenizer=custom_tokenizer)) \n",
    "\n",
    "        predicted_sentences = model.predict(sentences, mini_batch_size=16)\n",
    "\n",
    "\n",
    "        for i in range(0,len(epmc_sentence)):\n",
    "            entities = predicted_sentences[i].to_dict(tag_type='ner')['entities']\n",
    "            all_entities = []    \n",
    "            if entities:\n",
    "                tagged_sents = predicted_sentences[i].to_dict(tag_type='ner')\n",
    "                for root_node in tagged_sents['entities']:\n",
    "                    exact = root_node['text']\n",
    "                    entity = root_node['type']\n",
    "\n",
    "                    if entity == 'GP':    \n",
    "                        all_entities.append(exact)              \n",
    "\n",
    "            predicted_ner = [pmc_id[i], section[i], epmc_sentence[i], epmc_ner[i], all_entities]\n",
    "            public_writer.writerow(predicted_ner)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "file_20k_path = '/nfs/gns/literature/machine-learning/evaluation/20K-ML-NER/'\n",
    "file_20k_name = file_20k_path+'20K-GP_PCSE-Annotations.csv'\n",
    "\n",
    "\n",
    "file_20k_df = pd.read_csv(file_20k_name, names=['pmc_id', 'section', 'sentence', 'epmc_ner','ml_ner'],sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1045024/1045024 [00:15<00:00, 67609.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate entries of the GP from the CSV\n",
    "updated_epmc_ner_non_duplicates = []\n",
    "\n",
    "for index_, each_annotation in tqdm(enumerate(file_20k_df.itertuples()),total=len(file_20k_df)):\n",
    "    epmc_ner = literal_eval(each_annotation.epmc_ner)\n",
    "    epmc_sentence = each_annotation.sentence\n",
    "    new_epmc_ner = []\n",
    "    for each_epmc_ner in set(epmc_ner):\n",
    "        if epmc_ner.count(each_epmc_ner) > 1:\n",
    "            count = epmc_sentence.count(each_epmc_ner)\n",
    "            new_epmc_ner.extend([each_epmc_ner]*count)\n",
    "        else:\n",
    "            new_epmc_ner.append(each_epmc_ner)\n",
    "#         print(new_epmc_ner)\n",
    "    updated_epmc_ner_non_duplicates.append(new_epmc_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>epmc_ner</th>\n",
       "      <th>ml_ner</th>\n",
       "      <th>eurpmc_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PMC4782685</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Among the 35 biobanks (76.1%) that grant condi...</td>\n",
       "      <td>['C3.1']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[C3.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PMC4782685</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>This result complies with the recommendation t...</td>\n",
       "      <td>['ECD']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ECD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>UNK</td>\n",
       "      <td>In order to ensure the adhesion of the enzyme ...</td>\n",
       "      <td>['serum albumin']</td>\n",
       "      <td>['albumin', 'GluOx']</td>\n",
       "      <td>[serum albumin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>UNK</td>\n",
       "      <td>NeuroManager interacts with cluster submission...</td>\n",
       "      <td>['SSH2']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SSH2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>UNK</td>\n",
       "      <td>NeuroManager allows the user to monitor simula...</td>\n",
       "      <td>['SMS']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SMS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>UNK</td>\n",
       "      <td>All remotes have to have SSH2.A compatible Jav...</td>\n",
       "      <td>['SSH2', 'MCR']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MCR, SSH2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>FIG</td>\n",
       "      <td>This class has a corresponding SimType of SIM_...</td>\n",
       "      <td>['SIM']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SIM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>FIG</td>\n",
       "      <td>Use the SimMachines defined in A and specify t...</td>\n",
       "      <td>['SIM']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SIM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>One important effort is around the development...</td>\n",
       "      <td>['SED']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SED]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>Although SED-ML deals with the use of “simulat...</td>\n",
       "      <td>['SED', 'SED']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SED, SED]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>For example, for the human-chimp-gorilla-orang...</td>\n",
       "      <td>['chimp', 'chimp']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chimp, chimp, chimp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>Although there is considerable uncertainty in ...</td>\n",
       "      <td>['chimp']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chimp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>As an illustration, in one human-chimp-gorilla...</td>\n",
       "      <td>['chimp']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chimp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>That this many loci would not have any phyloge...</td>\n",
       "      <td>['chimp']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chimp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>AUTH_CONT</td>\n",
       "      <td>JHD and NAR developed the AGT and anomaly zone...</td>\n",
       "      <td>['NAR', 'NAR']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[NAR, NAR]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmc_id    section                                           sentence  \\\n",
       "0   PMC4782685    RESULTS  Among the 35 biobanks (76.1%) that grant condi...   \n",
       "1   PMC4782685    DISCUSS  This result complies with the recommendation t...   \n",
       "2   PMC4610596        UNK  In order to ensure the adhesion of the enzyme ...   \n",
       "3   PMC4602303        UNK  NeuroManager interacts with cluster submission...   \n",
       "4   PMC4602303        UNK  NeuroManager allows the user to monitor simula...   \n",
       "5   PMC4602303        UNK  All remotes have to have SSH2.A compatible Jav...   \n",
       "6   PMC4602303        FIG  This class has a corresponding SimType of SIM_...   \n",
       "7   PMC4602303        FIG  Use the SimMachines defined in A and specify t...   \n",
       "8   PMC4602303    DISCUSS  One important effort is around the development...   \n",
       "9   PMC4602303    DISCUSS  Although SED-ML deals with the use of “simulat...   \n",
       "10  PMC1464820    DISCUSS  For example, for the human-chimp-gorilla-orang...   \n",
       "11  PMC1464820    DISCUSS  Although there is considerable uncertainty in ...   \n",
       "12  PMC1464820    DISCUSS  As an illustration, in one human-chimp-gorilla...   \n",
       "13  PMC1464820    DISCUSS  That this many loci would not have any phyloge...   \n",
       "14  PMC1464820  AUTH_CONT  JHD and NAR developed the AGT and anomaly zone...   \n",
       "\n",
       "              epmc_ner                ml_ner             eurpmc_ner  \n",
       "0             ['C3.1']                    []                 [C3.1]  \n",
       "1              ['ECD']                    []                  [ECD]  \n",
       "2    ['serum albumin']  ['albumin', 'GluOx']        [serum albumin]  \n",
       "3             ['SSH2']                    []                 [SSH2]  \n",
       "4              ['SMS']                    []                  [SMS]  \n",
       "5      ['SSH2', 'MCR']                    []            [MCR, SSH2]  \n",
       "6              ['SIM']                    []                  [SIM]  \n",
       "7              ['SIM']                    []                  [SIM]  \n",
       "8              ['SED']                    []                  [SED]  \n",
       "9       ['SED', 'SED']                    []             [SED, SED]  \n",
       "10  ['chimp', 'chimp']                    []  [chimp, chimp, chimp]  \n",
       "11           ['chimp']                    []                [chimp]  \n",
       "12           ['chimp']                    []                [chimp]  \n",
       "13           ['chimp']                    []                [chimp]  \n",
       "14      ['NAR', 'NAR']                    []             [NAR, NAR]  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_20k_df['eurpmc_ner'] =  updated_epmc_ner_non_duplicates\n",
    "file_20k_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1045024/1045024 [00:12<00:00, 84903.31it/s]\n"
     ]
    }
   ],
   "source": [
    "k_exacts = []\n",
    "k_preds = []\n",
    "k_missing = []\n",
    "\n",
    "\n",
    "for index_, each_annotation in tqdm(enumerate(file_20k_df.itertuples()),total=len(file_20k_df)):\n",
    "#     if index_ <10:\n",
    "    #     pmc_id = each_annotation.pmc_id\n",
    "    #     section = each_annotation.section\n",
    "    #     epmc_sentence = each_annotation.sentence\n",
    "#         k_exacts.append(literal_eval(each_annotation.eurpmc_ner))\n",
    "        k_exacts.append(each_annotation.eurpmc_ner)\n",
    "        k_preds.append(literal_eval(each_annotation.ml_ner))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_intersection(lst1, lst2): \n",
    "    miss = []\n",
    "    temp = set(lst2) \n",
    "    for value in lst1:\n",
    "        scores = [fuzz.partial_ratio(value,sublist) for sublist in temp]\n",
    "        if 100 not in scores:\n",
    "#         if any(i < 70for i in scores):\n",
    "            miss.append(value)  \n",
    "    return miss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1045024/1045024 [00:40<00:00, 25594.11it/s]\n"
     ]
    }
   ],
   "source": [
    "k_missing = []\n",
    "for i,j in tqdm(zip(k_exacts,k_preds), total = len(k_exacts)):\n",
    "    if i:\n",
    "        missing = no_intersection(i, j)\n",
    "        if missing:\n",
    "            k_missing.append(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = list(itertools.chain.from_iterable(k_missing))\n",
    "count = Counter(missing_data)\n",
    "y = OrderedDict(count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/nfs/gns/literature/machine-learning/Santosh/FP_analysis/20K/'\n",
    "with open(path+'k_exacts', 'wb') as fp:\n",
    "    pickle.dump(k_exacts, fp)\n",
    "    \n",
    "with open(path+'k_preds', 'wb') as fp:\n",
    "    pickle.dump(k_preds, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_data = list(itertools.chain.from_iterable(k_exacts))\n",
    "anno_count = Counter(anno_data)\n",
    "anno_y = OrderedDict(anno_count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(path+\"anno_non_dup_frequencies_GP_20K.csv\", \"w\",  newline='\\n') as outfile:\n",
    "    public_writer = csv.writer(outfile, delimiter='\\t', lineterminator='\\n')\n",
    "    for keys, values in y.items(): # Get keys from the missing\n",
    "        filt_per = (values/anno_y[keys])*100\n",
    "        new_row = [keys, str(values), str(anno_y[keys]), str(filt_per)]\n",
    "        public_writer.writerows([new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_20k_df['eurpmc_ner'] = file_20k_df.eurpmc_ner.apply(lambda x: literal_eval(str(x)))\n",
    "file_20k_df['ml_ner'] = file_20k_df.ml_ner.apply(lambda x: literal_eval(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>eurpmc_ner</th>\n",
       "      <th>ml_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PMC4782685</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Among the 35 biobanks (76.1%) that grant condi...</td>\n",
       "      <td>[C3.1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PMC4782685</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>This result complies with the recommendation t...</td>\n",
       "      <td>[ECD]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>UNK</td>\n",
       "      <td>In order to ensure the adhesion of the enzyme ...</td>\n",
       "      <td>[serum albumin]</td>\n",
       "      <td>[albumin, GluOx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>UNK</td>\n",
       "      <td>NeuroManager interacts with cluster submission...</td>\n",
       "      <td>[SSH2]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>UNK</td>\n",
       "      <td>NeuroManager allows the user to monitor simula...</td>\n",
       "      <td>[SMS]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>UNK</td>\n",
       "      <td>All remotes have to have SSH2.A compatible Jav...</td>\n",
       "      <td>[MCR, SSH2]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>FIG</td>\n",
       "      <td>This class has a corresponding SimType of SIM_...</td>\n",
       "      <td>[SIM]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>FIG</td>\n",
       "      <td>Use the SimMachines defined in A and specify t...</td>\n",
       "      <td>[SIM]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>One important effort is around the development...</td>\n",
       "      <td>[SED]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PMC4602303</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>Although SED-ML deals with the use of “simulat...</td>\n",
       "      <td>[SED, SED]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>For example, for the human-chimp-gorilla-orang...</td>\n",
       "      <td>[chimp, chimp, chimp]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>Although there is considerable uncertainty in ...</td>\n",
       "      <td>[chimp]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>As an illustration, in one human-chimp-gorilla...</td>\n",
       "      <td>[chimp]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>That this many loci would not have any phyloge...</td>\n",
       "      <td>[chimp]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PMC1464820</td>\n",
       "      <td>AUTH_CONT</td>\n",
       "      <td>JHD and NAR developed the AGT and anomaly zone...</td>\n",
       "      <td>[NAR, NAR]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmc_id    section                                           sentence  \\\n",
       "0   PMC4782685    RESULTS  Among the 35 biobanks (76.1%) that grant condi...   \n",
       "1   PMC4782685    DISCUSS  This result complies with the recommendation t...   \n",
       "2   PMC4610596        UNK  In order to ensure the adhesion of the enzyme ...   \n",
       "3   PMC4602303        UNK  NeuroManager interacts with cluster submission...   \n",
       "4   PMC4602303        UNK  NeuroManager allows the user to monitor simula...   \n",
       "5   PMC4602303        UNK  All remotes have to have SSH2.A compatible Jav...   \n",
       "6   PMC4602303        FIG  This class has a corresponding SimType of SIM_...   \n",
       "7   PMC4602303        FIG  Use the SimMachines defined in A and specify t...   \n",
       "8   PMC4602303    DISCUSS  One important effort is around the development...   \n",
       "9   PMC4602303    DISCUSS  Although SED-ML deals with the use of “simulat...   \n",
       "10  PMC1464820    DISCUSS  For example, for the human-chimp-gorilla-orang...   \n",
       "11  PMC1464820    DISCUSS  Although there is considerable uncertainty in ...   \n",
       "12  PMC1464820    DISCUSS  As an illustration, in one human-chimp-gorilla...   \n",
       "13  PMC1464820    DISCUSS  That this many loci would not have any phyloge...   \n",
       "14  PMC1464820  AUTH_CONT  JHD and NAR developed the AGT and anomaly zone...   \n",
       "\n",
       "               eurpmc_ner            ml_ner  \n",
       "0                  [C3.1]                []  \n",
       "1                   [ECD]                []  \n",
       "2         [serum albumin]  [albumin, GluOx]  \n",
       "3                  [SSH2]                []  \n",
       "4                   [SMS]                []  \n",
       "5             [MCR, SSH2]                []  \n",
       "6                   [SIM]                []  \n",
       "7                   [SIM]                []  \n",
       "8                   [SED]                []  \n",
       "9              [SED, SED]                []  \n",
       "10  [chimp, chimp, chimp]                []  \n",
       "11                [chimp]                []  \n",
       "12                [chimp]                []  \n",
       "13                [chimp]                []  \n",
       "14             [NAR, NAR]                []  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_cloumns = ['pmc_id', 'section', 'sentence', 'eurpmc_ner','ml_ner']\n",
    "file_20k_df[interested_cloumns].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFilePath = 'file_20k_df_non_dup.json'\n",
    "file_20k_df[interested_cloumns].to_json(path+jsonFilePath, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_path = '/nfs/gns/literature/machine-learning/Santosh/FP_analysis/20K/'+'anno_non_dup_frequencies_GP_20K.csv'\n",
    "columns_freq = ['Entity', 'Freq_of_ML_removed','EPMC_total_Freq','Percentage_removed']\n",
    "anno_freq_df = pd.read_csv(complete_path, sep = '\\t', error_bad_lines=False, names = columns_freq)\n",
    "\n",
    "jsonFilePath = 'EPMC_GP_freqs.json'\n",
    "anno_freq_df.to_json(path+jsonFilePath, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/gns/literature/machine-learning/Santosh/FP_analysis/20K/'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
