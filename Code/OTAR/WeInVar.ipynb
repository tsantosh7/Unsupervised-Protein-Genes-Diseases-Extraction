{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# file = '/home/stirunag/pre-trained_word_embeddings/glove/glove.6B.50d.txt'\n",
    "# glove2word2vec(glove_input_file=file, word2vec_output_file=\"gensim_glove.6B.50d.txt\")\n",
    "\n",
    "###Finally, read the word2vec txt to a gensim model using KeyedVectors:\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove.6B.50d.txt\", binary=False)\n",
    "\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"/home/synoptica/google_wv/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# euclidean distance between two vectors\n",
    "import math\n",
    "def l2_dist(v1, v2):\n",
    "    sum = 0.0\n",
    "    if len(v1) == len(v2):\n",
    "        for i in range(len(v1)):\n",
    "            delta = v1[i] - v2[i]\n",
    "            sum += delta * delta\n",
    "        return math.sqrt(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synoptica/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "index2word_set = set(glove_model.wv.index2word)\n",
    "\n",
    "def avg_feature_vector(sentence, model, num_features, index2word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Sensor_fusion\n",
    "# https://en.wikipedia.org/wiki/Inverse-variance_weighting\n",
    "\n",
    "def WeInVar_feature_vector(sentence, model, num_features, index2word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    var_combined = 0.0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, np.divide(model[word], np.var(model[word])))\n",
    "            var_combined = var_combined + np.divide(1, np.var(model[word]))\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, var_combined+n_words)\n",
    "    return feature_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_similarities(sentence_1, sentence_2):\n",
    "    s1_afv = avg_feature_vector(sentence_1, model=glove_model,   num_features=300, index2word_set=index2word_set)\n",
    "    s2_afv = avg_feature_vector(sentence_2, model=glove_model,num_features=300, index2word_set=index2word_set)\n",
    "    \n",
    "    print('consine: ' + str(1 - spatial.distance.cosine(s1_afv, s2_afv)))\n",
    "    print('Euclidean: '+ str(1-l2_dist(s1_afv, s2_afv)))\n",
    "    \n",
    "    print('\\n*** Proposed ****\\n')\n",
    "    \n",
    "    s1_cfv = WeInVar_feature_vector(sentence_1, model=glove_model,num_features=300, index2word_set=index2word_set)\n",
    "    s2_cfv = WeInVar_feature_vector(sentence_2, model=glove_model,num_features=300, index2word_set=index2word_set)\n",
    "    \n",
    "    print('consine: ' + str(1 - spatial.distance.cosine(s1_cfv, s2_cfv)))\n",
    "    print('Euclidean: '+ str(1-l2_dist(s1_cfv, s2_cfv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consine: 0.6539125177578349\n",
      "Euclidean: 0.056384929834607966\n",
      "\n",
      "*** Proposed ****\n",
      "\n",
      "consine: 0.9236403283615906\n",
      "Euclidean: 0.6276778890216066\n"
     ]
    }
   ],
   "source": [
    "# Test case 1\n",
    "# The two sentences are completely equivalent, as they mean the same thing.  \n",
    "\n",
    "sentence_1 = 'The bird is bathing in the sink.'\n",
    "sentence_2 = 'Birdie is washing itself in the water basin.'\n",
    "\n",
    "print_similarities(sentence_1, sentence_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consine: 0.6682252848367785\n",
      "Euclidean: -0.03880286941085709\n",
      "\n",
      "*** Proposed ****\n",
      "\n",
      "consine: 0.735840847325616\n",
      "Euclidean: 0.25239685010484103\n"
     ]
    }
   ],
   "source": [
    "# Test case 2\n",
    "# The two sentences are mostly equivalent, but some unimportant details differ.\n",
    "\n",
    "sentence_1 = 'In May 2010, the troops attempted to invade Kabul.'\n",
    "sentence_2 = 'The US army invaded Kabul on May 7th last year, 2010.'\n",
    "\n",
    "print_similarities(sentence_1, sentence_2)\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consine: 0.7894748904362346\n",
      "Euclidean: 0.27037969500919634\n",
      "\n",
      "*** Proposed ****\n",
      "\n",
      "consine: 0.8878459569072047\n",
      "Euclidean: 0.48346821967648423\n"
     ]
    }
   ],
   "source": [
    "# Test 3\n",
    "# The two sentences are roughly equivalent, but some important information differs/missing.\n",
    "\n",
    "sentence_1 = 'John said he is considered a witness but not a suspect.'\n",
    "sentence_2 = 'He is not a suspect anymore.\" John said.'\n",
    "\n",
    "print_similarities(sentence_1, sentence_2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consine: 0.9539640381008274\n",
      "Euclidean: 0.5670408861243774\n",
      "\n",
      "*** Proposed ****\n",
      "\n",
      "consine: 0.9219473037366839\n",
      "Euclidean: 0.59916840555105\n"
     ]
    }
   ],
   "source": [
    "# Test 4\n",
    "# The two sentences are not equivalent, but share some details.\n",
    "\n",
    "sentence_1 = 'They flew out of the nest in groups.'\n",
    "sentence_2 = 'They flew into the nest together.'\n",
    "\n",
    "print_similarities(sentence_1, sentence_2)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consine: 0.6929881319764487\n",
      "Euclidean: 0.05788454002226906\n",
      "\n",
      "*** Proposed ****\n",
      "\n",
      "consine: 0.8759480898375229\n",
      "Euclidean: 0.508549488160922\n"
     ]
    }
   ],
   "source": [
    "# Test 5\n",
    "# The two sentences are not equivalent, but are on the same topic.\n",
    "    \n",
    "sentence_1 = 'The woman is playing the violin.'\n",
    "sentence_2 = 'The young lady enjoys listening to the guitar.'\n",
    "\n",
    "print_similarities(sentence_1, sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consine: 0.653876231695043\n",
      "Euclidean: 0.19453509021267557\n",
      "\n",
      "*** Proposed ****\n",
      "\n",
      "consine: 0.7143262707738096\n",
      "Euclidean: 0.320769877087943\n"
     ]
    }
   ],
   "source": [
    "# Test 6\n",
    "# The two sentences are on different topics.\n",
    "\n",
    "sentence_1 = 'John went horse back riding at dawn with a whole group of friends.'\n",
    "sentence_2 = 'Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.'\n",
    "\n",
    "print_similarities(sentence_1, sentence_2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
