{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import itertools\n",
    "from collections import Counter, OrderedDict\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/nfs/gns/literature/machine-learning/evaluation/20karticles/europePMC-NER/annotations_API/full_sentences/tagged_sentences/Europe_PMC_annotation.csv'\n",
    "annot_csv = pd.read_csv(file_path, names=['pmc_id', 'section', 'sentence', 'ner'],sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "import requests\n",
    "# from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "from requests.compat import urljoin\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-28 14:22:34,509 loading file /nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/manual_annotated_dataset/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "flair_models = '/nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/manual_annotated_dataset/'\n",
    "# load the model you trained\n",
    "model = SequenceTagger.load(flair_models+'best-model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for multi processing\n",
    "# import numpy as np\n",
    "# count = 0\n",
    "# for g, df in annot_csv.groupby(np.arange(len(annot_csv)) // 16):\n",
    "#     count = count+1\n",
    "#     list_sent = []\n",
    "#     print(df.shape)\n",
    "#     for index_, each_annotation in enumerate(df.itertuples(), 0):\n",
    "#         print(index_,each_annotation.sentence)\n",
    "#     if count ==1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pmc_id', 'section', 'sentence', 'ner'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893974"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1893974/1893974 [00:44<00:00, 42255.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "result_path = '/nfs/gns/literature/machine-learning/evaluation/20K-ML-NER/'\n",
    "result_file_name = '20K-DS-Data.csv'\n",
    "\n",
    "with open(result_path + result_file_name, 'a', newline='\\n') as f1:\n",
    "    public_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "    \n",
    "    for index_, each_annotation in tqdm(enumerate(annot_csv.itertuples()),total=len(annot_csv)):\n",
    "#         if index_ <10:\n",
    "        annot = []\n",
    "        pmc_id = each_annotation.pmc_id\n",
    "        section = each_annotation.section\n",
    "        epmc_sentence = each_annotation.sentence\n",
    "\n",
    "        for each_epmc_ner in literal_eval(each_annotation.ner):\n",
    "            if each_epmc_ner[2] == 'Diseases':\n",
    "                annot.append(each_epmc_ner[1])\n",
    "\n",
    "        if annot:\n",
    "            new_row = [pmc_id, section, epmc_sentence, annot]\n",
    "            public_writer.writerows([new_row])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, WordPunctTokenizer\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenizer based on word and punctuations only.\n",
    "    \"\"\"\n",
    "    tokens: List[Token] = []\n",
    "\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "\n",
    "    text = tokenizer.tokenize(text)\n",
    "\n",
    "    index = 0\n",
    "    for index, word in enumerate(text):\n",
    "        tokens.append(\n",
    "            Token(\n",
    "                text=word, start_position=index, whitespace_after=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_annot_csv = pd.read_csv(result_path + result_file_name, names=['pmc_id', 'section', 'sentence', 'ner'],sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_annot_csv_ = DS_annot_csv.head(32)\n",
    "# DS_annot_csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# count = 0\n",
    "# for g, df in annot_csv.groupby(np.arange(len(annot_csv)) // 16):\n",
    "#     count = count+1\n",
    "#     list_sent = []\n",
    "#     print(df.shape)\n",
    "#     for index_, each_annotation in enumerate(df.itertuples(), 0):\n",
    "#         print(index_,each_annotation.sentence)\n",
    "#     if count ==1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30763/30763 [6:53:34<00:00,  1.24it/s]   \n"
     ]
    }
   ],
   "source": [
    "result_path = '/nfs/gns/literature/machine-learning/evaluation/20K-ML-NER/'\n",
    "result_file_name = '20K-DS_PCSE-Annotations.csv'\n",
    "\n",
    "DS_data_annot = result_path + result_file_name\n",
    "\n",
    "with open(DS_data_annot, 'w', newline='\\n') as f1:\n",
    "    public_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "\n",
    "    for g, anno_df in tqdm(DS_annot_csv.groupby(np.arange(len(DS_annot_csv)) // 16)):\n",
    "        \n",
    "        epmc_sentence = []\n",
    "        pmc_id = []\n",
    "        section = []\n",
    "        epmc_ner = []\n",
    "        sentences = []\n",
    "        \n",
    "#         for index_, each_annotation in tqdm(enumerate(anno_df.itertuples()),total=len(anno_df)):\n",
    "        for each_annotation in anno_df.itertuples():\n",
    "            pmc_id.append(each_annotation.pmc_id)\n",
    "            section.append(each_annotation.section)\n",
    "            epmc_sentence.append(each_annotation.sentence)\n",
    "            epmc_ner.append(each_annotation.ner)\n",
    "            sentences.append(Sentence(each_annotation.sentence, use_tokenizer=custom_tokenizer)) \n",
    "\n",
    "        predicted_sentences = model.predict(sentences, mini_batch_size=32)\n",
    "\n",
    "\n",
    "        for i in range(0,len(epmc_sentence)):\n",
    "            entities = predicted_sentences[i].to_dict(tag_type='ner')['entities']\n",
    "            all_entities = []    \n",
    "            if entities:\n",
    "                tagged_sents = predicted_sentences[i].to_dict(tag_type='ner')\n",
    "                for root_node in tagged_sents['entities']:\n",
    "                    exact = root_node['text']\n",
    "                    entity = root_node['type']\n",
    "\n",
    "                    if entity == 'DS':    \n",
    "                        all_entities.append(exact)              \n",
    "\n",
    "            predicted_ner = [pmc_id[i], section[i], epmc_sentence[i], epmc_ner[i], all_entities]\n",
    "            public_writer.writerow(predicted_ner)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "file_20k_path = '/nfs/gns/literature/machine-learning/evaluation/20K-ML-NER/'\n",
    "file_20k_name = file_20k_path+'20K-DS_PCSE-Annotations.csv'\n",
    "\n",
    "\n",
    "file_20k_df = pd.read_csv(file_20k_name, names=['pmc_id', 'section', 'sentence', 'epmc_ner','ml_ner'],sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492195/492195 [00:12<00:00, 38073.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate entries of the GP from the CSV\n",
    "updated_epmc_ner_non_duplicates = []\n",
    "\n",
    "for index_, each_annotation in tqdm(enumerate(file_20k_df.itertuples()),total=len(file_20k_df)):\n",
    "    epmc_ner = literal_eval(each_annotation.epmc_ner)\n",
    "    epmc_sentence = each_annotation.sentence\n",
    "    new_epmc_ner = []\n",
    "    for each_epmc_ner in set(epmc_ner):\n",
    "        if epmc_ner.count(each_epmc_ner) > 1:\n",
    "            count = epmc_sentence.count(each_epmc_ner)\n",
    "            new_epmc_ner.extend([each_epmc_ner]*count)\n",
    "        else:\n",
    "            new_epmc_ner.append(each_epmc_ner)\n",
    "#         print(new_epmc_ner)\n",
    "    updated_epmc_ner_non_duplicates.append(new_epmc_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>epmc_ner</th>\n",
       "      <th>ml_ner</th>\n",
       "      <th>eurpmc_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PMC4782685</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>For instance, cancer registries or retrospecti...</td>\n",
       "      <td>['cancer']</td>\n",
       "      <td>['cancer']</td>\n",
       "      <td>[cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>INTRO</td>\n",
       "      <td>It has been implicated in fundamental function...</td>\n",
       "      <td>['neurological disorders']</td>\n",
       "      <td>['chronic neurological disorders']</td>\n",
       "      <td>[neurological disorders]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>INTRO</td>\n",
       "      <td>WPT has been extensively studied for implantab...</td>\n",
       "      <td>['gastro-esophageal reflux disease']</td>\n",
       "      <td>['gastro-esophageal reflux disease', 'GERD']</td>\n",
       "      <td>[gastro-esophageal reflux disease]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>UNK</td>\n",
       "      <td>The flexible polyimide substrate with a thickn...</td>\n",
       "      <td>['scars']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[scars]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PMC4726007</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>To further test the algorithm’s performance, w...</td>\n",
       "      <td>['bacteremia']</td>\n",
       "      <td>['bacteremia']</td>\n",
       "      <td>[bacteremia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PMC4726007</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>This enables our LAM technique to scale to the...</td>\n",
       "      <td>['polymicrobial infection']</td>\n",
       "      <td>['polymicrobial infection']</td>\n",
       "      <td>[polymicrobial infection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PMC5712973</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>In more detail, the radial distortion is mainl...</td>\n",
       "      <td>['defect']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[defect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PMC4083040</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>This idea was corroborated by our results and ...</td>\n",
       "      <td>['addiction']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[addiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PMC4083040</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>The case of tobacco addiction is a particular ...</td>\n",
       "      <td>['addiction']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[addiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PMC4083040</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>On the other hand, smokers can be against new ...</td>\n",
       "      <td>['addiction']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[addiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PMC4754747</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Importantly, inactivation of BBCK by oxidation...</td>\n",
       "      <td>['neurodegenerative disorders']</td>\n",
       "      <td>['neurodegenerative disorders', 'Alzheimer’s d...</td>\n",
       "      <td>[neurodegenerative disorders]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PMC5381373</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Such difficulties maybe attributed to the defe...</td>\n",
       "      <td>['defect']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[defect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PMC5381373</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>A possible consequence is that doping is count...</td>\n",
       "      <td>['defect']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[defect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PMC5381373</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Instead, introduction of defects may lead to t...</td>\n",
       "      <td>['defects']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[defects]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PMC5591214</td>\n",
       "      <td>INTRO</td>\n",
       "      <td>Additionally, sessile wart-like glands are sca...</td>\n",
       "      <td>['wart']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[wart]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmc_id  section                                           sentence  \\\n",
       "0   PMC4782685  DISCUSS  For instance, cancer registries or retrospecti...   \n",
       "1   PMC4610596    INTRO  It has been implicated in fundamental function...   \n",
       "2   PMC4610596    INTRO  WPT has been extensively studied for implantab...   \n",
       "3   PMC4610596      UNK  The flexible polyimide substrate with a thickn...   \n",
       "4   PMC4726007  RESULTS  To further test the algorithm’s performance, w...   \n",
       "5   PMC4726007  DISCUSS  This enables our LAM technique to scale to the...   \n",
       "6   PMC5712973  METHODS  In more detail, the radial distortion is mainl...   \n",
       "7   PMC4083040  DISCUSS  This idea was corroborated by our results and ...   \n",
       "8   PMC4083040  DISCUSS  The case of tobacco addiction is a particular ...   \n",
       "9   PMC4083040  DISCUSS  On the other hand, smokers can be against new ...   \n",
       "10  PMC4754747      UNK  Importantly, inactivation of BBCK by oxidation...   \n",
       "11  PMC5381373  RESULTS  Such difficulties maybe attributed to the defe...   \n",
       "12  PMC5381373  RESULTS  A possible consequence is that doping is count...   \n",
       "13  PMC5381373  RESULTS  Instead, introduction of defects may lead to t...   \n",
       "14  PMC5591214    INTRO  Additionally, sessile wart-like glands are sca...   \n",
       "\n",
       "                                epmc_ner  \\\n",
       "0                             ['cancer']   \n",
       "1             ['neurological disorders']   \n",
       "2   ['gastro-esophageal reflux disease']   \n",
       "3                              ['scars']   \n",
       "4                         ['bacteremia']   \n",
       "5            ['polymicrobial infection']   \n",
       "6                             ['defect']   \n",
       "7                          ['addiction']   \n",
       "8                          ['addiction']   \n",
       "9                          ['addiction']   \n",
       "10       ['neurodegenerative disorders']   \n",
       "11                            ['defect']   \n",
       "12                            ['defect']   \n",
       "13                           ['defects']   \n",
       "14                              ['wart']   \n",
       "\n",
       "                                               ml_ner  \\\n",
       "0                                          ['cancer']   \n",
       "1                  ['chronic neurological disorders']   \n",
       "2        ['gastro-esophageal reflux disease', 'GERD']   \n",
       "3                                                  []   \n",
       "4                                      ['bacteremia']   \n",
       "5                         ['polymicrobial infection']   \n",
       "6                                                  []   \n",
       "7                                                  []   \n",
       "8                                                  []   \n",
       "9                                                  []   \n",
       "10  ['neurodegenerative disorders', 'Alzheimer’s d...   \n",
       "11                                                 []   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14                                                 []   \n",
       "\n",
       "                            eurpmc_ner  \n",
       "0                             [cancer]  \n",
       "1             [neurological disorders]  \n",
       "2   [gastro-esophageal reflux disease]  \n",
       "3                              [scars]  \n",
       "4                         [bacteremia]  \n",
       "5            [polymicrobial infection]  \n",
       "6                             [defect]  \n",
       "7                          [addiction]  \n",
       "8                          [addiction]  \n",
       "9                          [addiction]  \n",
       "10       [neurodegenerative disorders]  \n",
       "11                            [defect]  \n",
       "12                            [defect]  \n",
       "13                           [defects]  \n",
       "14                              [wart]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_20k_df['eurpmc_ner'] =  updated_epmc_ner_non_duplicates\n",
    "file_20k_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492195/492195 [00:11<00:00, 43470.73it/s]\n"
     ]
    }
   ],
   "source": [
    "k_exacts = []\n",
    "k_preds = []\n",
    "k_missing = []\n",
    "\n",
    "\n",
    "for index_, each_annotation in tqdm(enumerate(file_20k_df.itertuples()),total=len(file_20k_df)):\n",
    "#     if index_ <10:\n",
    "    #     pmc_id = each_annotation.pmc_id\n",
    "    #     section = each_annotation.section\n",
    "    #     epmc_sentence = each_annotation.sentence\n",
    "#         k_exacts.append(literal_eval(each_annotation.eurpmc_ner))\n",
    "        k_exacts.append(each_annotation.eurpmc_ner)\n",
    "        k_preds.append(literal_eval(each_annotation.ml_ner))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_intersection(lst1, lst2): \n",
    "    miss = []\n",
    "    temp = set(lst2) \n",
    "    for value in lst1:\n",
    "        scores = [fuzz.partial_ratio(value,sublist) for sublist in temp]\n",
    "        if 100 not in scores:\n",
    "#         if any(i < 70for i in scores):\n",
    "            miss.append(value)  \n",
    "    return miss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492195/492195 [00:19<00:00, 25000.12it/s]\n"
     ]
    }
   ],
   "source": [
    "k_missing = []\n",
    "for i,j in tqdm(zip(k_exacts,k_preds), total = len(k_exacts)):\n",
    "    if i:\n",
    "        missing = no_intersection(i, j)\n",
    "        if missing:\n",
    "            k_missing.append(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = list(itertools.chain.from_iterable(k_missing))\n",
    "count = Counter(missing_data)\n",
    "y = OrderedDict(count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = '/nfs/gns/literature/machine-learning/Santosh/FP_analysis/20K/'\n",
    "with open(path+'DS_k_exacts', 'wb') as fp:\n",
    "    pickle.dump(k_exacts, fp)\n",
    "    \n",
    "with open(path+'DS_k_preds', 'wb') as fp:\n",
    "    pickle.dump(k_preds, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_data = list(itertools.chain.from_iterable(k_exacts))\n",
    "anno_count = Counter(anno_data)\n",
    "anno_y = OrderedDict(anno_count.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(path+\"anno_non_dup_frequencies_DS_20K.csv\", \"w\",  newline='\\n') as outfile:\n",
    "    public_writer = csv.writer(outfile, delimiter='\\t', lineterminator='\\n')\n",
    "    for keys, values in y.items(): # Get keys from the missing\n",
    "        filt_per = (values/anno_y[keys])*100\n",
    "        new_row = [keys, str(values), str(anno_y[keys]), str(filt_per)]\n",
    "        public_writer.writerows([new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_20k_df['eurpmc_ner'] = file_20k_df.eurpmc_ner.apply(lambda x: literal_eval(str(x)))\n",
    "file_20k_df['ml_ner'] = file_20k_df.ml_ner.apply(lambda x: literal_eval(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>section</th>\n",
       "      <th>sentence</th>\n",
       "      <th>eurpmc_ner</th>\n",
       "      <th>ml_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PMC4782685</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>For instance, cancer registries or retrospecti...</td>\n",
       "      <td>[cancer]</td>\n",
       "      <td>[cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>INTRO</td>\n",
       "      <td>It has been implicated in fundamental function...</td>\n",
       "      <td>[neurological disorders]</td>\n",
       "      <td>[chronic neurological disorders]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>INTRO</td>\n",
       "      <td>WPT has been extensively studied for implantab...</td>\n",
       "      <td>[gastro-esophageal reflux disease]</td>\n",
       "      <td>[gastro-esophageal reflux disease, GERD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PMC4610596</td>\n",
       "      <td>UNK</td>\n",
       "      <td>The flexible polyimide substrate with a thickn...</td>\n",
       "      <td>[scars]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PMC4726007</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>To further test the algorithm’s performance, w...</td>\n",
       "      <td>[bacteremia]</td>\n",
       "      <td>[bacteremia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PMC4726007</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>This enables our LAM technique to scale to the...</td>\n",
       "      <td>[polymicrobial infection]</td>\n",
       "      <td>[polymicrobial infection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PMC5712973</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>In more detail, the radial distortion is mainl...</td>\n",
       "      <td>[defect]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PMC4083040</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>This idea was corroborated by our results and ...</td>\n",
       "      <td>[addiction]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PMC4083040</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>The case of tobacco addiction is a particular ...</td>\n",
       "      <td>[addiction]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PMC4083040</td>\n",
       "      <td>DISCUSS</td>\n",
       "      <td>On the other hand, smokers can be against new ...</td>\n",
       "      <td>[addiction]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PMC4754747</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Importantly, inactivation of BBCK by oxidation...</td>\n",
       "      <td>[neurodegenerative disorders]</td>\n",
       "      <td>[neurodegenerative disorders, Alzheimer’s dise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PMC5381373</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Such difficulties maybe attributed to the defe...</td>\n",
       "      <td>[defect]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PMC5381373</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>A possible consequence is that doping is count...</td>\n",
       "      <td>[defect]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PMC5381373</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Instead, introduction of defects may lead to t...</td>\n",
       "      <td>[defects]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PMC5591214</td>\n",
       "      <td>INTRO</td>\n",
       "      <td>Additionally, sessile wart-like glands are sca...</td>\n",
       "      <td>[wart]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmc_id  section                                           sentence  \\\n",
       "0   PMC4782685  DISCUSS  For instance, cancer registries or retrospecti...   \n",
       "1   PMC4610596    INTRO  It has been implicated in fundamental function...   \n",
       "2   PMC4610596    INTRO  WPT has been extensively studied for implantab...   \n",
       "3   PMC4610596      UNK  The flexible polyimide substrate with a thickn...   \n",
       "4   PMC4726007  RESULTS  To further test the algorithm’s performance, w...   \n",
       "5   PMC4726007  DISCUSS  This enables our LAM technique to scale to the...   \n",
       "6   PMC5712973  METHODS  In more detail, the radial distortion is mainl...   \n",
       "7   PMC4083040  DISCUSS  This idea was corroborated by our results and ...   \n",
       "8   PMC4083040  DISCUSS  The case of tobacco addiction is a particular ...   \n",
       "9   PMC4083040  DISCUSS  On the other hand, smokers can be against new ...   \n",
       "10  PMC4754747      UNK  Importantly, inactivation of BBCK by oxidation...   \n",
       "11  PMC5381373  RESULTS  Such difficulties maybe attributed to the defe...   \n",
       "12  PMC5381373  RESULTS  A possible consequence is that doping is count...   \n",
       "13  PMC5381373  RESULTS  Instead, introduction of defects may lead to t...   \n",
       "14  PMC5591214    INTRO  Additionally, sessile wart-like glands are sca...   \n",
       "\n",
       "                            eurpmc_ner  \\\n",
       "0                             [cancer]   \n",
       "1             [neurological disorders]   \n",
       "2   [gastro-esophageal reflux disease]   \n",
       "3                              [scars]   \n",
       "4                         [bacteremia]   \n",
       "5            [polymicrobial infection]   \n",
       "6                             [defect]   \n",
       "7                          [addiction]   \n",
       "8                          [addiction]   \n",
       "9                          [addiction]   \n",
       "10       [neurodegenerative disorders]   \n",
       "11                            [defect]   \n",
       "12                            [defect]   \n",
       "13                           [defects]   \n",
       "14                              [wart]   \n",
       "\n",
       "                                               ml_ner  \n",
       "0                                            [cancer]  \n",
       "1                    [chronic neurological disorders]  \n",
       "2            [gastro-esophageal reflux disease, GERD]  \n",
       "3                                                  []  \n",
       "4                                        [bacteremia]  \n",
       "5                           [polymicrobial infection]  \n",
       "6                                                  []  \n",
       "7                                                  []  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "10  [neurodegenerative disorders, Alzheimer’s dise...  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                                                 []  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_cloumns = ['pmc_id', 'section', 'sentence', 'eurpmc_ner','ml_ner']\n",
    "file_20k_df[interested_cloumns].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFilePath = 'DS_file_20k_df_non_dup.json'\n",
    "file_20k_df[interested_cloumns].to_json(path+jsonFilePath, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '/nfs/gns/literature/machine-learning/Santosh/FP_analysis/20K/'\n",
    "complete_path = path+'anno_non_dup_frequencies_DS_20K.csv'\n",
    "columns_freq = ['Entity', 'Freq_of_ML_removed','EPMC_total_Freq','Percentage_removed']\n",
    "anno_freq_df = pd.read_csv(complete_path, sep = '\\t', error_bad_lines=False, names = columns_freq)\n",
    "\n",
    "jsonFilePath = 'EPMC_DS_freqs.json'\n",
    "anno_freq_df.to_json(path+jsonFilePath, orient='records')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
