{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from operator import itemgetter\n",
    "from itertools import cycle, islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sif_embedding_wrapper\n",
    "import utils\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# model = KeyedVectors.load_word2vec_format('/home/stirunag/pre-trained_word_embeddings/PubMed-and-PMC-w2v.bin', binary=True)\n",
    "# model.save_word2vec_format('/home/stirunag/pre-trained_word_embeddings/PubMed-and-PMC-w2v.txt', binary=False)\n",
    "\n",
    "# words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/PubMed-and-PMC-FS.txt\", \n",
    "#                                                      '/home/stirunag/pre-trained_word_embeddings/wiki/enwiki_vocab_min200.txt')\n",
    "\n",
    "words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/glove/glove.6B.300d.txt\", \n",
    "                                                      '/home/stirunag/pre-trained_word_embeddings/wiki/enwiki_vocab_min200.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04656  ,  0.21318  , -0.0074364, ...,  0.0090611, -0.20989  ,\n",
       "         0.053913 ],\n",
       "       [-0.25539  , -0.25723  ,  0.13169  , ..., -0.2329   , -0.12226  ,\n",
       "         0.35499  ],\n",
       "       [-0.12559  ,  0.01363  ,  0.10306  , ..., -0.34224  , -0.022394 ,\n",
       "         0.13684  ],\n",
       "       ...,\n",
       "       [ 0.075713 , -0.040502 ,  0.18345  , ...,  0.21838  ,  0.30967  ,\n",
       "         0.43761  ],\n",
       "       [ 0.81451  , -0.36221  ,  0.31186  , ...,  0.075486 ,  0.28408  ,\n",
       "        -0.17559  ],\n",
       "       [ 0.429191 , -0.296897 ,  0.15011  , ...,  0.28975  ,  0.32618  ,\n",
       "        -0.0590532]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "data_path = os.path.abspath(os.path.join(os.path.dirname( '__file__' ), '..', 'Datasets'))+'/'\n",
    "\n",
    "# Although the dataset says csv, it is tab delimited. In addition to this, they have severe codels problems. \n",
    "# So best to parse throught codes first. \n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfc in position 2: invalid start byte\n",
    "\n",
    "#open for reading with \"universal\" type set\n",
    "\n",
    "import codecs\n",
    "\n",
    "doc_d_t = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_target'+'.csv','rU','UTF-8') \n",
    "EUADR_drug_target = pd.read_csv(doc_d_t, sep='\\t', na_filter = False)\n",
    "EUADR_drug_target['CLASS'] = 'drug_gene'\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_target_disease'+'.csv','rU','UTF-8',errors='ignore') \n",
    "EUADR_target_disease = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "EUADR_target_disease['CLASS'] = 'gene_disease'\n",
    "       \n",
    "doc_d_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_disease'+'.csv','rU','UTF-8')                       \n",
    "EUADR_drug_disease = pd.read_csv(doc_d_d, sep='\\t', na_filter = False)\n",
    "EUADR_drug_disease['CLASS'] = 'drug_disease'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EUADR = {} \n",
    "temp = EUADR_drug_target.append(EUADR_target_disease)\n",
    "EUADR['data'] = temp['SENTENCE'].tolist()\n",
    "EUADR['target'] = temp['CLASS'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247  355\n"
     ]
    }
   ],
   "source": [
    "print(str(EUADR_drug_target.__len__()) + '  ' + str(EUADR_target_disease.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {}\n",
    "for i,text in enumerate(EUADR['data']):\n",
    "    doc_id = str(i+1)\n",
    "    docs[doc_id] = {\n",
    "        \"text\": text.strip().strip('\"'),\n",
    "        \"category_ind\": 1 if EUADR['target'][i] == 'gene_disease' else 0,\n",
    "        \"label\": EUADR['target'][i]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc_ids = sorted(list(docs.keys()))\n",
    "df = pd.DataFrame({\"text\": [docs[d][\"text\"] for d in all_doc_ids], \n",
    "                       \"category_ind\": [docs[d]['category_ind'] for d in all_doc_ids], \n",
    "                       \"doc_id\": [d for d in all_doc_ids],\n",
    "                       \"label\": [docs[d]['label'] for d in all_doc_ids]\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(df[\"label\"].unique())\n",
    "text_df = pd.DataFrame({\"doc_id\": df[\"doc_id\"], \"text\": df[\"text\"]})\n",
    "truth_df = pd.DataFrame({\"doc_id\": df[\"doc_id\"], \"gt\": df[\"label\"]})\n",
    "truth_dict = {str(rec[\"doc_id\"]): rec[\"gt\"] for rec in truth_df.to_dict(orient=\"records\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(df[\"text\"], embs, words, weight4ind)\n",
    "df[\"vector\"] = pd.Series(list(doc_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_text_length = 10\n",
    "skip_prediction = list(df[df[\"text\"].map(len) < min_text_length].doc_id)\n",
    "skip_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_ = []\n",
    "# category_reps = {categories[0]: ['188'], categories[1]: [\"585\"]}\n",
    "category_reps = {categories[0]: ['124'], categories[1]: [\"259\"]}\n",
    "\n",
    "# drug_gene\n",
    "# gene_disease\n",
    "\n",
    "for k,v in category_reps.items():\n",
    "    categories_.append(k)\n",
    "    skip_prediction.extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df\n",
    "category_vecs = {}\n",
    "for c in categories_:\n",
    "    vectors = np.asarray(list(docs.loc[docs['doc_id'].isin(category_reps[c])].vector))\n",
    "    category_vecs[c] = np.mean(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vecs = {}\n",
    "for c in categories_:\n",
    "    vectors = np.asarray(list(docs.loc[docs['doc_id'].isin(category_reps[c])].vector))\n",
    "    category_vecs[c] = np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for idx, row in docs.iterrows():\n",
    "    doc_id = row[\"doc_id\"]\n",
    "    if doc_id in skip_prediction:\n",
    "        continue\n",
    "    max_sim = 0\n",
    "    winner = categories[0]\n",
    "    for j in category_vecs:\n",
    "        sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            winner = j\n",
    "    predictions[doc_id] = winner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883843263553407"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_accuracy_score(predictions, truth_dict):\n",
    "    scores = []\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    for k,v in predictions.items():\n",
    "    \n",
    "        preds.append(v)\n",
    "        labels.append(truth_dict[k])\n",
    "\n",
    "#         if v == truth_dict[k]:\n",
    "#             scores.append(1)\n",
    "#         else:\n",
    "#             scores.append(0)\n",
    "    \n",
    "#     print(f1_score(labels, preds, average='weighted')) \n",
    "#     if len(scores) == 0:\n",
    "#       return 0.0\n",
    "#     return sum(scores) / float(len(scores))\n",
    "\n",
    "    return f1_score(labels, preds, average='weighted')\n",
    "\n",
    "get_accuracy_score(predictions, truth_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from collections import deque\n",
    "    \n",
    "    \n",
    "def infer_topics(docs, n_topics, min_text_length=80, max_iter=150, batch_size=128, learning_offset=300.):\n",
    "    unclassifiable = list(docs[docs[\"text\"].map(len) < min_text_length].doc_id)\n",
    "    filtered = docs[~docs['doc_id'].isin(unclassifiable)]\n",
    "    ids = [d for d in list(filtered.doc_id)[0:10]]\n",
    "    n_features = 1000\n",
    "    tf_vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_df=0.95,\n",
    "        min_df=0.1,\n",
    "        max_features=n_features)\n",
    "    tf = tf_vectorizer.fit_transform(list(filtered.loc[:, 'text']))\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics,\n",
    "        max_iter=max_iter,\n",
    "        batch_size=batch_size,\n",
    "        learning_method='online',\n",
    "        learning_offset=learning_offset,\n",
    "        random_state=0)\n",
    "    lda.fit(tf)\n",
    "    doc_topics = lda.transform(tf)\n",
    "    topic_leaders = {\"topic_{}\".format(i): [] for i in iter(range(n_topics))}\n",
    "    for idx, probs in enumerate(doc_topics):\n",
    "        score = max(probs)\n",
    "        topic = np.argmax(probs)\n",
    "\n",
    "        doc_id = filtered.loc[filtered.index[idx]].doc_id\n",
    "        topic_leaders[\"topic_{}\".format(topic)].append(\n",
    "            {\"doc_id\": doc_id, \"score\": score})\n",
    "    for i in iter(range(n_topics)):\n",
    "        topic_leaders[\"topic_{}\".format(i)] = sorted(\n",
    "            topic_leaders[\"topic_{}\".format(i)], key=itemgetter('score'), reverse=True)\n",
    "\n",
    "    def roundrobin(*iterables):\n",
    "        q = deque(iter(it) for it in iterables)\n",
    "        for itr in cycle(q):\n",
    "            try:\n",
    "                yield itr.__next__()\n",
    "            except StopIteration:\n",
    "                if len(q) > 0:\n",
    "                    q.pop()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return list(roundrobin(*topic_leaders.values()))\n",
    "\n",
    "ordered_docs = infer_topics(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': '120', 'score': 0.816831518758495},\n",
       " {'doc_id': '272', 'score': 0.8166679566169036},\n",
       " {'doc_id': '121', 'score': 0.816831518758495},\n",
       " {'doc_id': '549', 'score': 0.8166159896885092},\n",
       " {'doc_id': '137', 'score': 0.7927543300445525},\n",
       " {'doc_id': '599', 'score': 0.8165758595530275},\n",
       " {'doc_id': '124', 'score': 0.7927101495860739},\n",
       " {'doc_id': '456', 'score': 0.8164761838835681},\n",
       " {'doc_id': '125', 'score': 0.7927101495860739},\n",
       " {'doc_id': '602', 'score': 0.8164643767926444},\n",
       " {'doc_id': '128', 'score': 0.7927101495860739},\n",
       " {'doc_id': '261', 'score': 0.8164561185368904},\n",
       " {'doc_id': '8', 'score': 0.7927101495860739},\n",
       " {'doc_id': '262', 'score': 0.8164561185368904},\n",
       " {'doc_id': '191', 'score': 0.7927099035379565},\n",
       " {'doc_id': '571', 'score': 0.8164561185368904},\n",
       " {'doc_id': '196', 'score': 0.7927099035379565},\n",
       " {'doc_id': '393', 'score': 0.8124288015191476},\n",
       " {'doc_id': '198', 'score': 0.7927099035379565},\n",
       " {'doc_id': '394', 'score': 0.8124288015191476},\n",
       " {'doc_id': '544', 'score': 0.7927099035379565},\n",
       " {'doc_id': '396', 'score': 0.8124288015191476},\n",
       " {'doc_id': '545', 'score': 0.7927099035379565},\n",
       " {'doc_id': '397', 'score': 0.8124288015191476},\n",
       " {'doc_id': '546', 'score': 0.7927099035379565},\n",
       " {'doc_id': '398', 'score': 0.8124288015191476},\n",
       " {'doc_id': '547', 'score': 0.7927099035379565},\n",
       " {'doc_id': '399', 'score': 0.8124288015191476},\n",
       " {'doc_id': '64', 'score': 0.7927099035379565},\n",
       " {'doc_id': '401', 'score': 0.8124288015191476},\n",
       " {'doc_id': '65', 'score': 0.7927099035379565},\n",
       " {'doc_id': '402', 'score': 0.8124288015191476},\n",
       " {'doc_id': '69', 'score': 0.7927099035379565},\n",
       " {'doc_id': '403', 'score': 0.8124288015191476},\n",
       " {'doc_id': '70', 'score': 0.7927099035379565},\n",
       " {'doc_id': '404', 'score': 0.8124288015191476},\n",
       " {'doc_id': '71', 'score': 0.7927099035379565},\n",
       " {'doc_id': '405', 'score': 0.8124288015191476},\n",
       " {'doc_id': '74', 'score': 0.7927099035379565},\n",
       " {'doc_id': '406', 'score': 0.8124288015191476},\n",
       " {'doc_id': '80', 'score': 0.7927099035379565},\n",
       " {'doc_id': '408', 'score': 0.8124288015191476},\n",
       " {'doc_id': '515', 'score': 0.7927011086416733},\n",
       " {'doc_id': '409', 'score': 0.8124288015191476},\n",
       " {'doc_id': '516', 'score': 0.7927011086416733},\n",
       " {'doc_id': '410', 'score': 0.8124288015191476},\n",
       " {'doc_id': '528', 'score': 0.7927011086416733},\n",
       " {'doc_id': '411', 'score': 0.8124288015191476},\n",
       " {'doc_id': '140', 'score': 0.7870252046547503},\n",
       " {'doc_id': '412', 'score': 0.8124288015191476},\n",
       " {'doc_id': '141', 'score': 0.7870252046547503},\n",
       " {'doc_id': '274', 'score': 0.7925604743318228},\n",
       " {'doc_id': '192', 'score': 0.7870252046547503},\n",
       " {'doc_id': '278', 'score': 0.7925604743318228},\n",
       " {'doc_id': '199', 'score': 0.7870252046547503},\n",
       " {'doc_id': '279', 'score': 0.7925604743318228},\n",
       " {'doc_id': '169', 'score': 0.7698906867609904},\n",
       " {'doc_id': '323', 'score': 0.7925604743318228},\n",
       " {'doc_id': '172', 'score': 0.7698906867609904},\n",
       " {'doc_id': '326', 'score': 0.7925604743318228},\n",
       " {'doc_id': '173', 'score': 0.7698906867609904},\n",
       " {'doc_id': '327', 'score': 0.7925604743318228},\n",
       " {'doc_id': '138', 'score': 0.7498575761017626},\n",
       " {'doc_id': '328', 'score': 0.7925604743318228},\n",
       " {'doc_id': '143', 'score': 0.7498575761017626},\n",
       " {'doc_id': '329', 'score': 0.7925604743318228},\n",
       " {'doc_id': '150', 'score': 0.7498575761017626},\n",
       " {'doc_id': '360', 'score': 0.7925604743318228},\n",
       " {'doc_id': '157', 'score': 0.7498575761017626},\n",
       " {'doc_id': '363', 'score': 0.7925604743318228},\n",
       " {'doc_id': '158', 'score': 0.7498575761017626},\n",
       " {'doc_id': '368', 'score': 0.7925604743318228},\n",
       " {'doc_id': '176', 'score': 0.7498575761017626},\n",
       " {'doc_id': '472', 'score': 0.7925604743318228},\n",
       " {'doc_id': '177', 'score': 0.7498575761017626},\n",
       " {'doc_id': '473', 'score': 0.7925604743318228},\n",
       " {'doc_id': '178', 'score': 0.7498575761017626},\n",
       " {'doc_id': '504', 'score': 0.7925604743318228},\n",
       " {'doc_id': '179', 'score': 0.7498575761017626},\n",
       " {'doc_id': '559', 'score': 0.7925604743318228},\n",
       " {'doc_id': '181', 'score': 0.7498575761017626},\n",
       " {'doc_id': '263', 'score': 0.7925452579521272},\n",
       " {'doc_id': '183', 'score': 0.7498575761017626},\n",
       " {'doc_id': '264', 'score': 0.7925452579521272},\n",
       " {'doc_id': '184', 'score': 0.7498575761017626},\n",
       " {'doc_id': '271', 'score': 0.7925452579521272},\n",
       " {'doc_id': '187', 'score': 0.7498575761017626},\n",
       " {'doc_id': '297', 'score': 0.7925452579521272},\n",
       " {'doc_id': '194', 'score': 0.7498575761017626},\n",
       " {'doc_id': '459', 'score': 0.7925452579521272},\n",
       " {'doc_id': '197', 'score': 0.7498575761017626},\n",
       " {'doc_id': '460', 'score': 0.7925452579521272},\n",
       " {'doc_id': '204', 'score': 0.7498575761017626},\n",
       " {'doc_id': '461', 'score': 0.7925452579521272},\n",
       " {'doc_id': '232', 'score': 0.7498575761017626},\n",
       " {'doc_id': '281', 'score': 0.7925420118833627},\n",
       " {'doc_id': '233', 'score': 0.7498575761017626},\n",
       " {'doc_id': '277', 'score': 0.792541209197623},\n",
       " {'doc_id': '238', 'score': 0.7498575761017626},\n",
       " {'doc_id': '287', 'score': 0.7924408251835309},\n",
       " {'doc_id': '48', 'score': 0.7498575761017626},\n",
       " {'doc_id': '330', 'score': 0.7924408251835309},\n",
       " {'doc_id': '49', 'score': 0.7498575761017626},\n",
       " {'doc_id': '372', 'score': 0.7924202576238195},\n",
       " {'doc_id': '494', 'score': 0.7498575761017626},\n",
       " {'doc_id': '376', 'score': 0.7924202576238195},\n",
       " {'doc_id': '500', 'score': 0.7498575761017626},\n",
       " {'doc_id': '488', 'score': 0.7924202576238195},\n",
       " {'doc_id': '567', 'score': 0.7498575761017626},\n",
       " {'doc_id': '489', 'score': 0.7924202576238195},\n",
       " {'doc_id': '82', 'score': 0.7498575761017626},\n",
       " {'doc_id': '490', 'score': 0.7924202576238195},\n",
       " {'doc_id': '87', 'score': 0.7498575761017626},\n",
       " {'doc_id': '257', 'score': 0.7922221243432637},\n",
       " {'doc_id': '88', 'score': 0.7498575761017626},\n",
       " {'doc_id': '260', 'score': 0.7922221243432637},\n",
       " {'doc_id': '89', 'score': 0.7498575761017626},\n",
       " {'doc_id': '273', 'score': 0.7922221243432637},\n",
       " {'doc_id': '90', 'score': 0.7498575761017626},\n",
       " {'doc_id': '276', 'score': 0.7922221243432637},\n",
       " {'doc_id': '91', 'score': 0.7498575761017626},\n",
       " {'doc_id': '317', 'score': 0.7922002761270662},\n",
       " {'doc_id': '92', 'score': 0.7498575761017626},\n",
       " {'doc_id': '318', 'score': 0.7922002761270662},\n",
       " {'doc_id': '95', 'score': 0.7498575761017626},\n",
       " {'doc_id': '601', 'score': 0.7881141494395818},\n",
       " {'doc_id': '96', 'score': 0.7498575761017626},\n",
       " {'doc_id': '478', 'score': 0.7820023603452526},\n",
       " {'doc_id': '97', 'score': 0.7498575761017626},\n",
       " {'doc_id': '206', 'score': 0.7497908305218354},\n",
       " {'doc_id': '102', 'score': 0.7498201913805369},\n",
       " {'doc_id': '207', 'score': 0.7497908305218354},\n",
       " {'doc_id': '104', 'score': 0.7498201913805369},\n",
       " {'doc_id': '211', 'score': 0.7497908305218354},\n",
       " {'doc_id': '105', 'score': 0.7498201913805369},\n",
       " {'doc_id': '217', 'score': 0.7497908305218354},\n",
       " {'doc_id': '106', 'score': 0.7498201913805369},\n",
       " {'doc_id': '220', 'score': 0.7497908305218354},\n",
       " {'doc_id': '107', 'score': 0.7498201913805369},\n",
       " {'doc_id': '289', 'score': 0.7497908305218354},\n",
       " {'doc_id': '108', 'score': 0.7498201913805369},\n",
       " {'doc_id': '33', 'score': 0.7497908305218354},\n",
       " {'doc_id': '109', 'score': 0.7498201913805369},\n",
       " {'doc_id': '334', 'score': 0.7497908305218354},\n",
       " {'doc_id': '110', 'score': 0.7498201913805369},\n",
       " {'doc_id': '338', 'score': 0.7497908305218354},\n",
       " {'doc_id': '111', 'score': 0.7498201913805369},\n",
       " {'doc_id': '34', 'score': 0.7497908305218354},\n",
       " {'doc_id': '112', 'score': 0.7498201913805369},\n",
       " {'doc_id': '377', 'score': 0.7497908305218354},\n",
       " {'doc_id': '113', 'score': 0.7498201913805369},\n",
       " {'doc_id': '39', 'score': 0.7497908305218354},\n",
       " {'doc_id': '14', 'score': 0.7498201913805369},\n",
       " {'doc_id': '40', 'score': 0.7497908305218354},\n",
       " {'doc_id': '15', 'score': 0.7498201913805369},\n",
       " {'doc_id': '419', 'score': 0.7497908305218354},\n",
       " {'doc_id': '16', 'score': 0.7498201913805369},\n",
       " {'doc_id': '420', 'score': 0.7497908305218354},\n",
       " {'doc_id': '162', 'score': 0.7498201913805369},\n",
       " {'doc_id': '421', 'score': 0.7497908305218354},\n",
       " {'doc_id': '166', 'score': 0.7498201913805369},\n",
       " {'doc_id': '422', 'score': 0.7497908305218354},\n",
       " {'doc_id': '170', 'score': 0.7498201913805369},\n",
       " {'doc_id': '424', 'score': 0.7497908305218354},\n",
       " {'doc_id': '171', 'score': 0.7498201913805369},\n",
       " {'doc_id': '447', 'score': 0.7497908305218354},\n",
       " {'doc_id': '214', 'score': 0.7498201913805369},\n",
       " {'doc_id': '453', 'score': 0.7497908305218354},\n",
       " {'doc_id': '219', 'score': 0.7498201913805369},\n",
       " {'doc_id': '468', 'score': 0.7497908305218354},\n",
       " {'doc_id': '223', 'score': 0.7498201913805369},\n",
       " {'doc_id': '471', 'score': 0.7497908305218354},\n",
       " {'doc_id': '23', 'score': 0.7498201913805369},\n",
       " {'doc_id': '510', 'score': 0.7497908305218354},\n",
       " {'doc_id': '24', 'score': 0.7498201913805369},\n",
       " {'doc_id': '511', 'score': 0.7497908305218354},\n",
       " {'doc_id': '25', 'score': 0.7498201913805369},\n",
       " {'doc_id': '540', 'score': 0.7497908305218354},\n",
       " {'doc_id': '26', 'score': 0.7498201913805369},\n",
       " {'doc_id': '541', 'score': 0.7497908305218354},\n",
       " {'doc_id': '27', 'score': 0.7498201913805369},\n",
       " {'doc_id': '568', 'score': 0.7497908305218354},\n",
       " {'doc_id': '28', 'score': 0.7498201913805369},\n",
       " {'doc_id': '574', 'score': 0.7497908305218354},\n",
       " {'doc_id': '29', 'score': 0.7498201913805369},\n",
       " {'doc_id': '1', 'score': 0.7496609589560681},\n",
       " {'doc_id': '30', 'score': 0.7498201913805369},\n",
       " {'doc_id': '10', 'score': 0.7496609589560681},\n",
       " {'doc_id': '31', 'score': 0.7498201913805369},\n",
       " {'doc_id': '11', 'score': 0.7496609589560681},\n",
       " {'doc_id': '32', 'score': 0.7498201913805369},\n",
       " {'doc_id': '13', 'score': 0.7496609589560681},\n",
       " {'doc_id': '53', 'score': 0.7498201913805369},\n",
       " {'doc_id': '135', 'score': 0.7496609589560681},\n",
       " {'doc_id': '68', 'score': 0.7498201913805369},\n",
       " {'doc_id': '136', 'score': 0.7496609589560681},\n",
       " {'doc_id': '72', 'score': 0.7498201913805369},\n",
       " {'doc_id': '148', 'score': 0.7496609589560681},\n",
       " {'doc_id': '73', 'score': 0.7498201913805369},\n",
       " {'doc_id': '3', 'score': 0.7496609589560681},\n",
       " {'doc_id': '75', 'score': 0.7498201913805369},\n",
       " {'doc_id': '395', 'score': 0.7496609589560681},\n",
       " {'doc_id': '76', 'score': 0.7498201913805369},\n",
       " {'doc_id': '407', 'score': 0.7496609589560681},\n",
       " {'doc_id': '86', 'score': 0.7498201913805369},\n",
       " {'doc_id': '413', 'score': 0.7496609589560681},\n",
       " {'doc_id': '103', 'score': 0.7497772670604979},\n",
       " {'doc_id': '414', 'score': 0.7496609589560681},\n",
       " {'doc_id': '116', 'score': 0.7497772670604979},\n",
       " {'doc_id': '417', 'score': 0.7496609589560681},\n",
       " {'doc_id': '119', 'score': 0.7497772670604979},\n",
       " {'doc_id': '418', 'score': 0.7496609589560681},\n",
       " {'doc_id': '129', 'score': 0.7497772670604979},\n",
       " {'doc_id': '462', 'score': 0.7496609589560681},\n",
       " {'doc_id': '205', 'score': 0.7497772670604979},\n",
       " {'doc_id': '463', 'score': 0.7496609589560681},\n",
       " {'doc_id': '208', 'score': 0.7497772670604979},\n",
       " {'doc_id': '464', 'score': 0.7496609589560681},\n",
       " {'doc_id': '209', 'score': 0.7497772670604979},\n",
       " {'doc_id': '466', 'score': 0.7496609589560681},\n",
       " {'doc_id': '210', 'score': 0.7497772670604979},\n",
       " {'doc_id': '467', 'score': 0.7496609589560681},\n",
       " {'doc_id': '218', 'score': 0.7497772670604979},\n",
       " {'doc_id': '5', 'score': 0.7496609589560681},\n",
       " {'doc_id': '36', 'score': 0.7497772670604979},\n",
       " {'doc_id': '6', 'score': 0.7496609589560681},\n",
       " {'doc_id': '37', 'score': 0.7497772670604979},\n",
       " {'doc_id': '9', 'score': 0.7496609589560681},\n",
       " {'doc_id': '371', 'score': 0.7497772670604979},\n",
       " {'doc_id': '227', 'score': 0.7496161621904822},\n",
       " {'doc_id': '38', 'score': 0.7497772670604979},\n",
       " {'doc_id': '228', 'score': 0.7496161621904822},\n",
       " {'doc_id': '41', 'score': 0.7497772670604979},\n",
       " {'doc_id': '229', 'score': 0.7496161621904822},\n",
       " {'doc_id': '543', 'score': 0.7497772670604979},\n",
       " {'doc_id': '236', 'score': 0.7496161621904822},\n",
       " {'doc_id': '188', 'score': 0.7497303584856175},\n",
       " {'doc_id': '249', 'score': 0.7496161621904822},\n",
       " {'doc_id': '189', 'score': 0.7497303584856175},\n",
       " {'doc_id': '250', 'score': 0.7496161621904822},\n",
       " {'doc_id': '256', 'score': 0.7497303584856175},\n",
       " {'doc_id': '284', 'score': 0.7496161621904822},\n",
       " {'doc_id': '301', 'score': 0.7497303584856175},\n",
       " {'doc_id': '286', 'score': 0.7496161621904822},\n",
       " {'doc_id': '303', 'score': 0.7497303584856175},\n",
       " {'doc_id': '294', 'score': 0.7496161621904822},\n",
       " {'doc_id': '304', 'score': 0.7497303584856175},\n",
       " {'doc_id': '295', 'score': 0.7496161621904822},\n",
       " {'doc_id': '307', 'score': 0.7497303584856175},\n",
       " {'doc_id': '319', 'score': 0.7496161621904822},\n",
       " {'doc_id': '308', 'score': 0.7497303584856175},\n",
       " {'doc_id': '320', 'score': 0.7496161621904822},\n",
       " {'doc_id': '309', 'score': 0.7497303584856175},\n",
       " {'doc_id': '321', 'score': 0.7496161621904822},\n",
       " {'doc_id': '310', 'score': 0.7497303584856175},\n",
       " {'doc_id': '339', 'score': 0.7496161621904822},\n",
       " {'doc_id': '311', 'score': 0.7497303584856175},\n",
       " {'doc_id': '373', 'score': 0.7496161621904822},\n",
       " {'doc_id': '312', 'score': 0.7497303584856175},\n",
       " {'doc_id': '382', 'score': 0.7496161621904822},\n",
       " {'doc_id': '313', 'score': 0.7497303584856175},\n",
       " {'doc_id': '384', 'score': 0.7496161621904822},\n",
       " {'doc_id': '316', 'score': 0.7497303584856175},\n",
       " {'doc_id': '385', 'score': 0.7496161621904822},\n",
       " {'doc_id': '346', 'score': 0.7497303584856175},\n",
       " {'doc_id': '387', 'score': 0.7496161621904822},\n",
       " {'doc_id': '349', 'score': 0.7497303584856175},\n",
       " {'doc_id': '388', 'score': 0.7496161621904822},\n",
       " {'doc_id': '359', 'score': 0.7497303584856175},\n",
       " {'doc_id': '390', 'score': 0.7496161621904822},\n",
       " {'doc_id': '362', 'score': 0.7497303584856175},\n",
       " {'doc_id': '465', 'score': 0.7496161621904822},\n",
       " {'doc_id': '454', 'score': 0.7497303584856175},\n",
       " {'doc_id': '484', 'score': 0.7496161621904822},\n",
       " {'doc_id': '513', 'score': 0.7497303584856175},\n",
       " {'doc_id': '485', 'score': 0.7496161621904822},\n",
       " {'doc_id': '523', 'score': 0.7497303584856175},\n",
       " {'doc_id': '492', 'score': 0.7496161621904822},\n",
       " {'doc_id': '532', 'score': 0.7497303584856175},\n",
       " {'doc_id': '501', 'score': 0.7496161621904822},\n",
       " {'doc_id': '569', 'score': 0.7497303584856175},\n",
       " {'doc_id': '502', 'score': 0.7496161621904822},\n",
       " {'doc_id': '570', 'score': 0.7497303584856175},\n",
       " {'doc_id': '503', 'score': 0.7496161621904822},\n",
       " {'doc_id': '600', 'score': 0.6715243410566111},\n",
       " {'doc_id': '506', 'score': 0.7496161621904822},\n",
       " {'doc_id': '391', 'score': 0.6550783257167586},\n",
       " {'doc_id': '508', 'score': 0.7496161621904822},\n",
       " {'doc_id': '392', 'score': 0.6550783257167586},\n",
       " {'doc_id': '509', 'score': 0.7496161621904822},\n",
       " {'doc_id': '476', 'score': 0.6056602109717646},\n",
       " {'doc_id': '280', 'score': 0.7495870938525232},\n",
       " {'doc_id': '477', 'score': 0.6056602109717646},\n",
       " {'doc_id': '283', 'score': 0.7495870938525232},\n",
       " {'doc_id': '479', 'score': 0.6056602109717646},\n",
       " {'doc_id': '285', 'score': 0.7495870938525232},\n",
       " {'doc_id': '480', 'score': 0.6056602109717646},\n",
       " {'doc_id': '374', 'score': 0.7495870938525232},\n",
       " {'doc_id': '556', 'score': 0.5979069833198231},\n",
       " {'doc_id': '375', 'score': 0.7495870938525232},\n",
       " {'doc_id': '557', 'score': 0.5979069833198231},\n",
       " {'doc_id': '379', 'score': 0.7495870938525232},\n",
       " {'doc_id': '448', 'score': 0.5920181221505227},\n",
       " {'doc_id': '380', 'score': 0.7495870938525232},\n",
       " {'doc_id': '449', 'score': 0.5920181221505227},\n",
       " {'doc_id': '381', 'score': 0.7495870938525232},\n",
       " {'doc_id': '450', 'score': 0.5920181221505227},\n",
       " {'doc_id': '389', 'score': 0.7495870938525232},\n",
       " {'doc_id': '451', 'score': 0.5920181221505227},\n",
       " {'doc_id': '474', 'score': 0.7495870938525232},\n",
       " {'doc_id': '35', 'score': 0.5252608802225425},\n",
       " {'doc_id': '475', 'score': 0.7495870938525232},\n",
       " {'doc_id': '139', 'score': 0.5207510616833458},\n",
       " {'doc_id': '483', 'score': 0.7495870938525232},\n",
       " {'doc_id': '142', 'score': 0.5207510616833458},\n",
       " {'doc_id': '182', 'score': 0.749580447649308},\n",
       " {'doc_id': '350', 'score': 0.5187239819903741},\n",
       " {'doc_id': '185', 'score': 0.749580447649308},\n",
       " {'doc_id': '455', 'score': 0.5187239819903741},\n",
       " {'doc_id': '190', 'score': 0.749580447649308},\n",
       " {'doc_id': '533', 'score': 0.5187239819903741},\n",
       " {'doc_id': '243', 'score': 0.749580447649308},\n",
       " {'doc_id': '535', 'score': 0.5187239819903741},\n",
       " {'doc_id': '245', 'score': 0.749580447649308},\n",
       " {'doc_id': '537', 'score': 0.5187239819903741},\n",
       " {'doc_id': '247', 'score': 0.749580447649308},\n",
       " {'doc_id': '539', 'score': 0.5187239819903741},\n",
       " {'doc_id': '258', 'score': 0.749580447649308},\n",
       " {'doc_id': '356', 'score': 0.5154282496612835},\n",
       " {'doc_id': '259', 'score': 0.749580447649308},\n",
       " {'doc_id': '416', 'score': 0.51542054183553},\n",
       " {'doc_id': '265', 'score': 0.749580447649308},\n",
       " {'doc_id': '590', 'score': 0.51542054183553},\n",
       " {'doc_id': '275', 'score': 0.749580447649308},\n",
       " {'doc_id': '596', 'score': 0.51542054183553},\n",
       " {'doc_id': '302', 'score': 0.749580447649308},\n",
       " {'doc_id': '552', 'score': 0.5124355752225586},\n",
       " {'doc_id': '378', 'score': 0.749580447649308},\n",
       " {'doc_id': '553', 'score': 0.5124355752225586},\n",
       " {'doc_id': '497', 'score': 0.749580447649308},\n",
       " {'doc_id': '358', 'score': 0.5088235063540377},\n",
       " {'doc_id': '514', 'score': 0.749580447649308},\n",
       " {'doc_id': '361', 'score': 0.5088235063540377},\n",
       " {'doc_id': '518', 'score': 0.749580447649308},\n",
       " {'doc_id': '364', 'score': 0.5088235063540377},\n",
       " {'doc_id': '519', 'score': 0.749580447649308},\n",
       " {'doc_id': '365', 'score': 0.5088235063540377},\n",
       " {'doc_id': '522', 'score': 0.749580447649308},\n",
       " {'doc_id': '367', 'score': 0.5088235063540377},\n",
       " {'doc_id': '524', 'score': 0.749580447649308},\n",
       " {'doc_id': '520', 'score': 0.5088235063540377},\n",
       " {'doc_id': '558', 'score': 0.749580447649308},\n",
       " {'doc_id': '521', 'score': 0.5088235063540377},\n",
       " {'doc_id': '560', 'score': 0.749580447649308},\n",
       " {'doc_id': '525', 'score': 0.5088235063540377},\n",
       " {'doc_id': '562', 'score': 0.749580447649308},\n",
       " {'doc_id': '526', 'score': 0.5088235063540377},\n",
       " {'doc_id': '563', 'score': 0.749580447649308},\n",
       " {'doc_id': '550', 'score': 0.5082585362660786},\n",
       " {'doc_id': '566', 'score': 0.749580447649308},\n",
       " {'doc_id': '551', 'score': 0.5082585362660786},\n",
       " {'doc_id': '592', 'score': 0.749580447649308},\n",
       " {'doc_id': '222', 'score': 0.5023330816782355},\n",
       " {'doc_id': '597', 'score': 0.749580447649308},\n",
       " {'doc_id': '168', 'score': 0.5021962483482735},\n",
       " {'doc_id': '481', 'score': 0.6892535746628917},\n",
       " {'doc_id': '266', 'score': 0.5021962483482735},\n",
       " {'doc_id': '482', 'score': 0.6892535746628917},\n",
       " {'doc_id': '267', 'score': 0.5021962483482735},\n",
       " {'doc_id': '486', 'score': 0.6892535746628917},\n",
       " {'doc_id': '268', 'score': 0.5021962483482735},\n",
       " {'doc_id': '487', 'score': 0.6892535746628917},\n",
       " {'doc_id': '355', 'score': 0.5021962483482735},\n",
       " {'doc_id': '491', 'score': 0.6892535746628917},\n",
       " {'doc_id': '357', 'score': 0.5021962483482735},\n",
       " {'doc_id': '493', 'score': 0.6892535746628917},\n",
       " {'doc_id': '4', 'score': 0.5021962483482735},\n",
       " {'doc_id': '400', 'score': 0.6013849769487211},\n",
       " {'doc_id': '100', 'score': 0.5},\n",
       " {'doc_id': '351', 'score': 0.6001050634581887},\n",
       " {'doc_id': '101', 'score': 0.5},\n",
       " {'doc_id': '352', 'score': 0.6001050634581887},\n",
       " {'doc_id': '114', 'score': 0.5},\n",
       " {'doc_id': '353', 'score': 0.6001050634581887},\n",
       " {'doc_id': '115', 'score': 0.5},\n",
       " {'doc_id': '354', 'score': 0.6001050634581887},\n",
       " {'doc_id': '117', 'score': 0.5},\n",
       " {'doc_id': '332', 'score': 0.5997095440701581},\n",
       " {'doc_id': '118', 'score': 0.5},\n",
       " {'doc_id': '333', 'score': 0.5997095440701581},\n",
       " {'doc_id': '122', 'score': 0.5},\n",
       " {'doc_id': '347', 'score': 0.5929262889758193},\n",
       " {'doc_id': '123', 'score': 0.5},\n",
       " {'doc_id': '348', 'score': 0.5929262889758193},\n",
       " {'doc_id': '126', 'score': 0.5},\n",
       " {'doc_id': '12', 'score': 0.5890484846526017},\n",
       " {'doc_id': '127', 'score': 0.5},\n",
       " {'doc_id': '299', 'score': 0.5042892023312674},\n",
       " {'doc_id': '130', 'score': 0.5},\n",
       " {'doc_id': '300', 'score': 0.5042892023312674},\n",
       " {'doc_id': '131', 'score': 0.5},\n",
       " {'doc_id': '452', 'score': 0.5042892023312674},\n",
       " {'doc_id': '132', 'score': 0.5},\n",
       " {'doc_id': '495', 'score': 0.5042892023312674},\n",
       " {'doc_id': '133', 'score': 0.5},\n",
       " {'doc_id': '193', 'score': 0.5037317135565619},\n",
       " {'doc_id': '134', 'score': 0.5},\n",
       " {'doc_id': '195', 'score': 0.5037317135565619},\n",
       " {'doc_id': '144', 'score': 0.5},\n",
       " {'doc_id': '270', 'score': 0.502589710544287},\n",
       " {'doc_id': '145', 'score': 0.5},\n",
       " {'doc_id': '512', 'score': 0.5018254846632445},\n",
       " {'doc_id': '147', 'score': 0.5},\n",
       " {'doc_id': '517', 'score': 0.5018254846632445},\n",
       " {'doc_id': '149', 'score': 0.5},\n",
       " {'doc_id': '527', 'score': 0.5018254846632445},\n",
       " {'doc_id': '152', 'score': 0.5},\n",
       " {'doc_id': '529', 'score': 0.5018254846632445},\n",
       " {'doc_id': '153', 'score': 0.5},\n",
       " {'doc_id': '530', 'score': 0.5018254846632445},\n",
       " {'doc_id': '154', 'score': 0.5},\n",
       " {'doc_id': '155', 'score': 0.5},\n",
       " {'doc_id': '156', 'score': 0.5}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_classify(docs, category_reps, min_text_length=80):\n",
    "    # Exclude docs deemed too short to classify.\n",
    "    skip_prediction = list(df[df[\"text\"].map(len) < min_text_length].doc_id)\n",
    "    categories = []\n",
    "    for k,v in category_reps.items():\n",
    "        categories.append(k)\n",
    "        skip_prediction.extend(v) # No need to predict manually labeled docs\n",
    "    category_vecs = {}\n",
    "    for c in categories:\n",
    "        vectors = np.asarray(list(docs.loc[docs['doc_id'].isin(category_reps[c])].vector))\n",
    "        category_vecs[c] = np.mean(vectors, axis=0)\n",
    "\n",
    "    predictions = {}\n",
    "    for idx, row in docs.iterrows():\n",
    "        doc_id = row[\"doc_id\"]\n",
    "        if doc_id in skip_prediction:\n",
    "            continue\n",
    "        max_sim = 0\n",
    "        winner = categories[0]\n",
    "        for j in category_vecs:\n",
    "            sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "                winner = j\n",
    "        predictions[doc_id] = winner\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '272'),\n",
       " ('120', '549'),\n",
       " ('120', '599'),\n",
       " ('120', '456'),\n",
       " ('120', '602'),\n",
       " ('120', '261'),\n",
       " ('120', '262'),\n",
       " ('120', '571'),\n",
       " ('120', '393'),\n",
       " ('120', '394'),\n",
       " ('120', '544'),\n",
       " ('120', '396'),\n",
       " ('120', '545'),\n",
       " ('120', '397'),\n",
       " ('121', '272'),\n",
       " ('121', '549'),\n",
       " ('121', '599'),\n",
       " ('121', '456'),\n",
       " ('121', '602'),\n",
       " ('121', '261'),\n",
       " ('121', '262'),\n",
       " ('121', '571'),\n",
       " ('121', '393'),\n",
       " ('121', '394'),\n",
       " ('121', '544'),\n",
       " ('121', '396'),\n",
       " ('121', '545'),\n",
       " ('121', '397'),\n",
       " ('137', '272'),\n",
       " ('137', '549'),\n",
       " ('137', '599'),\n",
       " ('137', '456'),\n",
       " ('137', '602'),\n",
       " ('137', '261'),\n",
       " ('137', '262'),\n",
       " ('137', '571'),\n",
       " ('137', '393'),\n",
       " ('137', '394'),\n",
       " ('137', '544'),\n",
       " ('137', '396'),\n",
       " ('137', '545'),\n",
       " ('137', '397'),\n",
       " ('124', '272'),\n",
       " ('124', '549'),\n",
       " ('124', '599'),\n",
       " ('124', '456'),\n",
       " ('124', '602'),\n",
       " ('124', '261'),\n",
       " ('124', '262'),\n",
       " ('124', '571'),\n",
       " ('124', '393'),\n",
       " ('124', '394'),\n",
       " ('124', '544'),\n",
       " ('124', '396'),\n",
       " ('124', '545'),\n",
       " ('124', '397'),\n",
       " ('125', '272'),\n",
       " ('125', '549'),\n",
       " ('125', '599'),\n",
       " ('125', '456'),\n",
       " ('125', '602'),\n",
       " ('125', '261'),\n",
       " ('125', '262'),\n",
       " ('125', '571'),\n",
       " ('125', '393'),\n",
       " ('125', '394'),\n",
       " ('125', '544'),\n",
       " ('125', '396'),\n",
       " ('125', '545'),\n",
       " ('125', '397'),\n",
       " ('128', '272'),\n",
       " ('128', '549'),\n",
       " ('128', '599'),\n",
       " ('128', '456'),\n",
       " ('128', '602'),\n",
       " ('128', '261'),\n",
       " ('128', '262'),\n",
       " ('128', '571'),\n",
       " ('128', '393'),\n",
       " ('128', '394'),\n",
       " ('128', '544'),\n",
       " ('128', '396'),\n",
       " ('128', '545'),\n",
       " ('128', '397'),\n",
       " ('8', '272'),\n",
       " ('8', '549'),\n",
       " ('8', '599'),\n",
       " ('8', '456'),\n",
       " ('8', '602'),\n",
       " ('8', '261'),\n",
       " ('8', '262'),\n",
       " ('8', '571'),\n",
       " ('8', '393'),\n",
       " ('8', '394'),\n",
       " ('8', '544'),\n",
       " ('8', '396'),\n",
       " ('8', '545'),\n",
       " ('8', '397'),\n",
       " ('191', '272'),\n",
       " ('191', '549'),\n",
       " ('191', '599'),\n",
       " ('191', '456'),\n",
       " ('191', '602'),\n",
       " ('191', '261'),\n",
       " ('191', '262'),\n",
       " ('191', '571'),\n",
       " ('191', '393'),\n",
       " ('191', '394'),\n",
       " ('191', '544'),\n",
       " ('191', '396'),\n",
       " ('191', '545'),\n",
       " ('191', '397'),\n",
       " ('196', '272'),\n",
       " ('196', '549'),\n",
       " ('196', '599'),\n",
       " ('196', '456'),\n",
       " ('196', '602'),\n",
       " ('196', '261'),\n",
       " ('196', '262'),\n",
       " ('196', '571'),\n",
       " ('196', '393'),\n",
       " ('196', '394'),\n",
       " ('196', '544'),\n",
       " ('196', '396'),\n",
       " ('196', '545'),\n",
       " ('196', '397'),\n",
       " ('198', '272'),\n",
       " ('198', '549'),\n",
       " ('198', '599'),\n",
       " ('198', '456'),\n",
       " ('198', '602'),\n",
       " ('198', '261'),\n",
       " ('198', '262'),\n",
       " ('198', '571'),\n",
       " ('198', '393'),\n",
       " ('198', '394'),\n",
       " ('198', '544'),\n",
       " ('198', '396'),\n",
       " ('198', '545'),\n",
       " ('198', '397')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representatives = {c:[] for c in categories_}\n",
    "top_n = 24\n",
    "ordered_ids = [d[\"doc_id\"] for d in ordered_docs]\n",
    "for doc_id in ordered_ids[:top_n]:\n",
    "    gt = truth_dict[str(doc_id)]\n",
    "    representatives[gt].append(doc_id)\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "values = [representatives[c] for c in categories]\n",
    "\n",
    "doc_combs = list(itertools.product(*values))    \n",
    "\n",
    "doc_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies =[]\n",
    "for comb in doc_combs:\n",
    "    category_reps = {}\n",
    "    for i,c in enumerate(categories):\n",
    "        category_reps[c] = [str(comb[i])]\n",
    "\n",
    "    preds = auto_classify(docs, category_reps)\n",
    "    acc = get_accuracy_score(preds, truth_dict)\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49973946789233414"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6415550371765205\n",
      "0.6474428956429021\n",
      "0.6828230583539661\n",
      "0.6268168045945823\n",
      "0.7485146276306445\n",
      "0.7963745656053349\n",
      "0.6415550371765205\n",
      "0.6474428956429021\n",
      "0.6828230583539661\n",
      "0.6268168045945823\n",
      "0.7485146276306445\n",
      "0.7963745656053349\n",
      "0.6074680753612387\n",
      "0.670804130332261\n",
      "0.6753159892120103\n",
      "0.6653696920363588\n",
      "0.799339422725612\n",
      "0.6259914956029453\n",
      "0.669253448240315\n",
      "0.7058644323987284\n",
      "0.708545569656681\n",
      "0.7148602569634745\n",
      "0.8368835044356866\n",
      "0.6986510230072914\n",
      "0.669253448240315\n",
      "0.7058644323987284\n",
      "0.708545569656681\n",
      "0.7148602569634745\n",
      "0.8368835044356866\n",
      "0.6986510230072914\n",
      "0.669253448240315\n",
      "0.7058644323987284\n",
      "0.708545569656681\n",
      "0.7148602569634745\n",
      "0.8368835044356866\n",
      "0.6986510230072914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8358974358974359"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_lda_combs(ordered_ids, docs_df, categories, truth_dict, top_n=12):\n",
    "    representatives = {c:[] for c in categories}\n",
    "    for doc_id in ordered_ids[:top_n]:\n",
    "        gt = truth_dict[str(doc_id)]\n",
    "        representatives[gt].append(doc_id)\n",
    "    for c in categories:\n",
    "        if len(representatives[c]) == 0:\n",
    "            print(\"No representatives for %s\" % c)\n",
    "            return None\n",
    "    values = [representatives[c] for c in categories]\n",
    "    doc_combs = list(itertools.product(*values))\n",
    "    return doc_combs\n",
    "\n",
    "def get_lda_accuracies(categories, doc_combs, docs_df, truth_dict):\n",
    "    accuracies = []\n",
    "    for comb in doc_combs:\n",
    "        category_reps = {}\n",
    "        for i,c in enumerate(categories):\n",
    "            category_reps[c] = [str(comb[i])]\n",
    "        preds = auto_classify(docs_df, category_reps)\n",
    "        acc = get_accuracy_score(preds, truth_dict)\n",
    "        accuracies.append(acc)\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "top_lda_combs = get_top_lda_combs([d[\"doc_id\"] for d in ordered_docs], \n",
    "                                  df, categories, truth_dict)\n",
    "lda_accs = get_lda_accuracies(categories, top_lda_combs, df, truth_dict)\n",
    "max(lda_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
