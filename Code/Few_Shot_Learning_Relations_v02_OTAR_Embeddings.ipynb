{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import cycle, islice\n",
    "from operator import itemgetter\n",
    "import sif_embedding_wrapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import codecs\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# model = KeyedVectors.load_word2vec_format('/home/stirunag/models/model_OTAR_200d-3mc-10it.bin', binary=True)\n",
    "# model.save_word2vec_format('/home/stirunag/pre-trained_word_embeddings/model_OTAR_200d-3mc-10it.txt', binary=False)\n",
    "\n",
    "# sed -i -n -e '2,$p'file.txt to remove first line from the txt file\n",
    "\n",
    "\n",
    "# words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/model_OTAR_200d-3mc-10it.txt\", \n",
    "#                                                      '/home/stirunag/pre-trained_word_embeddings/OTAR/TF.txt')\n",
    "\n",
    "\n",
    "# words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/PubMed-and-PMC-FS.txt\", \n",
    "#                                                      '/home/stirunag/pre-trained_word_embeddings/wiki/enwiki_vocab_min200.txt')\n",
    "\n",
    "words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/glove/glove.6B.300d.txt\", \n",
    "                                                      '/home/stirunag/pre-trained_word_embeddings/wiki/enwiki_vocab_min200.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "data_path = os.path.abspath(os.path.join(os.path.dirname( '__file__' ), '..', 'Datasets'))+'/'\n",
    "\n",
    "# Although the dataset says csv, it is tab delimited. In addition to this, they have severe codels problems. \n",
    "# So best to parse throught codes first. \n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfc in position 2: invalid start byte\n",
    "\n",
    "#open for reading with \"universal\" type set\n",
    "\n",
    "import codecs\n",
    "\n",
    "doc_d_t = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_target'+'.csv','rU','UTF-8') \n",
    "EUADR_drug_target = pd.read_csv(doc_d_t, sep='\\t', na_filter = False)\n",
    "EUADR_drug_target['CLASS'] = 'drug_gene'\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_target_disease'+'.csv','rU','UTF-8',errors='ignore') \n",
    "EUADR_target_disease = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "EUADR_target_disease['CLASS'] = 'gene_disease'\n",
    "       \n",
    "doc_d_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_disease'+'.csv','rU','UTF-8')                       \n",
    "EUADR_drug_disease = pd.read_csv(doc_d_d, sep='\\t', na_filter = False)\n",
    "EUADR_drug_disease['CLASS'] = 'drug_disease'\n",
    "\n",
    "\n",
    "EUADR_temp = EUADR_drug_target.append(EUADR_target_disease).append(EUADR_drug_disease)\n",
    "\n",
    "EUADR_temp_1 = EUADR_temp[EUADR_temp['ASSOCIATION_TYPE'] == 'PA']\n",
    "EUADR_temp_2 = EUADR_temp[EUADR_temp['ASSOCIATION_TYPE'] == 'NA']\n",
    "EUADR_temp = EUADR_temp_1.append(EUADR_temp_2)\n",
    "\n",
    "EUADR_temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GAD dataset\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'GAD_Corpus_IBIgroup/'+'GAD_Y_N'+'.csv','rU','UTF-8',errors='ignore') \n",
    "GAD_target_disease_Y_N = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "GAD_target_disease_Y_N['CLASS'] = 'gene_disease'\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'GAD_Corpus_IBIgroup/'+'GAD_F'+'.csv','rU','UTF-8',errors='ignore') \n",
    "GAD_target_disease_F = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "GAD_target_disease_F['CLASS'] = 'gene_disease'\n",
    "\n",
    "GAD_temp = GAD_target_disease_Y_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EUADR_temp.reset_index(inplace=True)\n",
    "\n",
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(EUADR_temp[\"SENTENCE\"], embs, words, weight4ind)\n",
    "EUADR_temp[\"vector\"] = pd.Series(list(doc_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EUADR_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {}\n",
    "\n",
    "for idx, row in EUADR_temp.iterrows():\n",
    "    ground_truth[idx] = row['ASSOCIATION_TYPE']\n",
    "\n",
    "categories = list(EUADR_temp[\"ASSOCIATION_TYPE\"].unique())\n",
    "categories    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {}\n",
    "for idx, row in EUADR_temp.iterrows():\n",
    "    ground_truth[idx] = row['ASSOCIATION_TYPE'] \n",
    "\n",
    "inv_map = {}\n",
    "for k, v in ground_truth.items():\n",
    "    inv_map[v] = inv_map.get(v, [])\n",
    "    inv_map[v].append(k)\n",
    "\n",
    "# inv_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average/mean of the sentence vectors that represent our topics \n",
    "category_vecs = {}\n",
    "for c in categories:\n",
    "    vectors = np.asarray(list(EUADR_temp.loc[EUADR_temp.index.isin(inv_map[c])].vector))\n",
    "    category_vecs[c] = np.mean(vectors, axis=0)\n",
    "\n",
    "    \n",
    "# category_vecs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to predict the label of unknown sentences\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "selected_idx = [j for i in inv_map.values() for j in i]\n",
    "\n",
    "for idx, row in EUADR_temp.iterrows():\n",
    "    if idx in selected_idx:\n",
    "        max_sim = 0\n",
    "        winner = 'other'\n",
    "        for j in category_vecs:\n",
    "            sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "                winner = j\n",
    "        predictions[idx] = winner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_score(predictions, truth_dict):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    mis_classified = []\n",
    "    mis_pred = []\n",
    "    \n",
    "    for k,v in predictions.items():\n",
    "        preds.append(v)\n",
    "        labels.append(truth_dict[k])\n",
    "        if v!=truth_dict[k]:\n",
    "#             print(str(v) + '--x--' + str(truth_dict[k]))\n",
    "            mis_pred.append(str(v))\n",
    "            mis_classified.append(k)\n",
    "\n",
    "    return f1_score(labels, preds, average='weighted'), mis_classified, mis_pred\n",
    "\n",
    "\n",
    "score, miss_classified_df, miss_pred = get_accuracy_score(predictions, ground_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "miss_calssified_df = EUADR_temp.iloc[miss_classified_df , [13,2]] \n",
    "miss_calssified_df['Predicted-CLASS'] = miss_pred\n",
    "miss_calssified_df\n",
    "\n",
    "# result_path = os.path.abspath(os.path.join(os.path.dirname( '__file__' ), '..', 'Results'))+'/'\n",
    "# miss_calssified_df.to_csv(result_path+'miss_predictions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAD_temp.reset_index(inplace=True)\n",
    "\n",
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(GAD_temp[\"GAD_CONCLUSION\"], embs, words, weight4ind)\n",
    "GAD_temp[\"vector\"] = pd.Series(list(doc_embeddings))\n",
    "\n",
    "GAD_temp['GAD_ASSOC'] = GAD_temp['GAD_ASSOC'].apply(lambda x: x.replace('Y', 'PA').replace('N', 'NA').replace('F', 'FA'))\n",
    "GAD_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAD_test_ground_truth = {}\n",
    "\n",
    "for idx, row in GAD_temp.iterrows():\n",
    "    GAD_test_ground_truth[idx] = row['GAD_ASSOC']\n",
    "    \n",
    "# Try to predict the label of unknown sentences\n",
    "\n",
    "GAD_test_predictions = {}\n",
    "\n",
    "for idx, row in GAD_temp.iterrows():\n",
    "    max_sim = 0.00\n",
    "    winner = 'other'\n",
    "    for j in category_vecs:\n",
    "        sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            winner = j\n",
    "    GAD_test_predictions[idx] = winner   \n",
    "    \n",
    "    \n",
    "GAD_score, GAD_miss_classified, GAD_miss_pred = get_accuracy_score(GAD_test_predictions, GAD_test_ground_truth)\n",
    "GAD_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_calssified_GAD_test = GAD_temp.iloc[GAD_miss_classified , [11,2]] \n",
    "miss_calssified_GAD_test['Predicted-CLASS'] = GAD_miss_pred\n",
    "miss_calssified_GAD_test\n",
    "# miss_calssified_GAD_test.to_csv(result_path+'miss_predictions_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
