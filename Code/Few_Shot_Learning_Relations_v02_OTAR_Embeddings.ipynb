{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import cycle, islice\n",
    "from operator import itemgetter\n",
    "import sif_embedding_wrapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import codecs\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# model = KeyedVectors.load_word2vec_format('/home/stirunag/models/model_OTAR_200d-3mc-10it.bin', binary=True)\n",
    "# model.save_word2vec_format('/home/stirunag/pre-trained_word_embeddings/model_OTAR_200d-3mc-10it.txt', binary=False)\n",
    "\n",
    "# sed -i -n -e '2,$p'file.txt to remove first line from the txt file\n",
    "\n",
    "\n",
    "words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/model_OTAR_200d-3mc-10it.txt\", \n",
    "                                                     '/home/stirunag/pre-trained_word_embeddings/OTAR/TF.txt')\n",
    "\n",
    "\n",
    "# words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/PubMed-and-PMC-FS.txt\", \n",
    "#                                                      '/home/stirunag/pre-trained_word_embeddings/wiki/enwiki_vocab_min200.txt')\n",
    "\n",
    "# words, embs, weight4ind = sif_embedding_wrapper.load_embeddings(\"/home/stirunag/pre-trained_word_embeddings/glove/glove.6B.300d.txt\", \n",
    "#                                                       '/home/stirunag/pre-trained_word_embeddings/wiki/enwiki_vocab_min200.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "data_path = os.path.abspath(os.path.join(os.path.dirname( '__file__' ), '..', 'Datasets'))+'/'\n",
    "\n",
    "# Although the dataset says csv, it is tab delimited. In addition to this, they have severe codels problems. \n",
    "# So best to parse throught codes first. \n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfc in position 2: invalid start byte\n",
    "\n",
    "#open for reading with \"universal\" type set\n",
    "\n",
    "doc_d_t = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_target'+'.csv','rU','UTF-8') \n",
    "EUADR_drug_target = pd.read_csv(doc_d_t, sep='\\t', na_filter = False)\n",
    "EUADR_drug_target['CLASS'] = 'other'\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_target_disease'+'.csv','rU','UTF-8',errors='ignore') \n",
    "EUADR_target_disease = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "EUADR_target_disease['CLASS'] = 'gene_disease'\n",
    "       \n",
    "doc_d_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_disease'+'.csv','rU','UTF-8')                       \n",
    "EUADR_drug_disease = pd.read_csv(doc_d_d, sep='\\t', na_filter = False)\n",
    "EUADR_drug_disease['CLASS'] = 'other'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = EUADR_drug_target.append(EUADR_target_disease).append(EUADR_drug_disease)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(df[\"SENTENCE\"], embs, words, weight4ind)\n",
    "df[\"vector\"] = pd.Series(list(doc_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other', 'gene_disease']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    ground_truth[idx] = row['CLASS']\n",
    "\n",
    "categories = list(df[\"CLASS\"].unique())\n",
    "categories    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use LDA to get the topics and assign to class to find top performaning sentences\n",
    "\n",
    "min_text_length=80\n",
    "max_iter=150\n",
    "batch_size=512\n",
    "learning_offset=300.\n",
    "n_topics = len(categories)\n",
    "\n",
    "\n",
    "docs = df\n",
    "\n",
    "unclassifiable = list(docs[docs[\"SENTENCE\"].map(len) < min_text_length].index)\n",
    "filtered = docs[~docs.index.isin(unclassifiable)]\n",
    "ids = [d for d in list(filtered.index)[0:10]]\n",
    "\n",
    "n_features = 50000\n",
    "tf_vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_df=0.95,\n",
    "    min_df=0.1,\n",
    "    max_features=n_features)\n",
    "tf = tf_vectorizer.fit_transform(list(filtered.loc[:, 'SENTENCE']))\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    max_iter=max_iter,\n",
    "    batch_size=batch_size,\n",
    "    learning_method='online',\n",
    "    learning_offset=learning_offset,\n",
    "    random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "doc_topics = lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_leaders = {\"topic_{}\".format(i): [] for i in iter(range(n_topics))}\n",
    "doc_id = filtered.index\n",
    "\n",
    "for idx, probs in enumerate(doc_topics):\n",
    "    score = max(probs)\n",
    "    topic = np.argmax(probs)\n",
    "    doc_id = filtered.index[idx]\n",
    "    topic_leaders[\"topic_{}\".format(topic)].append({\"doc_id\": doc_id, \"score\": score})\n",
    "\n",
    "for i in iter(range(n_topics)):\n",
    "    topic_leaders[\"topic_{}\".format(i)] = sorted(\n",
    "        topic_leaders[\"topic_{}\".format(i)], key=itemgetter('score'), reverse=True)\n",
    "        \n",
    "    \n",
    "\n",
    "# topic_leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select only those sentences which have score more than 65%\n",
    "\n",
    "sentences = {c:[] for c in categories} \n",
    "selected_sentences = {c:[] for c in categories}\n",
    "sentences_with_score = {c:[] for c in categories}\n",
    "\n",
    "\n",
    "for each_topic in topic_leaders:\n",
    "    for each_doc in topic_leaders[each_topic]:\n",
    "        gt = ground_truth[each_doc['doc_id']]\n",
    "        sentences[gt].append(each_doc['doc_id'])\n",
    "        sentences_with_score[gt].append(each_doc['score'])\n",
    "#         print(each_doc['score'])\n",
    "        if each_doc['score']>0.66:\n",
    "             selected_sentences[gt].append(each_doc['doc_id'])\n",
    "    \n",
    "# selected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene_disease': array([  2.26870566e-01,   1.59295737e-01,   1.67848273e-01,\n",
       "          1.68088293e-01,   3.19782366e-01,  -2.61122644e-01,\n",
       "         -4.10503985e-01,   7.45768469e-02,   4.75212000e-01,\n",
       "          4.99350315e-04,   2.83911673e-02,   2.02528075e-01,\n",
       "         -3.10628164e-01,   4.83273800e-01,  -8.22246937e-03,\n",
       "         -1.17849019e-01,   2.77768774e-01,   3.05515428e-01,\n",
       "          6.31747180e-01,   3.05047933e-01,  -1.56340096e-01,\n",
       "         -1.37995032e-01,  -2.65361064e-01,  -1.87110943e-01,\n",
       "         -8.90708888e-02,   4.54369474e-01,   1.11236949e-01,\n",
       "          1.96965794e-01,   6.18862159e-01,   2.33794377e-01,\n",
       "          8.15756975e-01,   3.87161307e-01,   5.33904477e-02,\n",
       "         -1.00010579e-01,  -8.28008654e-02,  -2.30715544e-01,\n",
       "         -2.39405975e-01,  -6.26783999e-01,   9.47008441e-02,\n",
       "         -1.43448400e-01,   1.89181505e-02,  -2.56588831e-01,\n",
       "         -1.66810646e-01,  -1.57205745e-01,  -3.76705362e-01,\n",
       "         -1.91883665e-01,  -2.08621651e-01,  -1.16404971e-01,\n",
       "         -2.77303753e-01,   1.18059940e-01,   2.77384587e-01,\n",
       "         -1.29963386e-01,   9.27463564e-02,   1.21212776e-01,\n",
       "         -1.41856108e-01,  -3.90795662e-01,   8.87683172e-02,\n",
       "         -1.34551048e-01,  -6.67919094e-02,  -2.21223108e-01,\n",
       "          3.14782216e-01,  -4.41987518e-01,   6.82628104e-02,\n",
       "         -7.58021992e-02,   1.85854705e-01,  -4.83095850e-01,\n",
       "          2.79311231e-01,  -2.95066410e-01,   6.18590051e-01,\n",
       "          3.63978270e-01,   1.82930969e-01,  -3.91101860e-01,\n",
       "          3.49964447e-02,  -4.97641740e-01,  -4.16653374e-02,\n",
       "          7.61245509e-02,   2.75659627e-01,   1.32462132e-01,\n",
       "         -2.01481073e-01,   2.70366922e-01,   3.30726601e-01,\n",
       "         -3.10411187e-01,  -4.14045590e-01,   1.75497675e-01,\n",
       "         -8.86952716e-02,   2.46808635e-01,   2.83132503e-01,\n",
       "         -3.75660705e-01,  -2.32125326e-01,   3.65404834e-01,\n",
       "          1.31357953e-02,  -1.33710078e-01,  -5.57086022e-01,\n",
       "          1.52797373e-01,   3.70874798e-01,  -3.36366758e-01,\n",
       "          3.76633105e-01,   8.63850898e-01,   2.84331021e-01,\n",
       "          9.93740311e-02,   4.35676962e-01,   1.02119429e-01,\n",
       "          6.92963416e-02,  -2.51185782e-01,   6.61570442e-01,\n",
       "          1.10195134e-01,  -2.76538475e-03,   3.89963660e-01,\n",
       "         -2.51584480e-01,   9.80522498e-02,   1.87603351e-02,\n",
       "         -7.98666543e-02,  -5.22629933e-01,   6.86411129e-01,\n",
       "         -6.02026115e-01,   1.18641190e-01,  -1.15318298e-01,\n",
       "         -7.53496677e-02,  -6.54795272e-01,   2.08395919e-01,\n",
       "         -4.00864374e-01,   1.60094786e-01,   3.22543935e-01,\n",
       "          2.32951396e-01,   4.95917426e-01,  -8.36356976e-02,\n",
       "         -3.31236285e-01,   2.51787873e-01,   4.73279471e-03,\n",
       "          1.29119490e-01,  -5.75750629e-02,   4.15043004e-01,\n",
       "          2.70489471e-02,   2.08946884e-01,  -2.33312840e-01,\n",
       "         -2.00784203e-01,   5.37262224e-02,   2.22068270e-01,\n",
       "         -2.01385066e-01,  -4.69605609e-01,  -3.01907469e-01,\n",
       "          2.10810110e-01,   4.11168022e-01,   4.24258190e-04,\n",
       "          3.32490873e-01,  -1.57746498e-01,  -2.78582913e-01,\n",
       "         -2.30416764e-01,   2.50348293e-01,   1.41960672e-01,\n",
       "          8.13150367e-03,  -1.49808625e-01,   1.72562424e-01,\n",
       "         -8.22411400e-01,  -1.26332445e-02,   2.67641147e-01,\n",
       "          1.88804523e-01,  -3.12044985e-01,   8.64240565e-02,\n",
       "          2.59481504e-02,   9.64124370e-02,  -3.18878923e-01,\n",
       "         -2.93746196e-01,   5.24021347e-01,   4.53212654e-01,\n",
       "          1.88316262e-01,  -1.93854103e-01,   3.25539659e-01,\n",
       "         -7.67379147e-02,  -5.33176886e-01,   2.84465223e-01,\n",
       "          1.23533021e-01,  -6.59977055e-02,  -1.55596589e-01,\n",
       "         -1.38987444e-01,   1.57056817e-01,  -2.33768178e-01,\n",
       "          3.13640719e-01,  -1.02203511e-01,  -2.70809635e-02,\n",
       "          3.50108938e-01,  -4.08417414e-01,   4.57041063e-01,\n",
       "         -9.18473512e-02,  -1.34283603e-01,  -3.70096949e-01,\n",
       "         -8.01576638e-02,   4.48013191e-01,  -1.86879855e-01,\n",
       "          3.44760037e-01,  -3.44834613e-02,   1.09151936e-01,\n",
       "         -5.60836943e-01,   1.96473085e-01,   2.23087629e-01,\n",
       "         -3.05620827e-01,  -2.25219261e-01,  -2.06028791e-01,\n",
       "          2.58349405e-01,  -1.16793304e-01]),\n",
       " 'other': array([ 0.44772258,  0.35682758,  0.12904875,  0.3338336 , -0.11838816,\n",
       "         0.33670812, -0.18741038,  0.16895675,  0.16143141, -0.76070755,\n",
       "        -0.06922217, -0.0929399 , -0.32899155,  0.23862066, -0.18818248,\n",
       "        -0.42599845,  0.4846198 , -0.06441014,  0.05596165,  0.10202391,\n",
       "        -0.40933927,  0.03996687, -0.49782696,  0.29455452, -0.08448427,\n",
       "        -0.22911757, -0.49404045,  0.04393435,  0.18823207,  0.1905789 ,\n",
       "         0.5382378 ,  0.62805266,  0.24734626,  0.15183749, -0.05355631,\n",
       "        -0.33047156,  0.15108733, -0.29010683,  0.06125607,  0.13091899,\n",
       "        -0.30124744,  0.07933018, -0.29829348, -0.06350818, -0.20652323,\n",
       "         0.47757154,  0.64960352,  0.46861958, -0.50547982,  0.1932453 ,\n",
       "         0.38210305,  0.23877746,  0.03952139, -0.12490206,  0.33445655,\n",
       "         0.03097267,  0.1533126 , -0.2303432 , -0.41454862,  0.14515354,\n",
       "        -0.09085539, -0.43318033,  0.44763477,  0.2248612 ,  0.26091083,\n",
       "        -0.08589477, -0.32209729, -0.54083423, -0.09444692,  0.50539111,\n",
       "        -0.00855926, -0.44072127, -0.26678989, -0.11738903,  0.1836007 ,\n",
       "         0.282414  ,  0.1155934 ,  0.21110844, -0.16135033,  0.34218522,\n",
       "         0.07762504, -0.67162677,  0.20089617, -0.00823105, -0.30878637,\n",
       "         0.24540152,  0.05330306, -0.42549845, -0.35370453,  0.51820324,\n",
       "        -0.86967703,  0.08398166, -0.27289858,  0.31934045, -0.19565888,\n",
       "         0.10224057,  0.00540081,  0.43992076, -0.47470271,  0.4427907 ,\n",
       "         0.38937534, -0.12604051, -0.20010651, -0.77760898,  0.2578165 ,\n",
       "         0.11182667,  0.37953329,  0.15276131, -0.23853678,  0.58194193,\n",
       "         0.68348944,  0.06198933, -0.13386213,  0.5177222 , -0.16315241,\n",
       "         0.09560578,  0.56707136,  0.12781442, -0.03973017,  0.1432139 ,\n",
       "         0.19475526,  0.34384704,  0.1405583 ,  0.199658  , -0.05471572,\n",
       "        -0.20843486,  0.36853469,  0.01103616, -0.27090618, -0.36605831,\n",
       "         0.56547552,  0.24254406,  0.27506047, -0.09611449,  0.18961085,\n",
       "         0.12257289, -0.13317812,  0.41270137, -0.15737885, -0.52583277,\n",
       "         0.59984291,  0.1881324 ,  0.4634513 ,  0.69537675,  0.19698616,\n",
       "        -0.25822203,  0.35191443, -0.20167593,  0.58130468, -0.27820288,\n",
       "        -0.13683728, -0.70638193, -0.31802531, -0.59552259,  0.03405379,\n",
       "        -0.06022355, -0.066599  ,  0.15948278,  0.3937086 ,  0.30569202,\n",
       "        -0.16910102, -0.34830033, -0.04384716,  0.08713182,  0.01667072,\n",
       "        -0.48623974,  0.45751218, -0.18905935, -0.38692893, -0.22075265,\n",
       "        -0.02256446, -0.06377369,  0.45020204, -0.48631954, -0.62205466,\n",
       "         0.24261368, -0.25347173,  0.33888522,  0.46787502, -0.41130642,\n",
       "         0.31082874, -0.34267432,  0.01824271, -0.40768662, -0.26181042,\n",
       "        -0.3394989 ,  0.02848539,  0.06286148, -0.27103804, -0.01487246,\n",
       "        -0.34695241,  0.07803307, -0.47490297, -0.60506181,  0.18907543,\n",
       "        -0.38470162,  0.30604111,  0.10978588, -0.30247727,  0.163164  ])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average/mean of the sentence vectors that represent our topics \n",
    "category_vecs = {}\n",
    "for c in categories:\n",
    "    vectors = np.asarray(list(df.loc[df.index.isin(selected_sentences[c])].vector))\n",
    "    category_vecs[c] = np.mean(vectors, axis=0)\n",
    "\n",
    "    \n",
    "category_vecs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to predict the label of unknown sentences\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "selected_idx = [j for i in selected_sentences.values() for j in i]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx in selected_idx:\n",
    "        max_sim = 0\n",
    "        winner = 'other'\n",
    "        for j in category_vecs:\n",
    "            sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "                winner = j\n",
    "        predictions[idx] = winner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87189278783481672"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_score(predictions, truth_dict):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    mis_classified = []\n",
    "    mis_pred = []\n",
    "    \n",
    "    for k,v in predictions.items():\n",
    "        preds.append(v)\n",
    "        labels.append(truth_dict[k])\n",
    "        if v!=truth_dict[k]:\n",
    "#             print(str(v) + '--x--' + str(truth_dict[k]))\n",
    "            mis_pred.append(str(v))\n",
    "            mis_classified.append(k)\n",
    "\n",
    "    return f1_score(labels, preds, average='weighted'), mis_classified, mis_pred\n",
    "\n",
    "\n",
    "score, miss_classified_df, miss_pred = get_accuracy_score(predictions, ground_truth)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "miss_calssified_df = df.iloc[miss_classified_df , [12,13]] \n",
    "miss_calssified_df['Predicted-CLASS'] = miss_pred\n",
    "# miss_calssified_df\n",
    "\n",
    "result_path = os.path.abspath(os.path.join(os.path.dirname( '__file__' ), '..', 'Results'))+'/'\n",
    "miss_calssified_df.to_csv(result_path+'miss_predictions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generalisation on the Unseen Dataset GAD\n",
    "\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'GAD_Corpus_IBIgroup/'+'GAD_Y_N'+'.csv','rU','UTF-8',errors='ignore') \n",
    "GAD_target_disease = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "GAD_target_disease['CLASS'] = 'gene_disease'\n",
    "\n",
    "\n",
    "# GAD_target_disease.head(10)\n",
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(GAD_target_disease[\"GAD_CONCLUSION\"], embs, words, weight4ind)\n",
    "GAD_target_disease[\"vector\"] = pd.Series(list(doc_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synoptica/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99081246622230235"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAD_test_ground_truth = {}\n",
    "\n",
    "for idx, row in GAD_target_disease.iterrows():\n",
    "    GAD_test_ground_truth[idx] = row['CLASS']\n",
    "    \n",
    "# Try to predict the label of unknown sentences\n",
    "\n",
    "GAD_test_predictions = {}\n",
    "\n",
    "for idx, row in GAD_target_disease.iterrows():\n",
    "    max_sim = 0.00\n",
    "    winner = 'other'\n",
    "    for j in category_vecs:\n",
    "        sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            winner = j\n",
    "    GAD_test_predictions[idx] = winner   \n",
    "    \n",
    "    \n",
    "GAD_score, GAD_miss_classified, GAD_miss_pred = get_accuracy_score(GAD_test_predictions, GAD_test_ground_truth)\n",
    "GAD_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miss_calssified_GAD_test = GAD_target_disease.iloc[GAD_miss_classified , [10,11]] \n",
    "miss_calssified_GAD_test['Predicted-CLASS'] = GAD_miss_pred\n",
    "# miss_calssified_df_test\n",
    "miss_calssified_GAD_test.to_csv(result_path+'miss_predictions_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene_disease': 0.38856808612462623, 'other': -0.11055105143789226}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test new sentence\n",
    "\n",
    "test_sample = 'This study assessed associations between the CYP4F2 gene and myocardial infarction (MI), using a haplotype-based case-control study of 234 MI patients and 248 controls genotyped for 5 single-nucleotide polymorphisms (rs3093105, rs3093135, rs1558139, rs2108622, rs3093200).'\n",
    "# test_sample = 'Assessment of 1177 human immunodeficiency virus (HIV) resistance genotypes at an HIV/AIDS clinic showed a decrease in the incidence of the K65R mutation, from 15.2% of isolates during the period 2002-2004 to 2.7% of isolates during the period 2005-2006 (P < .001), despite elevated and stable rates of tenofovir use.'\n",
    "# test_sample = 'Doxorubicin-induced DNA damage was also specifically abolished by the proteasome inhibitors bortezomib and MG132 and much reduced in top2beta(-/-) mouse embryonic fibroblasts (MEF) compared with TOP2beta(+/+) MEFs, suggesting the involvement of proteasome and DNA topoisomerase IIbeta (Top2beta).'\n",
    "# test_sample = 'SLC9A6 at Xq26.3 (Gilfillan et al., 2008)X-linked mental retardation'\n",
    "# test_sample = 'DLBCL was identified by a microenvironment gene expression signature and is associated with increased expression of inflammatory mediators, such as multiple components of the T-cell receptor (TCR), molecules associated with T/NK-cell activation and the complement cascade, downstream targets of IFNγ'\n",
    "\n",
    "test_embedding = sif_embedding_wrapper.sentences2vecs([test_sample], embs, words, weight4ind)\n",
    "\n",
    "sim = {}\n",
    "for j in category_vecs:\n",
    "    sim[j] = cosine_similarity(test_embedding.reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "\n",
    "sim    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on the 30 papers dataset\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open(data_path+'EBI Standard/'+'rel_data_bronze.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "EBI_standard = []\n",
    "\n",
    "for each_point in data:\n",
    "    for each_sent in data[each_point]:\n",
    "        EBI_standard.append({'SENTENCE': each_sent['sent'], 'CLASS': each_sent['rel']})    \n",
    "        \n",
    "EBI_standard_temp = pd.DataFrame(EBI_standard)   \n",
    "\n",
    "EBI_standard_temp['CLASS'] = EBI_standard_temp['CLASS'].apply(lambda x: x.replace('YGD', 'gene_disease').replace('NGD', 'other').replace('AMB', 'other'))\n",
    "EBI_standard_temp.to_csv(data_path+'EBI_bronze_standard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70855977757182564"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(EBI_standard_temp[\"SENTENCE\"], embs, words, weight4ind)\n",
    "EBI_standard_temp[\"vector\"] = pd.Series(list(doc_embeddings))\n",
    "\n",
    "\n",
    "EBI_test_ground_truth = {}\n",
    "\n",
    "for idx, row in EBI_standard_temp.iterrows():\n",
    "    EBI_test_ground_truth[idx] = row['CLASS']\n",
    "    \n",
    "# Try to predict the label of unknown sentences\n",
    "\n",
    "EBI_test_predictions = {}\n",
    "\n",
    "for idx, row in EBI_standard_temp.iterrows():\n",
    "    max_sim = 0.00\n",
    "    winner = 'other'\n",
    "    for j in category_vecs:\n",
    "        sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            winner = j\n",
    "    EBI_test_predictions[idx] = winner    \n",
    "    \n",
    "\n",
    "EBI_score, EBI_miss_classified, EBI_miss_pred = get_accuracy_score(EBI_test_predictions, EBI_test_ground_truth)\n",
    "EBI_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_calssified_EBI_test = EBI_standard_temp.iloc[EBI_miss_classified , [0,1]] \n",
    "miss_calssified_EBI_test['Predicted-CLASS'] = EBI_miss_pred\n",
    "miss_calssified_EBI_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get PolySearch dataset\n",
    "ColNames = ['entity_1', 'entity_2', 'Association', 'PMID','Sentence']\n",
    "\n",
    "Poly_doc_d_t = codecs.open(data_path+'PolySearch/'+'p1_disease_gene_testset.simple'+'.tsv','rU','UTF-8') \n",
    "Poly_target_disease = pd.read_csv(Poly_doc_d_t, sep='\\t', na_filter = False, names = ColNames)\n",
    "Poly_target_disease['CLASS'] = 'gene_disease'\n",
    "\n",
    "doc_embeddings = sif_embedding_wrapper.sentences2vecs(Poly_target_disease[\"Sentence\"], embs, words, weight4ind)\n",
    "Poly_target_disease[\"vector\"] = pd.Series(list(doc_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Poly_test_ground_truth = {}\n",
    "\n",
    "for idx, row in Poly_target_disease.iterrows():\n",
    "    Poly_test_ground_truth[idx] = row['CLASS']\n",
    "    \n",
    "# Try to predict the label of unknown sentences\n",
    "\n",
    "Poly_test_predictions = {}\n",
    "\n",
    "for idx, row in Poly_target_disease.iterrows():\n",
    "    max_sim = 0.00\n",
    "    winner = 'other'\n",
    "    for j in category_vecs:\n",
    "        sim = cosine_similarity(row[\"vector\"].reshape(1, -1), category_vecs[j].reshape(1, -1)).flatten()[0]\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            winner = j\n",
    "    Poly_test_predictions[idx] = winner   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synoptica/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82432432432432434"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_score(predictions, truth_dict):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    mis_classified = []\n",
    "    mis_pred = []\n",
    "    \n",
    "    for k,v in predictions.items():\n",
    "        preds.append(v)\n",
    "        labels.append(truth_dict[k])\n",
    "        if v!=truth_dict[k]:\n",
    "#             print(str(v) + '--x--' + str(truth_dict[k]))\n",
    "            mis_classified.append(k)\n",
    "            mis_pred.append(str(v))\n",
    "\n",
    "    return f1_score(labels, preds, average='weighted'), mis_classified, mis_pred\n",
    "\n",
    "\n",
    "score, miss_classified, miss_pred = get_accuracy_score(Poly_test_predictions, Poly_test_ground_truth)\n",
    "score    \n",
    "# test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_calssified_Poly_test = Poly_target_disease.loc[Poly_miss_classified,['Sentence', 'CLASS']]\n",
    "miss_calssified_Poly_test['Predicted-CLASS'] = Poly_miss_pred\n",
    "miss_calssified_Poly_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
