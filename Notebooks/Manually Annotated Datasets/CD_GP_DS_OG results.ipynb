{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capo_tools_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/nfs/gns/literature/machine-learning/Santosh/Gitlab/biobertepmc/predictions/test_predictions_clean_CD_GP_DS_OG_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17957/17957 [00:06<00:00, 2826.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert to IOB format\n",
    "\n",
    "\n",
    "\n",
    "capo_tools_lib.ml_tagged_sentences_to_IOB(path, path,'results_test_IOB.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics.ner as ner_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ GP ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      5,582     5,582     5,582     5,761\n",
      " incorrect        179       179         0         0\n",
      "   partial          0         0       179         0\n",
      "   missing        824       824       824       824\n",
      "  spurious        602       602       602       602\n",
      "====================================================\n",
      " precision       0.88      0.88      0.89      0.91\n",
      "    recall       0.85      0.85      0.86      0.87\n",
      "  f1 score       0.86      0.86      0.88      0.89\n",
      "====================================================\n",
      "Gold Total      6,566\n",
      "Resp Total      6,351\n",
      "\n",
      "\n",
      "############ DS ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      1,790     1,790     1,790     1,880\n",
      " incorrect         90        90         0         0\n",
      "   partial          0         0        90         0\n",
      "   missing        473       473       473       473\n",
      "  spurious        203       203       203       203\n",
      "====================================================\n",
      " precision       0.86      0.86      0.88      0.90\n",
      "    recall       0.76      0.76      0.78      0.80\n",
      "  f1 score       0.81      0.81      0.83      0.85\n",
      "====================================================\n",
      "Gold Total      2,347\n",
      "Resp Total      2,082\n",
      "\n",
      "\n",
      "############ OG ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      2,569     2,569     2,569     2,737\n",
      " incorrect        168       168         0         0\n",
      "   partial          0         0       168         0\n",
      "   missing        438       438       438       438\n",
      "  spurious        197       197       197       197\n",
      "====================================================\n",
      " precision       0.88      0.88      0.90      0.93\n",
      "    recall       0.81      0.81      0.84      0.86\n",
      "  f1 score       0.84      0.84      0.87      0.90\n",
      "====================================================\n",
      "Gold Total      3,157\n",
      "Resp Total      2,921\n",
      "\n",
      "\n",
      "############ CD ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      1,125     1,125     1,125     1,142\n",
      " incorrect         17        17         0         0\n",
      "   partial          0         0        17         0\n",
      "   missing         94        94        94        94\n",
      "  spurious        113       113       113       113\n",
      "====================================================\n",
      " precision       0.90      0.90      0.90      0.91\n",
      "    recall       0.91      0.91      0.92      0.92\n",
      "  f1 score       0.90      0.90      0.91      0.92\n",
      "====================================================\n",
      "Gold Total      1,236\n",
      "Resp Total      1,255\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_path = '/nfs/gns/literature/machine-learning/'\n",
    "epmc_path = root_path+'Datasets/NER_Datasets/GP-DS-OG-CD-Santosh/test.tsv'\n",
    "all_tags = ['GP', 'DS', 'OG', 'CD']\n",
    "\n",
    "ml_path = root_path + 'Santosh/Gitlab/biobertepmc/predictions/test_predictions_clean_CD_GP_DS_OG_test.csvresults_test_IOB.tsv'\n",
    "for each_tag in all_tags:\n",
    "    print('############ '+each_tag+' ####################')\n",
    "    print('\\n')\n",
    "    print(ner_metrics.semeval_report(gold_path=epmc_path, response_path=ml_path, targets=[each_tag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               strict     exact   partial      type\n",
      "\n",
      "   correct     11,066    11,096    11,096    11,520\n",
      " incorrect        505       475         0        51\n",
      "   partial          0         0       475         0\n",
      "   missing      1,786     1,786     1,786     1,786\n",
      "  spurious      1,067     1,067     1,067     1,067\n",
      "====================================================\n",
      " precision       0.88      0.88      0.90      0.91\n",
      "    recall       0.83      0.83      0.85      0.86\n",
      "  f1 score       0.85      0.85      0.87      0.89\n",
      "====================================================\n",
      "Gold Total     13,306\n",
      "Resp Total     12,609\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ner_metrics.semeval_report(gold_path=epmc_path, response_path=ml_path, targets=all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scispcacy",
   "language": "python",
   "name": "scispcacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
