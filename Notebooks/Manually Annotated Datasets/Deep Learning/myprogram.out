nohup: ignoring input
2019-11-14 19:20:43,112 Reading data from /nfs/gns/literature/machine-learning/Datasets/NER_Datasets/EBI_standard-IOB
2019-11-14 19:20:43,112 Train: /nfs/gns/literature/machine-learning/Datasets/NER_Datasets/EBI_standard-IOB/train.csv
2019-11-14 19:20:43,112 Dev: /nfs/gns/literature/machine-learning/Datasets/NER_Datasets/EBI_standard-IOB/dev.csv
2019-11-14 19:20:43,112 Test: /nfs/gns/literature/machine-learning/Datasets/NER_Datasets/EBI_standard-IOB/test.csv
[b'<unk>', b'O', b'B-OG', b'B-DS', b'B-GP', b'<START>', b'<STOP>']
2019-11-14 19:21:42,589 ----------------------------------------------------------------------------------------------------
2019-11-14 19:21:42,589 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.5)
          (encoder): Embedding(275, 200)
          (rnn): LSTM(200, 1150, num_layers=3, dropout=0.5)
          (decoder): Linear(in_features=1150, out_features=275, bias=True)
        )
      )
    )
    (list_embedding_1): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.5)
          (encoder): Embedding(275, 200)
          (rnn): LSTM(200, 1150, num_layers=3, dropout=0.5)
          (decoder): Linear(in_features=1150, out_features=275, bias=True)
        )
      )
    )
    (list_embedding_2): ELMoEmbeddings(model=elmo-pubmed)
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=7672, out_features=7672, bias=True)
  (rnn): LSTM(7672, 256, bidirectional=True)
  (linear): Linear(in_features=512, out_features=7, bias=True)
)"
2019-11-14 19:21:42,589 ----------------------------------------------------------------------------------------------------
2019-11-14 19:21:42,590 Corpus: "Corpus: 79401 train + 16068 dev + 17680 test sentences"
2019-11-14 19:21:42,590 ----------------------------------------------------------------------------------------------------
2019-11-14 19:21:42,590 Parameters:
2019-11-14 19:21:42,590  - learning_rate: "0.1"
2019-11-14 19:21:42,590  - mini_batch_size: "16"
2019-11-14 19:21:42,590  - patience: "3"
2019-11-14 19:21:42,590  - anneal_factor: "0.5"
2019-11-14 19:21:42,590  - max_epochs: "150"
2019-11-14 19:21:42,590  - shuffle: "True"
2019-11-14 19:21:42,590  - train_with_dev: "False"
2019-11-14 19:21:42,590 ----------------------------------------------------------------------------------------------------
2019-11-14 19:21:42,590 Model training base path: "/nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/multi_bio_ner_model/EBI/300/v1"
2019-11-14 19:21:42,590 ----------------------------------------------------------------------------------------------------
2019-11-14 19:21:42,590 Device: cuda:0
2019-11-14 19:21:42,590 ----------------------------------------------------------------------------------------------------
2019-11-14 19:21:42,590 Embeddings storage mode: cpu
2019-11-14 19:21:42,597 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2019-11-14 19:21:43,129 epoch 1 - iter 0/4963 - loss 30.95641136 - samples/sec: 15040.16
2019-11-14 19:29:22,306 epoch 1 - iter 496/4963 - loss 1.01087848 - samples/sec: 17.33
2019-11-14 19:36:48,757 epoch 1 - iter 992/4963 - loss 0.83660501 - samples/sec: 17.80
2019-11-14 19:44:17,060 epoch 1 - iter 1488/4963 - loss 0.76678112 - samples/sec: 17.73
2019-11-14 19:51:50,642 epoch 1 - iter 1984/4963 - loss 0.72503837 - samples/sec: 17.53
2019-11-14 19:59:20,415 epoch 1 - iter 2480/4963 - loss 0.69208173 - samples/sec: 17.67
2019-11-14 20:06:50,518 epoch 1 - iter 2976/4963 - loss 0.66673087 - samples/sec: 17.65
2019-11-14 20:14:57,614 epoch 1 - iter 3472/4963 - loss 0.64023343 - samples/sec: 16.32
2019-11-14 20:22:59,308 epoch 1 - iter 3968/4963 - loss 0.62955124 - samples/sec: 16.50
2019-11-14 20:30:49,592 epoch 1 - iter 4464/4963 - loss 0.61801777 - samples/sec: 16.90
2019-11-14 20:38:40,720 epoch 1 - iter 4960/4963 - loss 0.60424209 - samples/sec: 16.87
2019-11-14 20:38:43,267 ----------------------------------------------------------------------------------------------------
2019-11-14 20:38:43,267 EPOCH 1 done: loss 0.6042 - lr 0.1000
2019-11-14 20:43:36,512 ----------------------------------------------------------------------------------------------------
2019-11-14 20:43:36,512 Exiting from training early.
2019-11-14 20:43:36,512 Saving model ...
