{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import random\n",
    "import sys\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import multiprocessing\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# url = 'http://ai-capo-api-lb/spaCy_ner_predictor?text_sentence='  # Load Balancer\n",
    "\n",
    "result_path = '/mnt/droplet/nfs/gns/literature/machine-learning/evaluation/FP_Analysis/SpaCy/model_call/'\n",
    "pathlib.Path(result_path).mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /mnt/droplet/nfs/gns/literature/Santosh_Tirunagari/GitHub/spacy_models/pretrain_exp/best/\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import util\n",
    "best_model_path = '/mnt/droplet/nfs/gns/literature/Santosh_Tirunagari/GitHub/spacy_models/pretrain_exp/best/'\n",
    "\n",
    "print(\"Loading from\", best_model_path)\n",
    "nlp2 = util.load_model_from_path(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_EPMC_text = '/mnt/droplet/nfs/gns/literature/machine-learning/evaluation/300articles/europePMC-NER/annotations_API/full_sentences/test_annotations/Europe_PMC_annotation.csv'\n",
    "colNames = ['pmc_id', 'section', 'sentence','ner'] \n",
    "    \n",
    "test_df = pd.read_csv(path_EPMC_text,sep ='\\t', names=colNames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def deleting_epmc_GPS(list_1,del_name):\n",
    "   \n",
    "    for sub_list in list_1:\n",
    "        if del_name in sub_list:\n",
    "            list_1.remove(sub_list)\n",
    "    return list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def remove_FP(epmc_list, ml_json):\n",
    "    all_ml_gps = []\n",
    "    if ml_json['annotations']:\n",
    "        for each_ml_annotation in ml_json['annotations']:\n",
    "            if each_ml_annotation[2] == 'GP':\n",
    "                all_ml_gps.append(each_ml_annotation[3])\n",
    "    \n",
    "    non_FP_removed =[]\n",
    "              \n",
    "\n",
    "    for each_ner in epmc_list:\n",
    "        if each_ner[2] == 'Gene_Proteins':\n",
    "            for each_ml_gp in all_ml_gps:         \n",
    "                score = fuzz.token_set_ratio(each_ml_gp, each_ner[1])\n",
    "                if score == 100:\n",
    "                    non_FP_removed.append(each_ner)\n",
    "\n",
    "    non_gp_tags =  deleting_epmc_GPS(epmc_list,'Gene_Proteins')  \n",
    "\n",
    "    fp_removed_tags = non_gp_tags+non_FP_removed\n",
    "\n",
    "    return fp_removed_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_annotations(text_sentence):\n",
    "    data_dict ={}\n",
    "    doc = nlp2(text_sentence)\n",
    "    terms_entities = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        terms_entities.append(\n",
    "            [ent.start_char, ent.end_char, ent.label_, ent.text])\n",
    "    \n",
    "    data_dict['annotations'] = terms_entities\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17957/17957 [00:48<00:00, 368.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "with open(result_path + 'spacy_fp_removal_80.tsv', 'w', newline='\\n') as f1:\n",
    "    public_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "    \n",
    "    for index,row in tqdm(test_df.iterrows(),total = len(test_df)):\n",
    "        try:\n",
    "            ml_annotations = get_spacy_annotations(row['sentence'])\n",
    "            fp_removed = remove_FP(literal_eval(row['ner']), ml_annotations)\n",
    "        except ValueError:\n",
    "            fp_removed =''\n",
    "            \n",
    "        public_writer.writerow([row['pmc_id'], row['section'],row['sentence'], fp_removed])   \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to IOB format\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sys.path.append('/mnt/droplet/nfs/gns/literature/Santosh_Tirunagari/test Gitlab/epmc-ml-misc-library/')\n",
    "\n",
    "import capo_tools_lib\n",
    "import evaluation_epmc_lib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17957/17957 [00:03<00:00, 5244.33it/s]\n"
     ]
    }
   ],
   "source": [
    "iob_result_path = result_path+'iob/'\n",
    "pathlib.Path(iob_result_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_path = result_path + 'spacy_fp_removal_80.tsv'\n",
    "capo_tools_lib.annotations_api_tagged_sentences_to_IOB(file_path,\n",
    "                                                       iob_result_path,'spacy_fp_removal_iob.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Annotation Pipeline Results ########################\n",
      "############ GP ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      2,986     2,986     2,986     3,129\n",
      " incorrect        143       143         0         0\n",
      "   partial          0         0       143         0\n",
      "   missing      3,440     3,440     3,440     3,440\n",
      "  spurious        530       530       530       530\n",
      "====================================================\n",
      " precision       0.82      0.82      0.84      0.86\n",
      "    recall       0.45      0.45      0.47      0.48\n",
      "  f1 score       0.58      0.58      0.60      0.61\n",
      "====================================================\n",
      "Gold Total      6,566\n",
      "Resp Total      3,659\n",
      "\n",
      "\n",
      "############ DS ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      1,095     1,095     1,095     1,215\n",
      " incorrect        120       120         0         0\n",
      "   partial          0         0       120         0\n",
      "   missing      1,135     1,135     1,135     1,135\n",
      "  spurious        449       449       449       449\n",
      "====================================================\n",
      " precision       0.66      0.66      0.69      0.73\n",
      "    recall       0.47      0.47      0.49      0.52\n",
      "  f1 score       0.55      0.55      0.58      0.61\n",
      "====================================================\n",
      "Gold Total      2,347\n",
      "Resp Total      1,664\n",
      "\n",
      "\n",
      "############ OG ####################\n",
      "\n",
      "\n",
      "               strict     exact   partial      type\n",
      "\n",
      "   correct      2,215     2,215     2,215     2,459\n",
      " incorrect        244       244         0         0\n",
      "   partial          0         0       244         0\n",
      "   missing        714       714       714       714\n",
      "  spurious        239       239       239       239\n",
      "====================================================\n",
      " precision       0.82      0.82      0.87      0.91\n",
      "    recall       0.70      0.70      0.74      0.77\n",
      "  f1 score       0.75      0.75      0.80      0.84\n",
      "====================================================\n",
      "Gold Total      3,157\n",
      "Resp Total      2,698\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import metrics.ner as ner_metrics\n",
    "\n",
    "\n",
    "# precision\t0.7\t0.7\t0.72\t0.73\n",
    "# recall\t0.53\t0.53\t0.54\t0.55\n",
    "# f1 score\t0.6\t0.6\t0.62\t0.6\n",
    "\n",
    "#\n",
    "# print(ner_metrics.semeval_scores_report(gold=epmc_labels, response=ml_labels, digits=2))\n",
    "\n",
    "root_path = '/mnt/droplet/nfs/gns/literature/machine-learning/'\n",
    "epmc_path = root_path+'Datasets/NER_Datasets/EBI_standard-IOB/test.csv'\n",
    "all_tags = ['GP', 'DS', 'OG']\n",
    "\n",
    "print('################ Annotation Pipeline Results ########################')\n",
    "CAPO_path = iob_result_path+'spacy_fp_removal_iob.tsv'\n",
    "for each_tag in all_tags:\n",
    "    print('############ '+each_tag+' ####################')\n",
    "    print('\\n')\n",
    "    print(ner_metrics.semeval_report(gold_path=epmc_path, response_path=CAPO_path, targets=[each_tag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scispcacy",
   "language": "python",
   "name": "scispcacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
