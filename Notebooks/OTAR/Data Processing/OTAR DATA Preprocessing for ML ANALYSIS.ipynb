{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to parallel process OTAR json file to extract sentences and entities\n",
    "# (c) EMBL-EBI, June 2019\n",
    "#\n",
    "# Started: 7 June 2019\n",
    "# Updated: 29 January  2020\n",
    "\n",
    "_author_ = 'Santosh Tirunagari'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import csv\n",
    "\n",
    "import glob\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     pool = multiprocessing.Pool(processes=15)\n",
    "#     pool.map(process_each_split_to_extract_sentences, file_path)\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#     print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_each_split_to_extract_sentences(complete_file_path):\n",
    "\n",
    "    colNames = ['pmcid', 'section', 't_start', 't_end', 'd_start', 'd_end', 'text']\n",
    "    OTAR_df = pd.read_csv(complete_file_path, names=colNames, encoding='utf-8')\n",
    "    f_name = complete_file_path.split('/')[-1]\n",
    "    \n",
    "    with open(result_folder + f_name+ '.csv', 'w', newline='\\n') as f1:\n",
    "        public_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "\n",
    "\n",
    "        for index_, each_annotation in enumerate(OTAR_df.itertuples()): #tqdm(enumerate(OTAR_df.itertuples()),total=len(OTAR_df)):\n",
    "#         if index_ <10:\n",
    "            pmc_id = each_annotation.pmcid.replace('http://europepmc.org/','')\n",
    "            section = each_annotation.section\n",
    "            t_start = each_annotation.t_start\n",
    "            t_end = each_annotation.t_end\n",
    "            d_start = each_annotation.d_start\n",
    "            d_end = each_annotation.d_end\n",
    "            otar_sentence = each_annotation.text\n",
    "            GP = otar_sentence[t_start:t_end+1]\n",
    "            DS = otar_sentence[d_start:d_end+1]\n",
    "\n",
    "            try:\n",
    "                GP.encode('latin_1').decode('utf-8').strip()  # Each char is a Unicode codepoint.\n",
    "            except:\n",
    "                re.sub(r'[^\\x00-\\x7f]', r'', GP).strip()\n",
    "                \n",
    "            try:\n",
    "                DS.encode('latin_1').decode('utf-8').strip()  # Each char is a Unicode codepoint.\n",
    "            except:\n",
    "                re.sub(r'[^\\x00-\\x7f]', r'', DS).strip()    \n",
    "\n",
    "\n",
    "            new_row = [pmc_id, section, otar_sentence, GP,DS]\n",
    "            public_writer.writerows([new_row])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/nfs/gns/literature/Santosh_Tirunagari/OTAR_dumps/CSV_dumps/' #Toy\n",
    "result_folder = '/nfs/gns/literature/Santosh_Tirunagari/OTAR_Results/ML-NER-Analysis/Data/'\n",
    "\n",
    "split_list = sorted(glob.glob(os.path.join(file_path, '*split*'))) \n",
    "\n",
    "for each_file in tqdm(split_list, total = len(split_list)):\n",
    "    process_each_split_to_extract_sentences(each_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the GPs and DS for the same OTAR sentence\n",
    "\n",
    "def merge_GP_DS_in_sentences(complete_file_path):\n",
    "    \n",
    "#     GP_final_result_folder = '/nfs/gns/literature/Santosh_Tirunagari/OTAR_Results/ML-NER-Analysis/Final_data/GP/'\n",
    "#     DS_final_result_folder = '/nfs/gns/literature/Santosh_Tirunagari/OTAR_Results/ML-NER-Analysis/Final_data/DS/'\n",
    "    \n",
    "    final_result_folder = '/nfs/gns/literature/Santosh_Tirunagari/OTAR_Results/ML-NER-Analysis/Final_data/'\n",
    "    colNames = ['pmcid', 'section', 'sentence', 'GP', 'DS']\n",
    "    \n",
    "    OTAR_df = pd.read_csv(complete_file_path, names=colNames, encoding='utf-8', sep='\\t')\n",
    "    f_name = complete_file_path.split('/')[-1]\n",
    "    \n",
    " \n",
    "    GP_df = OTAR_df['GP'].groupby([OTAR_df.pmcid, OTAR_df.section, OTAR_df.sentence]).apply(list).reset_index()\n",
    "#     GP_df.to_csv(GP_final_result_folder+f_name+, sep='\\t')\n",
    "    \n",
    "    DS_df = OTAR_df['DS'].groupby([OTAR_df.pmcid, OTAR_df.section, OTAR_df.sentence]).apply(list).reset_index()\n",
    "#     DS_df.to_csv(DS_final_result_folder+f_name+, sep='\\t')\n",
    "    \n",
    "    source_df = pd.merge(GP_df, DS_df[['sentence','DS']], on='sentence')\n",
    "    df = source_df.drop_duplicates(subset=['sentence'])\n",
    "    \n",
    "    df.to_csv(final_result_folder+f_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [36:14<00:00, 10.87s/it]\n"
     ]
    }
   ],
   "source": [
    "intermediate_file_path = '/nfs/gns/literature/Santosh_Tirunagari/OTAR_Results/ML-NER-Analysis/Intermediate_data/'\n",
    "\n",
    "split_list = sorted(glob.glob(os.path.join(intermediate_file_path, '*split*'))) \n",
    "\n",
    "for each_file in tqdm(split_list, total = len(split_list)):\n",
    "    merge_GP_DS_in_sentences(each_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP_df = OTAR_df['GP'].groupby([OTAR_df.pmcid, OTAR_df.section, OTAR_df.sentence]).apply(list).reset_index()\n",
    "# DS_df = OTAR_df['DS'].groupby([OTAR_df.pmcid, OTAR_df.section, OTAR_df.sentence]).apply(list).reset_index()\n",
    "# df = pd.merge(GP_df, DS_df[['sentence','DS']], on='sentence')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
