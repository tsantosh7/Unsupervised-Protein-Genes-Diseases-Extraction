{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, WordPunctTokenizer\n",
    "from typing import List\n",
    "\n",
    "from flair.data import Sentence, Token\n",
    "from flair.models import SequenceTagger\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 18:20:55,582 loading file /nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/manual_annotated_dataset/only_flair_embeddings/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "flair_model = SequenceTagger.load('/nfs/gns/literature/Santosh_Tirunagari/GitHub/flair_models/ner/manual_annotated_dataset/only_flair_embeddings/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text: str) -> List[Token]:\n",
    "    \"\"\"\n",
    "    Tokenizer based on word and punctuations only.\n",
    "    \"\"\"\n",
    "    tokens: List[Token] = []\n",
    "\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "\n",
    "    text = tokenizer.tokenize(text)\n",
    "\n",
    "    index = 0\n",
    "    for index, word in enumerate(text):\n",
    "        tokens.append(\n",
    "            Token(\n",
    "                text=word, start_position=index, whitespace_after=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PMC3549600_sentences.json', 'PMC1090599_sentences.json')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_processed_files = sorted(glob.glob(result_json_dump_path + '*.json*'))\n",
    "names = [os.path.basename(x) for x in already_processed_files]\n",
    "already_processed_PMC_ids = [x[:-5]+'.json' for x in names]\n",
    "already_processed_PMC_ids\n",
    "\n",
    "result_file_name, already_processed_PMC_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Using Information and Communication Technology in Home Care for Communication between Patients, Family Members, and Healthcare Professionals: A Systematic Review Academic Editor: Carlos De Las Cuevas Introduction. Information and communication technology (ICT) are becoming a natural part in healthcare both for delivering and giving accessibility to healthcare for people with chronic illness living at home. Aim. The aim was to review existing studies describing the use of ICT in home care for communication between patients, family members, and healthcare professionals. Methods. A review of studies was conducted that identified 1,276 studies. A selection process and quality appraisal were conducted, which finally resulted in 107 studies. Results. The general results offer an overview of characteristics of studies describing the use of ICT applications in home care and are summarized in areas including study approach, quality appraisal, publications data, terminology used for defining the technology, and disease diagnosis. The specific results describe how communication with ICT was performed in home care and the benefits and drawbacks with the use of ICT. Results were predominated by positive responses in the use of ICT. Conclusion. The use of ICT applications in home care is an expanding research area, with a variety of ICT tools used that could increase accessibility to home care. Using ICT can lead to people living with chronic illnesses gaining control of their illness that promotes self-care. 1. Introduction Due to an ageing population and a shortage of hospital beds, it has become a challenge to find new ways to support and care for people with chronic illness living at home. Living with chronic illness changes the lives of those affected, who are often in need of support and nursing care in their homes [1–3]. eHealth has the potential to become a means of providing good care at home [4], which is especially challenging with regard to this emerging field [5]. eHealth refers to information and communication technology (ICT) tools and services for health, whether the tools are used behind the scenes by healthcare professionals or directly by patients and their relatives [6]. ICT tools can be used to access a wide variety of technological solutions for communication, including text messaging, gathering and monitoring data, diagnosis and treatment at distances, and retrieving electronic health records [5, 7]. According to the World Health Organization (WHO) [8], eHealth is used in the healthcare for transmission of digital data, including data stored and retrieved electronically to support healthcare, both at the local site and at a distance. E-Health includes the interaction between patients and health service providers or peer-to-peer communication between patients and/or health professionals. Interest has primarily focused on the use of ICT tools in the care of older [9] and severely chronically ill people [10]. Although ICT has been increasingly used in healthcare in recent years, efforts across countries have been fragmented and could benefit from improved cross-border coordination. eHealth tools and services have been widely introduced and implemented, and the potential benefits ICT can bring people with chronic illness will increase significantly [6]. 2. Aim The aim was to review existing studies describing the use of ICT in home care for communication between patients, family members, and healthcare professionals. The particular objectives of the review were the following:to provide an overview of characteristics of studies describing the use of ICT in home care,to describe how ICT was used for communication in home care, to describe the benefits and drawbacks of the use of ICT in home care.  3. Method The design for conducting this systematic review was guided by DiCenso et al. [11], with the following steps taken: for formulating a research question, conducting a literature search, applying inclusion and exclusion criteria, abstracting data, and undertaking an analysis. 3.1. Selection Criteria The inclusion criteria for this literature review were set as follows: (1) ICT interventions; (2) communication between any healthcare professionals, patients, and/or family members; (3) studies published in scientific journals; (4) studies published between 2000 and 2010; and (5) in the English language. Criteria for exclusion were ICT interventions that included technological systems not involving people (no active patient acceptance) such as monitoring by camera, alarm systems, and use of ordinary telephones, noting that telephones can be used complementarily to other techniques. Letters, editorials, and news items were also excluded. 3.2. Search Strategy In the literature search the following electronic bibliographic databases were used: PubMed, Scopus, and CINAHL. Search limits were set to English language studies published in scientific journals from 2000 to June 2010. The search terms and search strategy were customized for each database to search completely and exactly. The search strategy included thesaurus terms (MeSH terms and subject headings) combined with free-text words. Examples of main search terms used were telemedicine, information and communication, ICT, technology, e-health, home care, home, and nursing. To maximize the search results, multiple sets of search terms were used. The search was done until an overlap in the studies was observed. All studies retrieved from the search in databases were imported into a reference manager (EndNote). The literature searches resulted in 1,276 studies; after duplicates were discarded by EndNote, 923 studies remained. A search alert was created to get the latest published studies, which resulted in 11 additional studies. The final total to be reviewed was 934. The literature search was performed with support from librarians. 3.3. Selection Process A first selection was based on titles and abstracts of the 934 studies to identify whether or not they were within the scope of the research question. Next, a selection based on inclusion criteria was conducted, with focus on studies of ICT applications used in home care. After this selection, a total of 320 studies remained for closer review. The full-text version of the studies was then read and initially categorized based on type of communication applied in the studies. Two authors read all the studies independently. To increase reliability they discussed ambiguities of inclusion criteria until consensus was reached. This reduced the number to 139 studies relevant to the research question. However, nine relevant studies were unavailable both electronically and in paper form, which thereby were excluded from this study, leaving 130 studies. The selection process for the studies reviewed is presented in Figure 1. 3.4. Quality Appraisal All eligible studies (n = 130) were evaluated for scientific quality on a three-grade scale: high scientific quality, good scientific quality, and fair scientific quality. The grading system is used by The Swedish Council on Technology Assessment in Health Care (SBU) for systematic reviews [12–14]. The quality appraisal was performed in accordance with a previously presented method for quality appraisal [15–18], which was chosen to be appropriate. In appraising the scientific quality of each study, protocols were used to extract data. Different protocols were used for studies with a quantitative approach and for studies with a qualitative approach. In the protocol for quantitative studies the items focused mainly on exclusion, sample procedures, intervention, dropouts, randomization, similarity of groups, blinding, outcomes, statistical procedures, ethical considerations, validity and reliability of instruments used, and possibility of generalization of results. In the protocol for qualitative studies the items focused mainly on context, ethical reasoning, procedure of sample, data collection, analysis procedures, saturation, clarity and logic of results, theoretical framework, theory generation, and description of main results. The protocols contained questions to be answered with yes/no/unclear and additional space to comment on the relevance of each item and for the extracted data. The number of questions answered yes was divided by the total number of questions and thereafter converted to percentage. Willman et al. [15] state that the use of percentage makes it possible to weight and compare different study's methodologies. As recommended [15] the percentage was transformed to high scientific quality (80–100%), good scientific quality (70–79%), and fair scientific quality (60–69%). The studies that scored less than fair were excluded (n = 23), as they were considered not to be of sufficient scientific quality to be included. The quality appraisal was performed by two of the authors, initially together to obtain an equal assessment, but thereafter independently. When uncertainties arose, the authors discussed the result of the quality appraisal until consensus emerged. After the quality appraisal was undertaken, 107 studies remained. 3.5. Data Abstraction The remaining 107 studies were classified as relevant to the research question and met the inclusion and quality criteria for being included in the data abstraction. A list of all included studies can be found in Table 6. Each of the included studies was given an indexation and then categorized according to a number of different areas based on the following characteristics: country of origin, year of publication, study approach, journal, communication strategies, type of technology, type of communication, disease diagnosis, and quality appraisal. Thereafter, data from each of the included studies were extracted and entered into a matrix. 4. Results The result presentation is divided in two parts; general and specific results. 4.1. General Results The general results give an overview of characteristics of studies describing the use of ICT applications in home care. The results are summarized in areas including study approach, quality appraisal, publications data, terminology used for defining the technology, and disease diagnosis. 4.1.1. Studies' Approach Most of the included studies had a quantitative approach. Only about one-fifth had a qualitative approach. Further, some of the studies used mixed methods, with both qualitative and quantitative approaches (Table 1). Twenty-one studies were part of larger projects. 4.1.2. Quality Appraisal In the critical quality appraisal of all 107 studies, just under half were rated as high scientific quality (n = 48). That number was compared to studies rated as good scientific quality (n = 23) and fair to good scientific quality (n = 36) (Table 1). When comparing the quality appraisal between qualitative and quantitative approaches, differences could be noted. A greater proportion of the qualitative studies were rated as high scientific quality. In comparison, less than half of the quantitative studies were rated as high scientific quality. The opposite was the case with qualitative and quantitative studies rated as fair scientific quality. Good scientific quality ratings were found in both qualitative and quantitative studies. 4.1.3. Publication Data All of the 107 included studies were published between January 2000 and June 2010, so only part of year 2010 was included. During this period the number of publications increased by time, with about half of the included studies (n = 53) published between 2007 and 2009. Note that 2009 alone represents 23 studies of the total publications (Figure 2). The studies included were published in 69 different scientific journals. The two most common journals were Journal of Telemedicine and Telecare (n = 15) and Telemedicine Journal and e-Health (n = 12), together representing almost one-quarter of the total number of studies. The rest of the studies (n = 80) were spread over a variety of other journals (n = 67). The impact factor in the journals ranged between 0.348 and 14,293. The majority of the studies were performed in North America (n = 67). About one-third of the studies were done in Europe (n = 34), with United Kingdom, Sweden, and Italy being the most prominent. Only a few studies (n = 6) were conducted outside North America and Europe; those were done in Asia (n = 5) and Australia (n = 1). Three studies were carried out in cooperation between different countries, but only one study was a combined study involving the continents of North America and Europe (Table 2). 4.1.4. Terminology Used for Defining the Technology The results show that 13 different terms were used to define the technology utilized to increase accessibility to home care services and home nursing. The most frequently used terms were telehealth, telemedicine, technology, and telecare. Telehealth and telemedicine together (n = 59) account for more than half of the terms used in the included studies. Other terms used three times or more were e-Health, ICT/IT, telehealthcare, telemonitoring, and telenursing. Further, in some studies other terms were used as follows: e-rehabilitation, teleassistance, and telerehabilitation (Table 3). 4.1.5. Disease Diagnosis The ICT applications were used in healthcare for a wide range of different conditions through the life span. In the majority of the studies (n = 86), the technology was developed specifically for supporting people with chronicle illness living at home. The most frequent diseases studied were heart and lung diseases, chronic wounds, diabetes, cancer, and stroke. Chronic illness was used in 12 studies without any definition of the specific disease. Other conditions were, for example, infectious diseases, spinal cord injuries, and end-of-life care. A number of studies included did not specify the diagnoses (Figure 3). 4.2. Specific Results The specific results describe how ICT was used for communication in home care and benefits and drawbacks within the use of ICT in home care. The results are summarized in the following main areas: type of technology, communications between participants, and benefits and drawbacks of the use of ICT. 4.2.1. Types of Technology Three fields of applications were found to be prominent in the use of ICT in homecare: video technology, text messages and health monitoring. An important result was that a mix of more than one ICT applications was used in several studies (n = 31). A small number of studies included all types of ICT applications above. In some of the studies, a mix of text and pictures and/or audio was used. In a few studies digital images were used. Some studies did not specify the used ICT application (Table 4). Video Technology. The most frequently used type of technology was video technology (n = 53); the number includes studies using more than one ICT application. In several of those studies (n = 31), the main focus of the intervention was the use of videophones or videoconferencing. Another use of video technology was to complement patient health monitoring (n = 22). It is notable that web-based video conferencing was used only in a small number of studies (n = 3). In all studies involving parents of children with chronicle illness, video technology was used to communicate. Video technology was used with different types of applications. Examples of use were guiding patients in their use of medical equipment and to improve self-management, via video-based home telecare services. Another use was teleadvice given by clinical nurse specialists in different areas to community nurses. Videoconferencing was used between patients/family members and healthcare personnel for education and psychosocial or emotional support. Another way to use videoconferencing was to enable interactions between patients and nurses. Consultation via videoconferencing in the patient's home was used instead of visits to the hospital, which enabled access to experts to a greater extent. Virtual nurse visits after, for example, discharge from the hospital, were offered to both patients and family members. Text Messages. As shown in many studies (n = 30), a common way of communicating was via text messages. For sending text messages, websites or web-based programs were used in some studies (n = 10). Handheld platforms, such as mobile phones, laptop computers, or text telephones, were used by patients to both send and receive information as well as to communicate (n = 12). In other studies (n = 8), mobile phones or hand held equipment was used to send text messages. For example, text messages were used for sending messages to patients with self-care advice as a response to symptoms and test results they had reported. Another way to use text messages was by electronic diary for home monitoring to improve communication between patients and healthcare professionals. An electronic messaging programme via computers and mobile phones or e-mail and video mail messages was used, enabling nurses and patients to exchange messages to and from anywhere. Via a symptom management system, patients can receive messages in their daily management of symptoms. Health Monitoring. About half of the total studies (n = 52) included health monitoring, focusing on patients who sent health data to be analyzed by healthcare professionals. In most of the studies that looked at monitoring patient health, text messaging or video technology was used to communicate the data (n = 35). Other forms of communication were also used, including the telephone (n = 17). Health Buddy, was the most commonly used device for monitoring patient health (n = 8). Health Buddy, a system that connects patients in their homes with care providers, is a telehealth device that collects and transmits disease management information about a patient's condition including vital signs, symptoms, and behaviors. Types of patient health data collected from health monitoring systems in real time were, for example, weight, blood pressure, heart rate, and pulse. 4.2.2. Communication between Participants Different types of communication via ICT were described as being used between participants, who were typically nurses, healthcare professionals, patients, or family members. The most frequent line of communication in the studies was between patients and nurses or other healthcare professionals. ICT was used most for communication between nurses and patients. In 24 studies, the patient was not the focus for communication. Instead, it was common for the technology to be used for communication with family members. In five of the studies with a focus on family members, the ICT was developed for healthcare personnel giving support to parents. In some studies, the communication was merely between healthcare professionals and neither patients nor family members were part of the communication. The review shows that people living with illnesses at home and healthcare professionals gave positive responses from using different ICT applications for healthcare in communication with each other (Table 5). 4.3. Benefits and Drawbacks with the Use of ICT in Home Care Results of the included studies were predominated by positive responses from the use of different ICT applications in home care from both people living with chronic illnesses and healthcare professionals. For example, healthcare professionals' opinions were that their work was facilitated. Most studies show that communication between healthcare professionals and patients living at home was improved by using various ICT applications, as improvement in management of symptoms in daily life. It was revealed that various ICT applications can be advantageous to use in follow-up care of patients at home. Another benefit of using ICT applications in home care was found to be an improved accessibility. Results from studies show that using ICT in communication in home care can be cost saving but also the opposite. However, the use of ICT cannot replace a face-to-face encounter but can be used as a complement. 5. Discussion The aim of this study was to review existing studies describing the use of ICT in home care for communication between patients, family members, and healthcare professionals. This review provides an overview of characteristics of studies describing the use of ICT applications in home care. The results show that ICT in home care is an expanding field of interest, with a variety of ICT tools beginning to be evaluated significantly. Half of the included studies reviewed represent the year between 2007 and 2009. This may reflect the increased use of the Internet and ICT tools for care management with involvement of patients and family members' participation in care processes. Previous research [19] stated that focus has emerged from being technology focused to taking the users', that is, the patient, family members, and healthcare professionals, perspective into account. The review shows a trend that most studies were accomplished in North America and Europe, where the United Kingdom, Sweden, and Italy were most prominent. This is noticeable since Italy is one of the European countries in which less than 30 percent of the population uses the Internet on a daily basis. The maturity of the Internet use in daily life is an indicator of how far the digitalization of the healthcare sector should have come [19]. For instance, despite Sweden being a small country, seven of the studies included in this review were performed there, which might be explained by the fact that 75 percent of the population uses the Internet on a daily basis. This review shows that a wide variety of terms were used in the reviewed studies to define ICT. Most frequently used definitions were telehealth and telemedicine. This is in line with Koch's [7] review of the current state and future trends in home telehealth. The term telehealth has been broadly defined as the use of telecommunication and information technologies for provision of healthcare to individuals at a geographical distance [20]. Telehealth involves a wide variety of specific modalities including telephone-based interactions, Internet-based information, still and live imaging, personal digital assistants, and interactive audio-video communication or television [21]. Furthermore, eHealth is described as the overall umbrella field that includes both ICT and telehealth, combining use of electronic communication and information technology in healthcare [22]. This may explain the results of this review with many different terms used to define the technology. This review describes how ICT was used for communication in home care, and an interesting result found was that the most frequent type of communication was between patients and healthcare professionals. This indicates that user focus needs to be shifting from tools for professionals to tools for patients and family members. This is in accordance with Koch [7], describing trends toward tools and services not only for professionals, but also for patients and citizens. However from a nursing perspective, there is a lack of knowledge about how to use ICT solutions to meet the needs of people with chronic illness. In specific, by performing qualitative studies people's needs related to living with chronic illness can be elucidated. A challenge in home care will therefore be to use existing ICT tools to meet caring needs of people with chronic illness based on their experiences [23]. From a caring perspective, it is important to understand ICTs impact on quality of life, quality of care, and medical impact of measureable parameters [24]. This review describes benefits and drawbacks when ICT was used for communication in home care. A variety of ICT applications are described in the review. Bardram et al. [23] stated that ICT applications used in home care must take into consideration the role technology should play in the use of patient and healthcare professionals. Neglecting this aspect may lead to technology that not provide the needed support for communication. According to Koch et al. [25], research and practice of health-enabling and ambient-assistive technologies may significantly contribute to that technical solutions are explored in a social context and in relation to individual needs. Telehealth systems in the form of online and mobile tools are already opening up the possibilities for reduced hospitalization and an increased home care [26]. Various ICT applications will thereby offer healthcare professionals to become more flexible and able to address the differing needs of individual patients [27], that is, a more person-centred care. The results of this review show that people living with chronic illnesses and healthcare professionals were positive to the use of ICT applications, despite that ICT cannot replace a face-to-face encounter but can be used as a complement. Across the literature, outcomes for telehealth-based services are generally comparable to outcomes for services delivered face to face [21]. According to Charlton et al. [133], the style and type of communication the healthcare professional uses influence care outcomes. A literature review [134] shows that patients with possibilities of being cared for and using telecare at home preferred a combination of telecare and traditional healthcare delivery. Therefore, ICT applications must be used as an adjunct and not as replacements for standard care; otherwise, the positive results might not be replicated [135]. Many patients prefer being involved and participating in decision making regarding the care they will receive. Despite this, caring programs will be developed without caregiver's participation [136]. 5.1. Methodological Considerations The strength of this review is the broad literature search that finally resulted in 107 studies. The literature search was systematically conducted using selected databases based on relevant search terms. Even though the database search was done with assistance from a librarian expert in that field, it is possible that some study might have been missed. To get the latest published studies, a search alert was created. A limitation of this review may be that relevant studies might have been missed because of the selection of the English language. During the selection process, a quality appraisal was conducted; thereby, the scientific quality of the included studies could be ensured. The studies included have a great variation in study designs. Therefore, it is not possible to integrate the results and give a more specific summary in this review. However, this was not the intention as the aim was broad; we wanted to find numerous studies for being able to present the state of the art in this field of research. 6. Conclusion The use of ICT applications in home care is an expanding research area, with a variety of ICT applications used to increase access to home care. The result shows that ICT in home care is mostly used as a tool for communication between healthcare professionals and patients or family members. Healthcare professionals can, based on this result, advantageously use ICT applications in home care as a tool to support people living with chronic illnesses gaining control of their illness that promotes self-care. However, a great number of the included studies were performed as pilot studies. For being able to evaluate the effects of ICT applications in home care, more extensive longitudinal studies are needed. To understand more about how ICT can be adjusted to home care, multidisciplinary and qualitative studies are needed from the perspective of the patient and their close relatives. Flow chart of search result. Number of studies published per year between 2000 and June 2010. Number of studies per disease diagnosis. Sample data representation. Study quality Study method (number of studies) Qualitative (21) Quantitative (74) Mixed (12) High scientific quality 15 (71%) 29 (39%) 4 (33%) Good scientific quality 4 (19%) 17 (23%) 2 (17%) Fair scientific quality 2 (10%) 28 (38%) 6 (50%) Number of studies per country. Country Number of studies USA 62 UK 12 Sweden 7 Italy 5 Canada 4 China 2 Japan 2 Australia 1 Austria 1 Belgium 1 Denmark 1 Finland 1 Germany 1 Netherlands 1 Norway 1 Poland 1 South Korea 1 Denmark/Norway 1 UK/Germany/Netherlands 1 USA/Netherlands 1  Total of studies 107 Number of studies per terminology. Terminology Number of studies Telehealth 32 Telemedicine 27 Technology 11 Telecare 10 ICT/IT 7 Telemonitoring 6 Telenursing 4 e-Health 3 Telehealthcare 3 Telerehabilitation 2 e-rehabilitation 1 Teleassistance 1  Total of studies 107 Overview of ICT applications used in homecare. Number of studies (main focus for the study) Fields of application* \\u2009 Video technology(n = 53)** Text messages(n = 30)** Health monitoring(n = 52)** Type of technology 49 26 17 All types 4 Mix of text and picture and/or audio*** \\u2009 \\u2009 6 Digital images \\u2009 \\u2009 3 Not specified type of technology 2  Total of studies 107 Communication between participants. Communication Number of studies Patient-nurse 49 Patient-other healthcare professionals 34 Family members-healthcare professionals 14 Between healthcare professionals 10  Total of studies 107 Overview of studies (n = 107) included, interventions, and main results. Studies Intervention Main results Agrell et al. [28] Chronically ill patients could use medical equipment in their homes guided by nurses via video-based home telecare services. Participants were either very satisfied or somewhat satisfied with services they had received. All except one were willing to receive home telecare services in the future. The presence of telecare equipment in the home implied 24-hour-a-day access to a nurse. Some of the participants felt uncomfortable disclosing intimate information during televisits and others lamented the reduced amount of time nurses spent “socializing” as compared to in-person visits.  Ameen et al. [29] Patients in an experimental and control group had their ulcers photographed before and after the intervention. During the intervention period, an experienced clinical nurse specialist in tissue viability gave expert teleadvice to the community nurse. Statistically significant improvements were observed for the experimental group in the areas of dressings and management. Teleadvice can be of great benefit to community nurses in enhancing their knowledge in the practice of leg ulcer care. Provision of teleadvice can significantly improve nurses' knowledge in the care of leg ulcers. Teleadvice has implications for more efficient use of human resources and cost effectiveness in wound care.  Arnaert and Delesie [30] Real-time interpersonal communication was used between elderly patients and nurses. Tele-nurses delivered psychosocial support and educational interventions based on three principles: contact and communication, safety and protection, and care mediation. Telecare is an alternative care model that could be integrated into existing homecare services to provide older people with integrated health services.  Arnaert et al. [31] Video telephones (videophones) were used for exploring attitudes of older adults with depressive symptoms in their homes. Participants' preattitudes were dependent on their active or passive role in the learning process of the new technology. Their postattitudes were classified as ambivalent or positive. Two participants who had a positive attitude toward the videophones expressed a positive behavior use.  Artinian et al. [32] Patients participated in nurse-managed home tele-monitoring plus usual care or in nurse-managed, community-based monitoring plus usual care. Each week during the study period, patients received telephone counseling about lifestyle modifications. A specially trained registered nurse delivered the interventions. Each participant received an electronic home BPLink monitor and BP monitoring services. The BPLink monitor is a system that enables persons to monitor blood pressure and heart rate at home and send readings to the investigator and to their primary care provider by telephone without the use of a computer Participants in the home tele-monitoring and community-based monitoring groups had clinically and statistically significant reductions in both systolic blood pressure and diastolic blood pressure during a 3-month monitoring period as compared with the participants in the usual care group.  Baer et al. [33] Wounds were photographed by a homecare nurse using a digital camera, and the images were transmitted to a server from the nurse's office, together with patient details. The homecare nurse graded the wounds and suggested a treatment plan. Subsequently, a specialist wound care nurse also graded them and suggested a treatment plan, using the data stored on the web server, Home Telehealth Consultation System. The results were encouraging and suggest that web-based communication can improve the quality of care for patients with leg wounds and can reduce costs.  Barnason et al. [34] Effect of a home communication intervention (HCI) to augment home healthcare (HHC) on functioning and recovery outcomes of elderly patients undergoing coronary artery bypass graft. The experimental group in this study received HCI using a technology device called the Health Buddy. The Health Buddy device is a small, simple communication device, approximately 6 × 9 inches, with an illuminated screen and four large buttons for the patient to use to interact with messages viewed on the screen. HCI subjects, compared with the HHC group only, had a significantly higher adjusted mean general health functioning score. There were significant time effects on physical, role-physical, and mental health functioning, indicating that both groups improved over time. The groups reported similar postoperative problems; however, the control group had more emergency department visits than the HCI group.  Barnason et al. [35] The home communication intervention (HCI) was delivered to coronary artery bypass graft patients with ischemic heart failure, using a device called the Health Buddy. This small device attaches to the patient's telephone as a means of communication and provides healthcare professionals with assessment of patient symptoms (e.g., fatigue or sleep problems) and strategies to manage reported symptoms. Findings demonstrate promise for the potential usefulness of a targeted intervention for a vulnerable subsample of coronary artery bypass graft patients during the early recovery period. Furthermore, the uniqueness of the telehealth device used provided clinicians with another potential option for maintaining contact with high-risk patients. Self-efficacy is a key component to self-care and disease management.  Benatar et al. [36] Care was delivered by the homenurse visit or the nurse telemanagement method. In the latter, patients used trans-telephonic home monitoring devices to measure their weight, blood pressure, heart rate, and oxygen saturation. These data were transmitted daily to a secure Internet site. An advanced practice nurse worked collaboratively with a cardiologist and subsequently treated patients via telephone. The results demonstrate significant improvements in outcomes and quality of care for patients with severe heart failure using aggressive remote tele-monitoring versus traditional homenurse visits. The data provide evidence that the introduction of current state-of-the-art computerized technologies allows rapid and accurate monitoring of patients with severe heart failure. The combination of these technologies and heart failure management by an advanced-practice nurse under the guidance of a cardiologist is cost effective and leads to improved outcomes and care.  Bendixen et al. [37] The effects on healthcare costs of a Veterans Administration telerehabilitation programme were examined. LAMP (Low Activities of Daily Living (ADL) Monitoring Programme) is based on a rehabilitative model of care. LAMP patients received adaptive equipment and environmental modifications, which focused on self-care and safety within the home. LAMP care coordinators remotely monitored their patients' vital signs and provided education and self-management strategies for decreasing the effects of chronic illnesses and functional decline. No significant differences were detected in postenrollment costs between LAMP and the matched comparison group. For LAMP patients, the provision of adaptive equipment and environmental modifications, plus intensive in-home monitoring, led to increases in clinic visits after intervention with decreases in hospital and nursing home stays.  Bohnenkamp et al. [38] After discharge from the hospital, cancer patients with new ostomies were assigned to one of two groups: home health visits only or home health plus telenursing contact. The home health group received home health visitations by a nurse who continued evaluations and education according to current management protocols. The telenursing group was more satisfied with care after discharge from the hospital and required fewer pouch changes, so care was less expensive because of the decreased number of pouches used. The telenursing patient group believed that the ostomy nurse understood their problems better than the home health nurse did, and they were more comfortable with information provided by the ostomy nurse. The telenursing group received care from nurse specialists who were able to individualize patient care, decrease cost, and improve patient satisfaction.  Bowles and Dansky [39] Nurses in a large, urban homecare agency used televideo technology to improve the self-management of diabetes for older adults who were admitted for skilled home care. Telehomecare is a new teaching and monitoring tool that helps patients improve their knowledge and self-management of diabetes. Telehomecare visits are effective for reinforcing patient education and achieve significant improvements in self-management. Patients in the video group received more contact with their nurses in person and via video visits versus in-person visits.  Bowles et al. [40] Effects of evidence-based disease management guidelines were delivered to patients with heart failure and diabetes using three different modalities: in-person visits alone (control), in-person visits and a telephone intervention (telephone), and in-person visits and tele-monitoring (tele-monitoring). Three different kinds of telehealth monitors were used. Two monitors provided physiological monitoring, with a blood pressure cuff, bodyweight scale, glucometer, and pulse oximeter. The third monitor provided these in addition to a digital stethoscope and videoconferencing. The telehealth information was transmitted to the agency where it was monitored daily by the nurses. Nurses assessed physical and emotional status, reviewed medications, and instructed the patients on self-care and disease management. There was no difference between the groups in the primary outcome (rehospitalization), although there was a trend toward increased hospital readmissions in the telephone patients versus control. Having heart failure and receiving more in-person visits were significantly related to readmission and time to readmission. However, the differences between the three groups were nonsignificant. There was a trend for increased risk of readmission for the telephone group and for readmission sooner. Patient rehospitalization and emergency department visit rates were lower than the national average, making it difficult to detect a difference between groups.  Brennan et al. [41] Nursing practice capitalizes on a web-based resource (HeartCareII) to support patient self-management, symptom interpretation, and self-monitoring. Research staff provided computers and technical assistance; visiting nurses trained patients in the components of the HeartCareII website most relevant to their care needs. The duration of visiting nurse association (VNA) service and use of HeartCareII resources vary across patients and nurses.  Buckley et al. [42] Remote monitoring equipment and a video-phone operating over a standard telephone line were installed in the homes of patients with diabetes, and they were trained in their use and operation. Residents performed daily monitoring of blood pressure and/or blood glucose using the equipment. The residents received weekly video visits from the nurse educators. The results demonstrated a trend in reduction of HbA1c for the residents with diabetes, but there was no significant improvement in HbA1c, blood glucose, or blood pressure measurement. Knowledge of diabetes and hypertension, self-efficacy, and perception of telehealth significantly increased following the protocol.  Buckley et al. [43] The wound, ostomy, and continence (WOC) nurse first completed a wound assessment and recommendation form based on a verbal report from the homecare nurse then accessed digital images of the wounds and made any indicated modifications to the original assessment and management plan, providing a rationale for any changes. Comparisons were made between the assessment completed by the homecare nurse and the WOC nurse's assessment and between the WOC nurse's assessment and recommendations based only on a verbal report, and his or her assessment and recommendations based on the combination of a verbal report and a digital photograph. There was a high percentage of agreement between the wound assessments completed by the homecare nurse and those completed by the WOC nurse; areas of disagreement often impacted the overall assessment. WOC nurses who provide remote nurse-to-nurse consultations without directly visualizing the patients' wounds through digital images are at risk for under- or overtreating patients' wounds. Digital images also provide an opportunity for the WOC nurse to mentor homecare nurses in wound assessment and care.  Buckley et al. [44] The telehealth nurse scheduled a series of two initial home visits to stroke patients at home and follow-up weekly telehealth visits with each caregiver over a six-week period. The telehealth equipment was installed in the patient's home. Major factors related to the receptiveness of telehealth were the timing of when it was offered after discharge and the level of caregiver burden. Caregivers expressed the opinion that the option of using telehealth should be introduced at the time of the stroke survivors' discharge, when they were trying to cope with new needs and responsibilities. The majority of caregivers who had elected to use the telehealth reported having a moderate level of patient dependence upon them and a low-to-moderate level of burden was consistent with the caregivers' comments of needing additional support offered by telehealth and of being moderately comfortable with and interested in technology.  Cardozo and Steinberg [45] Recently discharged older patients received a nurse visit up to 3 times/week and home telemedicine monitoring on a daily basis. The telemedicine component used remote monitoring to assess the patient's health status. It had the capability to monitor respiratory rate, blood pressure, pulse oximetry, and patient weight and continually graph and update the electronic patient record. These data were available to the healthcare team and allowed them to improve care coordination and provide proactive and individualized management. It also included the Health Buddy appliance that provided important patient health education and self-regulating disease management information. A majority of patients showed improved quality of health perception, better disease understanding, and high satisfaction rates with telemedicine. A home-based, case-managed telemedicine care system is cost-effective and improves health outcomes in older patients who are at risk from deteriorating health and further deconditioning as a consequence of repeated hospital admissions. Telemedicine is well accepted by the elderly as a complementary modality of care.  Chae et al. [46] In home health services (HHS) for elderly patients, a telemedicine system with a 33-kbs narrow-band approach to determine the effectiveness in providing quality services was implemented and evaluated. A computer-based patient record was also developed to view a patient summary and to document encounters at the patient's home. Telemedicine was effective in terms of reducing the number of clinic visits and achieving patient satisfaction; 72% of patients were satisfied with telemedicine, but patient location showed a significant difference for patient satisfaction. Patients in their homes were more satisfied than patients in nursing homes. Of four types of services provided, medical consultation was the most highly satisfactory service with telemedicine, followed by physical therapy. Although the satisfaction scores did not indicate a significant difference in the system characteristics, the quality of verbal communication appeared to be a more important factor in influencing patient satisfaction than set-up time or quality of image. This approach enabled a physician to accurately assess elderly patients in their homes or nursing homes and to treat them with the help of a home-visiting nurse.  Chambers and Connor [47] An interactive software programme was designed to provide family caregivers with information, advice, and psychological support by way of feedback of their coping capacity. The multimedia programme consists of an information-based package that provides caregivers with advice on health promotion and relaxation and offers them a range of coping strategies (e.g., positive self-talk, assertiveness training, and relaxation tapes and videos). The programme also includes a caregiver's self-assessment instrument, designed to provide both family and professional caregivers with information to assess how family caregivers are coping with their caregiving roles. The programme is useful to caregivers and of high quality and efficient in relation to utility and usability. The programme was highly rated in terms of global usability and its five component scales of attractiveness, controllability, efficiency, helpfulness, and learnability. This illustrates that the programme is visually pleasant, easily understood, responds quickly, and corresponds with user's expectations. Users felt there was room for improvement in the navigation of the programme.  Chambers and Connor [48] The interactive application consisted of an information-based package that provided caregivers with advice on the promotion of psychological health, including relaxation and other coping strategies. The software application also included a caregiver self-assessment instrument, designed to provide both family and professional caregivers with information to assess how family caregivers were coping with their caregiving role. The findings evidenced that the majority of users found the software to be usable and informative. Some areas were highlighted for improvement in the navigation of the software.  Chang et al. [49] Telehealth and telephone communication technologies were used by nurse practitioners to provide individualized diabetes care management and to have similar effects on glycemic control. The number of days of participation in the programme was greater for the telehealth group than the group receiving the telephonic intervention, but this difference was not statistically significant. Approximately 75% of the patients worked with nurse practitioners and had reached individualized glycemic goals at disenrollment. Among these patients, those receiving the telehealth intervention had a 3.1% reduction in HbA1c, and those receiving the telephone intervention had a 2.7% reduction in HbA1c, over a mean period of 204 days. After disenrollment, HbA1c increased slightly, suggesting that veterans need continuous individualized care, in addition to routine followup, to manage their diabetes.  Cleland et al. [50] Patients with a recent admission for heart failure and left ventricular ejection fraction were assigned randomly to home tele-monitoring, nurse telephone support, or usual care. Home tele-monitoring consisted of twice-daily patient self-measurement of weight, blood pressure, heart rate, and rhythm with automated devices linked to a cardiology center. The nurse telephone support (NTS) consisted of specialist nurses who were available to patients by telephone. Primary care physicians delivered usual care. During 240 days of followup, 19.5%, 15.9%, and 12.7% of days were lost as the result of death or hospitalization for usual care, nurse telephone support, and home tele-monitoring, respectively (no significant difference). The number of admissions and mortality were similar among patients randomly assigned to nurse telephone support or home tele-monitoring, but the mean duration of admissions was reduced by 6 days with home tele-monitoring. Patients randomly assigned to receive usual care had higher one-year mortality than patients assigned to receive nurse telephone support or home tele-monitoring. Further investigation and refinement of the application of home tele-monitoring are warranted because it may play a valuable role in the management of selected patients with heart failure. Although many patients were elderly, their acceptance and ability to cope with the home tele-monitoring technology were high. Few patients asked for the equipment to be removed or failed to comply with daily measurements. Good or very good satisfaction with home tele-monitoring was reported by 96% of patients. Improved access to care, either by nurses or by tele-monitoring, appeared to lead to an increase in patient contacts.  Clemensen et al. [51] Video consultations in the home of the patient were introduced. The video consultation setup constitutes a new organisational way of working, described as “a new triangle” based on immediate interindividual cooperation and teamwork. In the triangle, competences were combined, which led to a more holistic treatment and a more active patient role. Competences were combined, which led to a more holistic treatment and a more active patient role. A spreading of knowledge among all participants was seen, resulting in an upgrading of the competences of the visiting nurse especially. The introduction of a real-time, online link between hospital and home constitutes the basis for simultaneous communication between all participants, resulting in a “witnessing” situation potentially securing or even enhancing quality of treatment.  Dang et al. [52] A programme called telephone-linked care for dementia was conducted. This programme offered access to resources, as in the REACH trial and also provided caregiver education and periodic monitoring questionnaires using a screen-phone. The intervention was delivered via a CTIS screenphone. The system allowed users to make and receive calls and messages. The respondents were more satisfied with the care coordination aspect of the programme than the education or the monitoring. The project suggests that care coordination aided by screen-phones may be a useful model for caregiver support in a managed care setting.  Dansky and Vasey [53] Patients with heart failure received the Health Buddy and used it for the duration of home health services. The Health Buddy was programmed to ask patients questions related to heart failure including symptoms, self-care practices, and medication compliance. During the formal episode of care, all patients received standard care. Patients who continued using telehealth beyond the formal episode of care showed greater improvements in respiratory status and activities of daily living. None of the patients who used telehealth during this stage had any hospitalizations or emergency department events, while 28.3% of the control group patients required hospitalization and 26.1% had at least one emergency department visit. Telehealth patients were more likely to report that they measured their weights daily and more likely to report an increase in diuretic dose following sudden weight gain, ankle swelling, or shortness of breath.  Dansky et al. [54] “Telehomecare” is a telephone-based communication system with medical peripherals that is used in the home setting. Patients use the medical devices to assess their health status and transmit the data to clinicians for review and action. Nurses and other clinicians use the data to monitor patients' health and teach patients and their caregivers self-management behaviours. Measurement and transmission of blood pressure, temperature, weight, blood glucose levels, and pulse oximetry are possible. The one-way systems are used independently by the patient and are typically programmed to be used every day at a predetermined time. If the nurse who checks the transmitted data observes abnormal values, he or she may call the patient or the homecare nurse for further information or intervention. The two-way system adds a video camera and digital stethoscope to the monitoring device, permitting two-way synchronous interaction between nurse and patient. Patients in the telehomecare group had a lower probability of hospitalizations and emergency department visits than did patients in the control group. Differences were statistically significant at 60 days but not at 120 days. Results show a greater reduction in symptoms for patients using telehomecare compared to control patients. The technology enables frequent monitoring of clinical indices and permits the home health care nurse to detect changes in cardiac status and intervene when necessary.  Dansky et al. [55] Telehealth, a clinical information system that transmits data over ordinary telephone lines, was used by individuals in their homes to communicate electronically with healthcare providers. This study investigated the influence of telehealth on self-management of heart failure in a sample of older adults. Confidence is a predictor of self-management behaviors. Patients using a video-based telehealth system showed the greatest gain in confidence levels with time. Managers and policy makers responsible for creating and funding programmes that support the use of health-information technologies by older adults can benefit from these results.  Dansky et al. [56] The home health agency used a telehomecare model as a complement to traditional home visits. The system connects a central station with patients' units over ordinary telephone lines using an internal modem. The central station combines a windows-based PC with a touch-tone telephone to deliver full-color video and telephone-quality audio. Telehomecare is highly structured and moderately complex. Nurses begin with simple tasks and move to more complex activities. The patient and the family are clearly the focus of telehomecare intervention.  Darkins et al. [57] The Veterans Health Administration introduced a national home telehealth programme, Care Coordination/Home Telehealth (CCHT). Its purpose was to coordinate the care of veteran patients with chronic conditions and avoid their unnecessary admission to long-term institutional care. After a patient is enrolled in the programme, the care coordinator selects the appropriate home telehealth technology, gives the required training to the patient and caregiver, reviews telehealth monitoring data, and provides active care or case management (including communication with the patient's physician). Routine analysis of data obtained for quality and performance purposes shows the benefits of a 25% reduction in number of bed days of care, a 19% reduction in the number of hospital admissions, and a mean satisfaction score rating of 86% after enrollment in the programme. The cost of Care Coordination/Home Telehealth is less than the other noninstitutional care programmes and nursing-home care. The Veterans Health Administration experience is that an enterprise-wide home telehealth implementation is an appropriate and cost-effective way of managing chronic-care patients in both urban and rural settings.  de Lusignan et al. [58] The use of the programme allowed monitoring of vital signs, such as pulse, blood pressure, and weight, of patients with chronic heart failure. Data was then transferred to a tele-monitoring server at a hospital and could be viewed by clinicians. The telemedicine group has the ability to video consult. A comparison was made with a control group (traditional care). Compliance with measuring weight, pulse, and BP remained high throughout the study. The data collection system and secure web server were reliable. The tele-monitoring group complied better with collecting prescriptions for their cardiac drugs. Video-consulting started with enthusiasm but became less useful. There were no significant differences in the quality of life and Chronic Heart Failure Questionnaire scores between the tele-monitored group and the controls.  DelliFraine et al. [59] The relationship between telemedicine knowledge management activities and nurses' perceived efficiency and effectiveness of telemedicine in home health was investigated. Knowledge management enhances the processes of care for a variety of services in different settings, with varying degrees of usage by clinical staff. These knowledge management activities are intended to facilitate communication and information exchange between physicians, nurses, and patients, which in turn enhances patient care delivery. Results indicate a significant association between combined explicit and tacit knowledge management activities using telemedicine and perceived efficiency and effectiveness of telemedicine. Telemedicine knowledge management activities might have a positive impact on perceived efficiency and effectiveness of care in home health.  Demiris et al. [60] Videoconferencing and Internet equipment were used to enable interactions between patients and nurses. An instrument that measures perceptions of telehomecare was used. There was no statistically significant change of perception in the control group. The experimental group showed an overall, more positive perception of the system, and the mean score difference was higher compared to the control group. Elderly patients evaluated their telehomecare experience as being positive, and they felt more comfortable with the technology, believing that the nurse can understand their medical problems over the television. The study suggested that patients tend to become more familiar with and confident in technology after participation in a telehomecare system, and the subjects seemed less concerned about telehomecare violating their privacy. The initial fears of some patients, like privacy, seemed to diminish. Some other original perceptions of telehomecare did not hold after exposure to the system. Patients' overall impressions of a telehomecare system were more positive after they had experienced it. They evaluated this experience as positive and beneficial for their own health as well as time saving for the nurses. They felt that a nurse could get a good understanding of their medical problems over the television and, therefore, accepted the underlying concept of telehomecare.  Elliott et al. [61] To examine the effectiveness of an individualized problem-solving intervention delivered in videoconferencing sessions with family caregivers of persons living with a spinal cord injury and possible contagion effects on care recipients. Family caregivers were randomly assigned to an education-only control group or an intervention group in which participants received problem-solving training in monthly videoconference sessions for a year. Older caregivers were more likely than younger caregivers to remain in the study. Intent-to-treat analyses projected a significant decrease in depression among caregivers receiving problem-solving training; efficacy analyses indicated this effect was pronounced at the sixth-month assessment. Care recipients of caregivers receiving problem-solving training reported gains in social functioning over time. Community-based, telehealth interventions may benefit family caregivers and their care recipients, but the mechanisms of these effects are unclear.  Finkelstein et al. [9] The study demonstrates that telehomecare linking homebound patients with their home healthcare nurses over a standard telephone system provides high-quality, clinically useful, and patient satisfactory interactions. Virtual visits, consisting of two-way audio and video interactions between the central site, home health care nurses, and subjects at home were compared for technical quality and clinical usefulness by the home health care nurses who performed the virtual visits. All subjects were satisfied with their home health care; satisfaction increased with an increasing level of telehomecare intervention. Subjects receiving physiological monitoring and videoconferencing/Internet access in addition to standard care were most satisfied with their care. Virtual visits can be conducted over ordinary telephone systems. Patients can use telehomecare with moderate levels of training. These programmes can provide timely and quality home health nursing care with virtual visits augmenting traditional home visits.  Finkelstein et al. [62] Patient outcomes and cost were compared when home healthcare was delivered by telemedicine or by traditional means for patients receiving skilled nursing care at home. A randomized controlled trial was established using three groups. The first group received traditional, skilled nursing care at home. The second group, the video intervention group, received traditional, skilled nursing care at home and virtual visits using videoconferencing technology. The third group, the monitoring intervention group, received traditional, skilled nursing care at home; virtual visits using videoconferencing technology; and physiologic monitoring for their underlying chronic condition. Virtual visits between a skilled home health care nurse and chronically ill patients at home can improve patient outcomes at lower costs than traditional, skilled face-to-face home healthcare visits. Subjects who were both monitored and used videoconferencing had a better ADL rating at discharge than did the control group.  Forbat et al. [63] An intervention with utility of a handheld side-effect monitoring system for people receiving chemotherapy in the homecare setting. People affected by cancer were reflecting on issues such as power and surveillance in cancer care. While these terms are ordinarily considered to reflect negative elements of care, they were used by participants in an empowering manner. Patients receiving cancer care at home reported positive perspectives on the use of healthcare technology, thereby subverting the idea of surveillance as negative. Use of health surveillance technologies, which enable people to remain in their own homes during treatment, are likely to be well received.  Gray et al. [64] An Internet-based telemedicine programme, Baby CareLink, was designed to reduce the costs of care and to provide enhanced medical, informational, and emotional support to families of very low-birthweight infants during and after their neonatal intensive care unit stay. Baby CareLink is a multifaceted telemedicine programme that incorporates videoconferencing and World Wide Web (WWW) technologies to enhance interactions among families, staff, and community providers. Families in the CareLink group reported higher overall quality of care and significantly fewer problems with the overall quality of care received by their family. They also reported greater satisfaction with the unit's physical environment and visitation policies. The frequency of family visits, telephone calls to the neonatal intensive care unit, and holding of the infant did not differ between groups. The duration of hospitalization until ultimate discharge to the home was similar in the two groups. All infants in the CareLink group were discharged directly to home whereas 20% of control infants were transferred to community hospitals before ultimate discharge home.  Guilfoyle et al. [65] A protocol for the use of videophones in community health was developed. Clients with a range of health needs were equipped with a commercially available video-phone connected using the client's home telephone line. A hands-free speakerphone and a miniature video camera (for close-up views) were connected to the video-phone. Both clients and nurses rated the equipment as satisfactory or better. None of the nurses felt that the equipment was difficult to use, including unpacking it and setting it up; only one client found it difficult. Taking into account the clients' responses, including their free-text comments, a judgement was made as to whether the video-phone had been useful to their nursing care. In seven cases, it was felt to be unhelpful, and in three cases, it was judged helpful.  Hauber and Jones [66] Telerehabilitation was used to support families caring at home for individuals with prolonged states of reduced consciousness. Patients were discharged home with family members as the primary caregivers. Their families were followed for 4 to 8 weeks via video-phone. Follow-up telephone surveys were conducted with a family member 6 to 9 months after discharge and compared to surveys of a similar group that had not received the video-phone followup. More patients in the videoconferencing group were still living at home and had returned for rehabilitation. Families in the video-phone group reported more of their needs met than families in the comparison group. The use of videoconferencing to bridge the transition to home for families caring for a family member may assist families in successfully caring for the individual in the home and reducing the number of perceived family needs.  Hirakawa et al. [67] The aim was to clarify the possible changes brought about by the introduction of the long-term care insurance system in terms of number of communication/recording tasks, related nursing services in use, and when and where these tasks were performed. It was also to explore the advantages of introducing information technology (IT) systems into nursing service settings. The study was designed as a before-and-after study in two sessions, namely, before and after introduction of a long-term care insurance system. Different measurements were performed during the intervention. Following the adoption of the new system, these tasks tended to occur mostly around the starting time of services. As for the staff, the involvement of the professional caregivers increased. Regarding content of communication/recording, reports, confirmation, and instruction increased.  Hofmann-Wellenhof et al. [68] The feasibility and acceptance of teledermatology for wound management of patients with chronic leg ulcers by homecare nurses were examined. Patients with chronic leg ulcers of different origin were included. In initial in-person visits, leg ulcers were assessed and classified and underlying diseases noted. Follow-up visits were done by homecare nurses. Once a week, digital images of the wound and surrounding skin and relevant clinical information were transmitted via a secure website to an expert at the wound care centre. The experts provided an assessment of wound status and therapeutic recommendations. In 89% of the 492 tele-consultations, the quality of images was sufficient or excellent, and experts were confident about giving therapeutic recommendations. Treatment modalities were changed or adapted in one-third of the consultations. There was a significant decrease in visits to a general physician or the wound care centre. The acceptance of teledermatology was high in patients, homecare nurses, and wound experts.  Horton [69] Telecare service was given to patients living at home with chronic obstructive pulmonary disease (COPD) by a home care team using telecare service. Telecare service comprised the following elements: daily monitoring of the patient's condition and monitoring to investigate and determine any physiological changes via parameters as oxygen saturation, pulse, and respiratory rate. The experience and expectation in telecare, the usability of equipment, and changes in practice can impact COPD care. The outcome highlighted that the rapid access to care, an increased sense of personal safety and security, and the continuity of care are perceived as benefits. However, the equipment was perceived as bulky and not user friendly.  Huddleston and Kobb [70] Older veterans with chronic diseases and high healthcare utilization were followed with an in-home technology device, that is, the Health Buddy, and risk management software. Programme staff could identify at-risk patients based on their responses to a series of questions about symptoms, behavior, and knowledge. Patients were followed in the programme for at least six months. The outcome showed a 45% decrease in hospital admissions, a 67% decrease in nursing-home admissions, a 54% decrease in emergency department visits, and a 38% decrease in pharmacy prescriptions. The patients also demonstrated improved compliance with treatment regimens, and both patients and providers reported high levels of programme satisfaction.  Jenkins and McSweeney [71] A comparison among the effectiveness of three hospital discharge care models for reducing congestive heart failure–related readmission charges. The care models— home telecare delivered via 2-way videoconference devices with integrated stethoscope, nurse telephone calls, and usual outpatient care—were compared. The outcome showed that the between-group difference was not statistically significant and cannot offer incremental benefits beyond telephone followup; it is also more expensive.  Jerant et al. [72] The trial compared 3 posthospitalization nursing-care models for reducing congestive heart failure (CHF) readmission charges during 180 days of followup. Subjects received in-person visits at baseline and at 60 days, plus one of three care modalities in the interim: video-based home telecare, telephone calls, or usual care. CHF-related readmission charges were more than 80% lower in the telenursing groups compared to usual care, and these groups also had significantly fewer CHF-related emergency visits. In-person visits were more than three times longer than telenursing visits (P < 0.0001), only partially due to added travel time. Patient self-care adherence, medications, health status, and satisfaction did not significantly differ between groups. Telenursing can reduce CHF hospitalizations and allow increased frequency of communication with patients.  Jerant et al. [73] Homenurse visits after discharge can reduce readmissions for persons with congestive heart failure (CHF), but the intervention costs are high. To compare the effectiveness of three hospital discharge care models for reducing CHF-related readmission charges: (1) home telecare delivered via a two-way video-conference device with an integrated electronic stethoscope; (2) nurse telephone calls; and (3) usual outpatient care. CHF-related readmission charges were 86% lower in the telecare group and 84% lower in the telephone group than in the usual care group. However, the between-group difference was not statistically significant. Both intervention groups had significantly fewer CHF-related emergency department visits and charges than the usual care group. Trends favouring both interventions were noted for all other utilization outcomes.  Kawaguchi et al. [74] The Internet-based system allows patients (equipped with a laptop computer), nurses, and physicians to access information from a central database through a wireless network. E-mail and video mail messages as well as vital signs data can be sent daily by the patient to a server at a regional healthcare centre and can be accessed by a nurse or physician, who can then decide on appropriate care. The system was tested by a male patient with type 2 diabetes mellitus to see whether it would enhance his own management of his condition. During a 71-day period, educational material was provided. The telenursing system helped the patient to manage his condition, as shown by significant improvements in his levels of blood glucose and glycosylated haemoglobin (HbA1c) and in blood pressure. Findings suggest that the system is feasible.  Kearney et al. [75] The acceptability of using handheld computers as a symptom assessment and management tool for patients receiving chemotherapy for cancer was evaluated. The patients used the handheld computer to record and send daily symptom reports to the cancer centre and receive instant, tailored symptom management advice during two treatment cycles. Patients believed the handheld computer had improved their symptom management and felt comfortable using it. The health professionals also found the handheld computer to be helpful in assessing and managing patients' symptoms. The hand-held, computer-based symptom management tool was feasible and acceptable to both patients and health professionals in complementing the care of patients receiving chemotherapy.  Keaton et al. [76] Caregivers answered questions through the use of Caring-web, which is a web-based intervention for caregivers of people with stroke. The e-mail messages from caregivers were then answered by a nurse specialist and members of an e-rehabilitation team. (Caring-web enables to provide different types of education and support to assist caregivers' needs.) The outcome showed that the caregivers' questions centered on medication management (19%), community and government service (23%), and stroke and related issues in dealing with stroke (58%). This indicated that the caregivers were seeking new knowledge so they could maintain themselves and their care recipients.  Kleinpell and Avitall [77] The intervention consisted of in-hospital-based screening for discharge needs. A home telehealth monitoring system for transmission of weight, blood pressure, heart rate, and pulse oximetry was installed in the patient's home. Telephone followup was conducted when parametres were out of preset and for postdischarge followup on days 1 and 3 and weekly for 4 weeks. Subjects were receptive to having the telehealth technology in the home and related positive experiences to having telephone followup to reinforce the discharge plan and to monitor postoperative recovery.  Kobza and Scheurich [78] The utilization of telemedicine in situations where wound specialists consulted with the home health nurse in the patient's home regarding care of chronic wounds was examined. During the two-way video visit, the wound specialist assessed the patient and the wounds and made recommendations for treatment. The wound specialist also collected outcome data during the visits. This data was then compared with like data collected as a baseline prior to the telemedicine intervention. Results revealed improved healing rates, decreased healing time, decreased number of home health visits, and a decreased number of hospitalizations related to wound complications. Telemedicine was deemed a viable option for delivering quality, cost-effective care to chronic-wound patients in the homecare setting.  LaFramboise et al. [79] The feasibility of providing a heart failure disease management programme was studied through an in-home telehealth communication device (that is, Health Buddy). The effectiveness of the Health Buddy was compared with traditional home management strategies (telephonic, home visit) in achieving selected patient outcomes (self-efficacy, functional status, depression, and health-related quality of life). Those who received telephonic disease management experienced decreased confidence in their ability to manage their heart failure, whereas all other groups experienced increased confidence. The results also indicated improvement over time with no group differences for functional status, depression, or health-related quality of life. These findings suggest that delivering a disease management programme through a telehealth communication device is feasible and may be as effective as traditional methods.  LaFramboise et al. [80] Patients with heart failure used a Health Buddy for self-management. They were asked seven questions daily about heart failure symptom status and ability to follow the prescribed regimen. Participants found that the Health Buddy is technically easy to use; that it promoted, taught, and supported heart failure self-management; and that it was even a “lifesaver,” but that it could be bothersome, complex, and a too lengthy intervention.  Larsen et al. [81] Universal Mobile Telephone System (UMTS) mobile phones for video consultations in the home were tested. Patients with diabetic foot ulcers were offered three video-consultations instead of visits to the hospital outpatient clinic. The consultations took from 5 to 18 minutes. In all consultations, the hospital experts were able to assess the ulcer in cooperation with the visiting nurse and to decide on treatment. Technical problems sometimes made it difficult. Even connectivity problems occurred in about half of the cases. In addition, the audio signal was rather unstable at times. In all situations except one, the clinicians were able to reach a decision that the expert felt confident about. After all consultations, the atmosphere and participants' attitudes were very positive.   Lillibridge and Hanna [82] A telehealth technology was used to assist case managers to effectively manage their caseloads of HIV/AIDs clients, increase responsiveness to clients' changing medical conditions, and serve as a partial solution to the ongoing nursing shortage. Telehealth monitors were placed and used in the clients' homes for a period of four months. The findings suggest that the use of telehealth technology has the potential to effectively assist case management and home health agencies, manage their caseloads, increase responsiveness to a client's changing medical conditions, and address the ongoing nursing shortage.  Lin and Yang [83] Asthma care mobile service (ACMS) was performed in the carrying out of the intervention. ACMS is a care platform for asthma patients that uses mobile phones to monitor asthma patients' real-time conditions. The patient's breathing, coughing extent, sleep quality, and daily routine circumstances were recorded using the mobile phone, and the data were sent to NCHC's network platform. General practitioners could detect the location of the patient and, in real time, obtain information on the local climate and air quality. NCHC analysed and recorded the information. Physicians could evaluate whether or not there was a disease crisis on the basis of data changes. If an asthma event occurred, it was possible to inform the patient to come to the hospital by using the same communication system. The health education center provided medical information to patients so they could better understand changes in their diseases and their doctors' recommendations. The results indicated that the most critical factor affecting behavioral intentions related to ACMS is user attitude, followed by perceived usefulness, subjective norm, perceived ease of use, and innovativeness. The results provide governments developing high-tech, preventive medicine strategies with the necessary data to define an appropriate policy to use in attracting greater participation in the effort.  Lindberg et al. [84] The experience of certified paediatric nurses (CPNs) with the use of videoconferencing between the neonatal intensive care unit and the families' homes has been studied. Families were given a home videoconferencing unit, which allowed them to have contact and communicate with staff at the neonatal unit day and night. The results showed that the nurses found that videoconferencing helped them to assess the overall situation at home and facilitated the relationship between parents and the infant. The CPNs felt that they were able to provide security to the family. The use of videoconferencing was considered to be a generally positive experience and a tool to improve nursing care at home.  Lindberg et al. [85] Parents of preterm infants used real-time videoconferencing between their home and the neonatal intensive care unit (NICU) as a support after taking their infant home. Via video and sound in real-time, parents had access, day and night, to NICU staff. The results showed that security provided access to the staff and face-to-face supportive meetings. Parents experienced videoconferencing as positive, which empowered them and gave them confidence in their new situation of being at home with their infant.  Lindberg et al. [86] Videoconferencing was used between midwives and parents at home in order to support parents who were discharged early after childbirth. The main reasons for contact were routine and the most frequent advice concerned breastfeeding. The quality of sound and picture was judged to be good and very good. The results showed that the meetings with videoconferencing were easy to handle and useful for making assessments and were a valuable and functional complement to usual practice, almost like a real-life encounter. The results suggest that videoconferencing may be a useful tool in postpartum care.  Lutz et al. [87] The feasibility of using a hometelehealth system for assessing stroke patients' physical functions, depression, fear of falling, and their family caregivers' burdens was examined. A hometelehealth programme that was a stroke-specific, care coordination, hometelehealth (CCHT) programme was used. Data were transmitted via home telephone lines, which interfaced with a web-based programme that connected with registered nurses who reviewed the data and recorded information in the computerized patient record system. The outcome indicated tailoring CCHT to individual needs. The patients believed the home health programme was beneficial and served as an important safety net and assurance during the initial period of returning home after discharge. The results provide opportunities for tailoring the programme's implementation.  Lutz et al. [88] The purpose was to identify postdischarge needs of stroke patients; their caregivers described their experiences of using a care-coordination hometelehealth (CC/HT) programme to address their needs. All study participants believed that a hometelehealth programme could be beneficial to their stroke recovery at home, and that it provided a safety net and a sense of security that a healthcare professional was monitoring their health. The findings suggest that a comprehensive care-coordination programme that includes hometelehealth could aid veterans and their caregivers in managing stroke recovery across the continuum of care at home and within the community.  Mair et al. [89] An ethnographic study embedded in an RCT of home- telecare for people suffering acute exacerbation of chronic obstructive pulmonary disease (COPD) was conducted. Participants were randomized to receive either face-to-face home nursing support or a home- telecare support service. The telecare service consisted of a video-phone link and attachments that permitted remote physiological monitoring of blood pressure, pulse, temperature, and pulse oximetry. Both specialist respiratory nurses and patients took part in the trial and reported their experiences. The telecare service did not provide an interactional advantage for the nurses providing this service and did not fit with the nurses' views of the most appropriate or preferred use of their skills. The telecare service seemed unlikely to become normalized as part of routine healthcare delivery because the nursing team lacked confidence that it was a safe way to provide healthcare in this context, and it was not perceived as improving efficiency.  Marineau [90] People with acute infections transitioning in the home with support by an advance practice nurse used a telehealth system with advanced practice nurses (APNs) as a support when they were acutely ill. APNs used equipment to assess the physiological and psychological status of individuals transitioning from an acute infection in their home. This care included interventions conducted by the APN via telehealth, which mimicked all the essential components that would be accomplished in the hospital with the exception of being able to physically touch the participant. The transition that occurred when an individual with an acute infection was discharged from the hospital to the home supported by telehealth technology revealed an overall positive experience. The findings highlighted the importance of the participants having a sense of control when recovering from their illnesses, which could be achieved at home with a family member acting as a substitute nurse. The participants shared that the hospital environment may not be optimal for recovering from an illness.  McCall et al. [91] The feasibility of using mobile phone-based technology (that is, Advanced Symptom Management System in Palliative Care (ASyMSp)) was tested to monitor and manage symptoms reported by patients being cared for at home in the advanced stages of their illness and was carried out in two rural communities. The system was usable and acceptable to patients and the health professionals who cared for them.  McCann et al. [92] A mobile phone-based advanced symptom management system (ASyMS) on chemotherapy-related toxicity in patients with lung, breast, or colorectal cancer was evaluated. Patients used the mobile phone to record their symptoms, sending their reports directly to the nurses at their clinical site. Patients reported many benefits of using ASyMS including improved communication with health professionals and improvements in the management of their symptoms. ASyMS has the potential to positively impact the management of symptoms in patients receiving chemotherapy treatment.  McGee and Gray [93] A symptom management system was developed and implemented on personal digital assistants (PDAs) for use by cancer outpatients in their daily management of chemotherapy symptoms. The system allowed patients to record their symptoms at home and send these data to their cancer centre. Patients could view personalized self-care advice and more general medical information. In addition, cancer care nurses were alerted about significantly high symptom scores and could contact the patient by phone. The patients felt the system was rewarding, valuable, educational, and interesting but should be treated cautiously. Patients expected that using the system would be more challenging than they in fact rated it after the trial. They rated it more educational and more rewarding than traditional meetings. The staff anticipated that the system would be useful for monitoring patients' symptoms. After the trial, most of the staff suggested that the system had improved communication between them and the patients, and that the patients had immediate access to and contact with the hospital.  Miller et al. [94] The intervention was delivered by way of a device called the Health Buddy to patients who had undergone coronary artery bypass graft (CABG) with diabetes, which delivers “daily sessions” or script and was used for six weeks with assessment of symptoms such as fatigue and pain. No statistical differences between the intervention and the control groups were found. Improvements in psychosocial functioning were comparable between the two groups.  Moreno et al. [95] The impacts on Medicare costs of providing a particular type of home telemedicine to eligible Medicare beneficiaries with type 2 diabetes were estimated. Two cohorts of beneficiaries living in two medically underserved areas were randomized to intensive nurse case management via televisits or usual care. Informatics for Diabetes Education and Telemedicine (IDEATel) did not reduce Medicare costs at either site. Total costs were higher for the treatment group than for the control group. Although the telehealth system had modest effects on clinical outcomes (reported elsewhere), it did not reduce Medicare use or costs for health services.  Mullan et al. [96] An electronic diary for home monitoring by lung transplant candidates to improve communication between candidates and the transplant team was used. Candidates were randomized into control (following standard telephone-reporting procedures) and intervention (using an electronic diary to record and transmit a range of health-related measures) groups. Subjects used the diary without difficulty and with good compliance and were positive regarding contact based on diary use. There were no significant differences in clinical outcomes between groups. Changing diary questions might improve the effectiveness of electronic monitoring for lung transplant candidates.  Myers et al. [97] Impact of home-based monitoring on the care of patients with congestive heart failure was examined. Home-based tele-monitoring as a therapeutic tool was used. The effectiveness of home tele-monitoring in patients recently discharged from the hospital was assessed. Patients were provided home tele-monitoring for a two-month period following hospital discharge. Home visit frequency, patient rehospitalization rate, emergency department use, quality of life, and healthcare costs were compared to those a similar usual care. Patients in the tele-monitor group transmitted their weight, blood pressure, and oxygen saturation daily to a tele-monitor nurse, who evaluated each patient with a follow-up telephone call. Daily homecare tele-monitoring reduced the frequency of home-nursing visits, provided cost savings, and was associated with improved self-perceived quality of life.  Nilsson et al. [98] District nurses' (DN) experiences of using information and communication technology (ICT) to communicate with chronically ill people in their homes were described. An electronic messaging programme via computers and mobile phones with an Internet connection was used, enabling DNs and the ill people to exchange messages to and from anywhere. The programme comprised different virtual rooms, and communication was via text messages. The DNs felt that the technology increased accessibility to nursing care through a more direct communication with the ill person, meaning that a more trusting relationship could be created. The DNs also experienced that the use of ICT saved working time. This study indicates that the use of ICT for communication allowed the DN to better support a chronically ill person at home, leading to improved home nursing care. This method of communication cannot replace physical presence but can be seen as a complement to nursing care at home.  Nilsson et al. [10] People with serious chronic illnesses who used information and communication technology (ICT) to communicate with their district nurse were studied. The intervention was performed using an electronic messaging programme. The programme was accessible to any computer with an Internet connection. The programme consisted of different virtual rooms, where people could communicate using text messages. The participants' communication with the district nurse was improved because of easy accessibility and because they felt increased security. They felt there were fewer limitations and that their everyday life was improved, which can also be seen as an improvement in care.  Pangarakis et al. [99] Lung transplant recipients used a telemedicine device, that is, an electronic home spirometer, to gauge the function of their lungs when they were away from the hospital or clinic setting. Healthcare providers review transmitted spirometry tests and user's symptom responses to detect early signs of infection and or rejection. Current home spirometry users have questions, concerns, and preferences about spirometry that may influence their daily adherence. The spirometer had the capability to deliver feedback messages to potentially address these questions and concerns. Findings revealed categories for feedback messaging content such as education (general, lifestyle, and infection), goals, timing, technique, monitoring, and reminders (time sensitive, positive). Messages were created according to length, feasibility, past experience, and neutrality for electronic implementation. It is believed that pertinent automated electronic feedback messages will enhance home spirometry connection, raise confidence in spirometry usage, and influence daily adherence to the spirometry protocol. The content additionally serves as a foundation for establishing a plan of care individualized to each home spirometry user.  Phillips et al. [100] Telehealth interventions were designed to reduce the incidence of secondary conditions among people with mobility impairment resulting from spinal cord injury. Patients received a video-based intervention for nine weeks, a telephone-based intervention for nine weeks, or standard follow-up care. Participants were followed for at least one year to monitor days of hospitalization, depressive symptoms, and health-related quality of life. Health-related quality of life was measured using the Quality of Well-Being (QWB) scale. QWB scores did not differ significantly between the three intervention groups at the end of the intervention period. At year one after discharge, scores for those completing one year of enrollment were significantly higher for the intervention groups compared to standard care. Mean annual hospital days were 3.00 for the video group, 5.22 for the telephone group, and 7.95 for the standard care group.  Pierce et al. [101] A site on the World Wide Web, called Caring˜Web, for online education and support for caregivers of individuals with stroke was developed to provide web-based, in-home support and education for caregivers of persons with stroke during the first year after hospitalization. The educational needs of survivors of stroke and their caregivers were identified and information that these individuals sought was developed into an educational Tip of the Month component for Caring˜Web. The top 12 topics reported were used to create educational Tips of the Month on Caring˜Web.  Procter and Single [102] Remote devices for daily home-monitoring of vital signs of patients living with multiple complex conditions were implemented. The equipment was installed in the patient's home and programmed to prompt the patient to undertake these observations on a daily basis at an agreed-upon time. Results were downloaded to a central web-based server, which was accessed daily by the project nurse. The service reduced overall hospital admissions during the intervention compared to those before the intervention. The patients' and caregivers' confidence in managing diseases was increased. Home monitoring helped patients to communicate more effectively with the primary care team, which was thereby enabled to provide more effective responses to patients.  Przybylski et al. [103] Patients with implantable cardioverter defibrillators were provided with remote monitoring to increase their safety by early detection of technical or medical malfunctions and to decrease the number of follow-up visits. Medical and technical events were reported by the remote monitoring system as well as interruptions in monitoring longer than 14 days. The remote-monitoring system reported medical events in 48% of patients. In total, 32 event reports were generated due to the detection of ventricular tachycardia, ventricular fibrillation, ineffective defibrillation with maximal energy, and supraventricular tachycardia. There were no reports on technical abnormalities of the implantable cardioverter-defibrillator system. The longest break was caused by the patient's stay abroad. The remaining interruptions were caused by travel, hospitalisations, and a temporary stay in a place without sufficient GSM coverage. During the follow-up period, there were no interruptions in monitoring caused by transmitter or implantable cardioverter-defibrillator failure. Remote monitoring of implantable cardioverter-defibrillator recipients does not present technical difficulties and enables early detection of serious events in patients.  Quinn [104] Low-technology equipment was used to improve care for patients with heart failure enrolled in a home health agency. The nine-week intervention was targeted toward the home health nurses and included telephone and home visits, a teaching tool, digital scales, and a log/notebook filled out by the patients in the study. The intervention outcomes included decreased patient rehospitalisation, decreased symptoms of heart failure, and increased quality of life; it also improved the organization of nursing care for patients with heart failure. The common symptoms of heart failure such as fatigue, shortness of breath, and sleep disturbances were validated. The emergent care visits and reduced nursing visits allow provision of the care for patients with heart failure in a more effective and efficient manner than usual care.  Reis et al. [105] An interactive multimedia program is described that would assess the patient and family member's level of preparedness for specific caregiving functions for prostate cancer and provide tailored skill-building vignettes on caregiving techniques. This program is designed for a hybrid delivery utilizing both web-based resources and a CD-ROM. Feedback from prostate patients and family members from a cancer center on perceived needs for caregiving training underscores the potential value of a computer-supported intervention for some patients and families. Implementation of the software, marketing, and distribution will be guided in part by recent e-health experiences that leave many health professionals appropriately skeptical about the utility of such products. The concept of providing electronic health communication for consumers, particularly in the area of prostate cancer caregiving, is clearly valid for numerous reasons.  Safran et al. [106] Parental use of an Internet-based educational and emotional support system, Baby CareLink, in a regional NICU programme. Baby CareLink was installed in NICUs in four area hospitals. Parents were offered access from hospital terminals and from any other Internet access point. Data on use of the programme was collected by the computer system. Medicaid families who accessed three or more Baby CareLink web pages per day took their infants home 17.5 days sooner than families who used Baby CareLink less often. Among non-Medicaid families, more-frequent users of Baby CareLink took their infants home 14.3 days sooner. Self-help tools for parents may free up nursing resources for families with greater needs.  Sandberg et al. [107] Patients with diabetes were provided with a specially designed home telemedicine unit that allowed them to videoconference with nurse case managers (NCMs) and dietitians, upload blood glucose and blood pressure readings, and access educational materials and individualized data displays. Subjects and NCMs/dietitians participated in videoconferences every 4 to 6 weeks (with significant need, every 2 weeks) to educate patients, facilitate goal setting/self-management, and discuss concerns. Supportive interactions provided contact tailored to individual needs toward the goals of improved glycemic control, diabetes self-care, and other health outcomes. Providers were very satisfied with their experience and felt their efforts with patients were generally successful. Providers also identified a number of unique benefits of telehealth interventions, such as opportunities for more frequent contact with patients, greater relaxation and information due to the ability to interact with the patients in their own homes, increased ability to reach the underserved, more timely and accurate medical monitoring, and improved management of data. The primary disadvantages identified were technology problems and a concern about the lack of physical contact with patients.  Scalvini et al. [108] General practitioners received a portable electrocardiograph that transmitted a 12-lead ECG readout to a receiving station via a mobile or fixed telephone. ECG traces recorded were transferred, in real time, to receiving stations where cardiologists were available 24 hours a day for ECG referral and interactive tele-consultations. Patients in the home-based tele-monitoring group received a portable device that transferred by mobile or fixed telephone to a receiving station where a nurse was available for reporting and interactive tele-consultation. The patient could call the centre when needed (teleassistance) or the clinical team could call the patient for a scheduled appointment (tele-monitoring). At the first telephone contact, a lower number of general practitioners' patients than the home-based tele-monitoring patients were on beta blocker, diuretic, and angiotensin-converting enzyme (ACE)-inhibitor therapy. The mean number of telephone calls was 2.6 per patient in the general practitioner group and 16.6 per patient in the home-based tele-monitoring group. This program, involving the patients directly, is able to reduce hospitalizations and decompensation episodes. The telecardiology service is able to solve the majority of GPs' questions, combining their knowledge of their patients, with the cardiologists' expertise in problems connected with CHF. In this case, telemedicine could be an opportunity for the GPs to follow their patients, contributing to improved management, therapy, and appropriateness of hospital admissions.  Scalvini et al. [109] The feasibility of home-based tele-cardiology for patients with chronic heart failure (CHF) was assessed. CHF patients were enrolled into a programme of telephone followup and single-lead electrocardiography (ECG) monitoring. The patients transmitted their ECG data by fixed telephone line to a receiving station, where a nurse was available for an interactive tele-consultation. A total of 124 cardiovascular events were recorded. Modifications to therapy were suggested in response to 119 calls; hospital admissions were suggested for 13 patients, further investigations for 7, and a consultation with the patient's general practitioner for 13. Twenty-two ECG abnormalities were recorded. In 63 patients receiving the beta-blocker carvedilol, the mean dosage increased from 36 to 42 mg. In the previous year, there were 1.8 hospitalizations per patient, while in the follow-up period there was 0.2 hospitalization per patient. Following up CHF patients using a nurse-led tele-cardiology programme seems to be feasible and useful.  Schwarz et al. [110] The purpose was to examine whether tele-monitoring by an advanced-practice nurse reduced subsequent hospital readmissions, emergency department visits, costs, and risk of hospital readmission for patients with HF. Patient/caregiver dyads were randomized into two groups after discharge. Participants were interviewed soon after discharge and 3 months later about effects of tele-monitoring on depressive symptoms, quality of life, and caregiver mastery. There were no significant differences related to tele-monitoring for any outcomes. Caregiver mastery, informal social support, and electronic home monitoring were not significant predictors of risk of hospital readmission. Further studies should address the interaction between the advanced-practice nurse and follow-up intervention with tele-monitoring of patients with HF to better target those who are most likely to benefit.  Sevean et al. [111] Patients' and families' experiences with video telehealth consultations as a method of healthcare delivery in rural/remote communities were accessed. Patients' and families' experiences of their telehealth visits were centered on three key themes: lessening the burdens (costs of travel, accommodations, lost wages, lost time, and physical limitations); maximizing supports (access to family, friends, familiar home environment, nurses, and other care providers); and tailoring specific e-health systems to enhance patient and family needs.  Shea et al. [112] Participants in the intervention group received a home telemedicine unit (HTU) developed specifically for IDEATel (American Telecare, Inc., Eden Prairie, MN, USA). The HTU consisted of a web-enabled computer with modem connection to an existing telephone line. The HTU provided four major functions: videoconferencing over standard telephone service (POTS), allowing patients to interact with nurse case managers; remote monitoring of glucose and blood pressure with electronic upload and integration with dial-up Internet service-provider access to a web portal providing access to patients' own clinical data; secure web-based messaging with nurse case managers; and access to an educational website. Telemedicine case management improved glycemic control, blood pressure levels, and total and LDL cholesterol levels at one year of followup.  Smith et al. [113] The study determined the feasibility of using home audio/video telehealth equipment for administering nursing interventions to families, observing the client response, and collecting research data over specific intervals of time. The subjects were adult patients' nighttime mechanical ventilators for obstructive sleep apnea. Skin color, vital signs, spirometry, and pulse oximetry data collected simultaneously through telehealth equipment and through nurse observation in the home were the same. Nursing interventions, equipment demonstrations, visual illustrations, and audiotaped educational directions were used to facilitate patient care; they were transmitted across telehealth with a few exceptions. Costs of telehealth visits were less than traditional home visits, and client evaluations of telehealth were positive.  Smith et al. [114] Whether a telehealth intervention could improve compliance with continuous positive airway pressure (CPAP) by patients with sleep apnea was tested. These patients had been nonadherent to the initial three months of therapy, even after receiving the initial standard and then supplemental audiotaped/videotaped patient education for adhering to CPAP nightly. Interventions were delivered by nurses to two groups in their homes by telehealth over a 12-week period. Both groups rated telehealth delivery positively. Telehealth interventions are a potentially cost-effective service for increasing adherence to prescribed medical treatments.  Stricklin et al. [115] Patient response is a critical aspect of successful POC technology (point of care technology) implementation. The results of a pilot POC patient satisfaction study conducted at four home health agencies were presented. Results support patient/caregiver satisfaction with POC technology use during the home visit. The top variables influencing patient receptiveness to the nurse's use of the computer in the home are those that closely relate to general satisfaction with homecare services. The patients want to be the nurse's first priority and focus; they do not want to be upstaged by the computer. Provided the computer does not create the perception of taking time or attention from the patient or inhibit verbal interaction, patients are likely to accept the nurse's use of a POC computer.  Tang et al. [116] A pilot study on telepsychiatry was conducted. A videoconferencing link was established between a regional hospital and a care and attention home. Using this system, a psychogeriatric outreach team provided psychiatric assessments to residents of the care and attention home over 11 months. Videoconferencing was found to be highly feasible. It was acceptable to staff and patients and more cost-effective than on-site visits.  Terry et al. [117] The aim was to evaluate the effectiveness of telemedicine (TM) with digital cameras in treating wounds in a homecare setting. Subjects were randomly assigned to one of three groups. Telemedicine is a useful communication tool in wound management but with limited power when randomization does not include wound size or type. Two important benchmarks were established for home care.  Torp et al. [118] A pilot study of how information and communication technology (ICT) may contribute to health promotion among elderly spousal caregivers. The objective was to explore whether use of ICT by informal caregivers of frail elderly people living at home would enable them to gain more knowledge about chronic illness, caring, and coping; establish an informal support network; and reduce stress and related mental health problems. Potential participants were close relatives of an elderly person with a diagnosis of a chronic illness dwelling in the same household who wished to continue caring for their relative at home. Results did not reveal any reduction in caregivers' stress or mental health problems. Caregivers reported extensive use of the ICT service, more social contacts, and increased support and less need for information about chronic illness and caring. Contact with and support from other caregivers with similar experiences were particularly valued by participants. The intervention enhanced contacts with family and friends outside the caregiver network. Thus, it can be seen that ICT has the potential to contribute to health promotion among elderly spousal caregivers.  Wakefield et al. [119] A home-based intervention for heart failure was evaluated. Differences in nurse and patient communication profiles between two telehealth modes were compared: telephone and video-phone; longitudinal changes in communication, nurse perceptions, and patient satisfaction were evaluated. Nurses were more likely to use open-ended questions, back-channel responses, friendly jokes, and checks for understanding on the telephone compared to video-phone. Compliments were given and partnership was more common on the video-phone. Patients were more likely to give lifestyle information and approval comments on the telephone, and more closed-ended questions on the video-phone were used. Nurses' perceptions of the interactions were not different between the telephone and video-phone, nor did their perceptions change significantly over the course of the intervention. There were no significant differences in patient satisfaction between the telephone and video-phone.  van den Berg et al. [120] The GP (general practitioner) delegated routine home visits to qualified practice employees (registered nurses). Eligible patients were provided with telecare devices to monitor disease-related physiological values. The GPs agreed that delegating tasks to a qualified practice assistant relieves them in their daily work.  Varis et al. [121] A telemedicine system, that is, Doc@home, was evaluated to assist blood pressure treatment to reach better blood pressure control among hypertensive patients. Blood pressure control was improved during the three-month followup. Patient-to-Doc@home compliance was good, but study physicians found the system time consuming in the beginning. The Doc@home telemedicine system showed a promising approach in hypertension treatment but needs some further development and trained staff to become a still more practical alternative.  Whitten et al. [122] A telehospice project was conducted in urban and rural regions. Data from patients receiving tele-hospice services in their homes was collected. Nurses were the primary providers of tele-hospice services and initiated the majority of routine televisits. Patients were extremely satisfied with tele-hospice and often expressed frustration that nurses did not use the tele-hospice equipment more frequently.  Whitten and Mickus [123] A home telehealth program for patients with chronic obstructive pulmonary disease (COPD) and/or congestive heart failure (CHF) was evaluated. Patients diagnosed with COPD and/or CHF who were prescribed home healthcare services were randomly assigned to an experimental group where they received home health care through a combination of traditional face-to-face and telemedicine visits and a control group where only conventional home care was employed. In regard to patient perceptions of home telecare, patients were satisfied with the technology and the way that care was delivered via this modality.  Willems et al. [124] A nurse-led tele-monitoring intervention compared with regular care in asthma was evaluated. The control group received regular outpatient care, while the intervention group used an asthma monitor with modem at home, with an asthma nurse as the main caregiver. Clinical asthma symptoms and medical consumption were measured by using diaries. Asthma-specific quality of life was also measured. Improvement in followup but no statistically significant difference between the groups was observed. A tele-monitoring programme on its own is not a guarantee of success. The patient's perceptions of asthma-specific quality of life (daily functioning) should be a key element in asthma tele-monitoring programmes.  J. M. Winters and J. M. Winters [125] A variety of experienced healthcare practitioners performed functional assessments of stroke subjects using a collection of validated scales by varying approaches (face-to-face, low-bandwidth, and high-bandwidth videoconferencing) in a randomized order. In a second study, undergraduate nursing students performed similar performance measures and taught an unfamiliar individual how to programme and use an intravenous pump device, take a tympanic temperature, or draw up insulin in a syringe. In the third study, advanced-practice nursing students assessed vital signs and performed cardiopulmonary assessments on community-dwelling subjects using low-bandwidth and face-to-face approaches. Healthcare practitioners and students generally preferred high-bandwidth approaches over low-bandwidth alternatives when videoconferencing was used. Most participants and practitioners were satisfied with the encounters, regardless of the level of technology used.  Visco et al. [126] Telehealth Wound Care Program implemented at a hospital home health agency and a hospital was used where the wound care provided for one patient was included and described in the case study. Many benefits of telehealth as an adjunct to usual therapy in wound care were noted.  Vitacca et al. [127] The feasibility of telemedicine for home monitoring of patients with chronic respiratory failure (CRF) discharged from hospital was assessed. The patients transmitted pulsed arterial saturation (pSat) data via a telephone modem to a receiving station where a nurse was available for a teleconsultation. A respiratory physician was also available. Scheduled and ad hoc appointments were conducted. The home monitoring was feasible and useful for titration of oxygen, mechanical ventilation setting, and stabilization of relapses.  Vitacca et al. [128] The aim was primarily to evaluate reduction in hospitalisations and, secondly, exacerbations, general practitioner (GP) calls, and related cost effectiveness of teleassistance (TA) for patients with chronic respiratory failure. Patients were randomised to two groups: an intervention group entered a one-year TA programme while controls received traditional care. The TA group experienced significantly fewer hospitalisations, urgent GP visits, and acute exacerbations. COPD patients, as a separate group, had fewer hospitalisations, emergency room admissions, urgent GP calls, or exacerbations. After deduction of TA costs, the average overall cost for each patient was less than that for usual care. In chronic respiratory failure patients on oxygen or home mechanical ventilation, nurse-centred teleassistance prevents hospitalisations, while it is cost-effective. The chronic obstructive pulmonary disease group seems to have a greater advantage from teleassistance.  Vitacca et al. [129] The use of telemedicine in support of weaning from invasive mechanical ventilation on a woman at home by means of a telepneumology programme (TPP) is described. Under telephone assistance of a pulmonologist and a TPP nurse tutor, the pulsed arterial saturimetric (pSaT), heart rate (HR), and breathing pattern tracing monitoring were transmitted via a home telephone line and the aid of the caregiver. Many patients at home on ventilators could possibly be weaned through the use of remote monitoring and call center response, with only family/caregivers on-site.  Woodend et al. [130] The impact of three months of telehome monitoring on hospital readmission, quality of life, and functional status in patients with heart failure or angina was tested. The intervention consisted of videoconferencing and phone line transmission of weight, blood pressure, and electrocardiograms Tele-home monitoring significantly reduced the number of hospital readmissions and days spent in the hospital for patients with angina and improved quality of life and functional status in patients with heart failure or angina. Patients found the technology easy to use and were satisfied. Telehealth technologies are a viable means of providing home monitoring to patients with heart disease at high risk of hospital readmission to improve their self-care abilities.  Wälivaara et al. [131] District nurses (DNs) from four healthcare centres had access to different kinds of distance-spanning technology with mobile devices and used it in their health care at home. The results fall into 2 categories: the well-known technology at hospitals is new at home; the new technology opens up possibilities, but it also has limitations. The participants viewed the technology at home as something good and as something that could open up possibilities. At the same time, they placed the use of the technology in the hands of the staff, which indicates some degree of dissociation from the technology. The importance of personal meetings between patient and caregiver was very clearly stressed even when distance meetings could be performed and accepted. The participants expressed immense trust in the nursing staff and considered them responsible for the new technology at home.  Young et al. [132] The effectiveness of telephone and video-phone followup for children and families after a child's scoliosis surgery was evaluated. At discharge, those in the intervention group were provided with a video-phone operating on the ordinary telephone network (PSTN). Video-phone and telephone use provided care continuity for patients and their families following a child's back surgery. The relative effect of the video-phone and telephone technology depended on the fit between the characteristics of the patients and families and the capacities of the technology. When implementing telehealth for follow-up care, a participatory process is recommended to ensure a proper fit between user characteristics and technology. \""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "article_path = '/nfs/gns/literature/machine-learning/evaluation/time_complexity/articles/'\n",
    "all_files = sorted(glob.glob(article_path + '*.txt*'))\n",
    "result_json_dump_path = '/nfs/gns/literature/machine-learning/evaluation/time_complexity/flair/'\n",
    "\n",
    "offset = 26\n",
    "article_file_path = article_path+'PMC3649237_sentences.txt'\n",
    "with open(article_file_path, 'r') as f:\n",
    "    article_contents = f.read()\n",
    "    \n",
    "article_contents.replace('\\n','')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-50a17344004b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_contents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredicted_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentences, mini_batch_size, embedding_storage_mode, all_tag_prob, verbose)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mfiltered_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_empty_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# remove previous embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_filter_empty_sentences\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_filter_empty_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mfiltered_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             log.warning(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_filter_empty_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mfiltered_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             log.warning(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'tokens'"
     ]
    }
   ],
   "source": [
    "sentence = article_contents.replace('\\n','')\n",
    "Sentence(sentence, use_tokenizer=custom_tokenizer)\n",
    "predicted_sentences = flair_model.predict(sentence)\n",
    "predicted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 18:28:23,131 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:28:23,133 Ignore 87 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:28:34,796 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:28:34,798 Ignore 12 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:28:43,586 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:28:43,588 Ignore 2 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 18:29:01,087 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:01,089 Ignore 11 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:29:09,947 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:09,949 Ignore 13 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:29:23,310 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:23,312 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:29:29,744 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:29,746 Ignore 6 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 18:29:35,640 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:35,642 Ignore 3 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:29:44,937 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:44,939 Ignore 3 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:29:54,336 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:29:54,338 Ignore 2 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:30:06,877 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:30:06,879 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 18:30:25,320 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:30:25,322 Ignore 7 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:30:35,306 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:30:35,308 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:30:44,014 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:30:44,016 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:30:52,104 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:30:52,106 Ignore 2 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:31:03,973 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:31:03,975 Ignore 8 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 18:31:17,558 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:31:17,561 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 18:31:34,809 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:31:34,811 Ignore 7 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 18:31:54,391 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:31:54,393 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 18:32:17,508 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:32:17,510 Ignore 2 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:32:25,258 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:32:25,260 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 18:32:39,973 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:32:39,975 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:32:50,285 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:32:50,287 Ignore 5 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:33:01,078 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:33:01,080 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 18:33:15,100 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:33:15,103 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 18:33:36,329 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:33:36,331 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 18:34:10,215 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:34:10,217 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 18:34:26,772 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:34:26,774 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:34:43,427 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:34:43,429 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:34:56,298 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:34:56,300 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:35:12,933 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:35:12,935 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:35:25,377 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:35:25,380 Ignore 2 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 18:35:39,368 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:35:39,370 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:35:49,083 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:35:49,085 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:35:57,750 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:35:57,753 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 18:36:20,436 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:36:20,438 Ignore 12 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 18:36:44,969 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:36:44,971 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:36:54,539 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:36:54,541 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 18:37:14,654 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:37:14,656 Ignore 3 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:37:27,597 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:37:27,599 Ignore 77 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:37:37,310 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:37:37,312 Ignore 5 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:37:45,301 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:37:45,304 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 18:38:06,063 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:38:06,065 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:38:19,038 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:38:19,040 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:38:35,309 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:38:35,311 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 18:38:53,332 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:38:53,334 Ignore 9 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:39:02,323 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:39:02,326 Ignore 7 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:39:10,807 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:39:10,809 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:39:24,071 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 18:39:24,073 Ignore 9 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 18:39:45,650 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:39:45,652 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:39:57,274 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:39:57,276 Ignore 7 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:40:05,201 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:40:05,203 Ignore 2 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:40:16,515 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:40:16,518 Ignore 15 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:40:28,776 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:40:28,779 Ignore 1 sentence(s) with no tokens.\n",
      "0\n",
      "2019-12-05 18:40:29,108 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:40:29,110 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:40:40,182 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:40:40,185 Ignore 1 sentence(s) with no tokens.\n",
      "1\n",
      "2019-12-05 18:40:41,372 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:40:41,374 Ignore 6 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 18:41:05,030 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:41:05,032 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:41:16,562 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:41:16,564 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:41:26,134 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:41:26,136 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 18:41:47,870 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:41:47,872 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 18:42:13,941 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:13,943 Ignore 1 sentence(s) with no tokens.\n",
      "0\n",
      "2019-12-05 18:42:14,249 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:14,251 Ignore 1 sentence(s) with no tokens.\n",
      "0\n",
      "2019-12-05 18:42:14,587 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:14,588 Ignore 2 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:42:22,767 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:22,769 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:42:29,572 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:29,574 Ignore 42 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:42:39,034 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:39,036 Ignore 2 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:42:51,394 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:42:51,396 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 18:43:09,064 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:43:09,066 Ignore 2 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:43:20,774 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:43:20,776 Ignore 3 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:43:28,724 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:43:28,726 Ignore 22 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:43:41,479 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:43:41,481 Ignore 11 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:43:51,412 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:43:51,414 Ignore 2 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:44:01,718 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:01,720 Ignore 1 sentence(s) with no tokens.\n",
      "1\n",
      "2019-12-05 18:44:02,468 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:02,470 Ignore 5 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 18:44:21,488 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:21,490 Ignore 6 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:44:29,862 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:29,864 Ignore 1 sentence(s) with no tokens.\n",
      "1\n",
      "2019-12-05 18:44:30,790 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:30,792 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:44:37,926 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:37,928 Ignore 2 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:44:46,553 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:46,555 Ignore 2 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:44:56,330 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:44:56,332 Ignore 11 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:45:04,758 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:45:04,760 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:45:13,090 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:45:13,092 Ignore 2 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:45:25,006 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:45:25,009 Ignore 6 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:45:32,999 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:45:33,001 Ignore 3 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:45:42,385 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:45:42,387 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:45:53,724 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:45:53,726 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:46:01,625 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:46:01,627 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:46:17,968 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:46:17,970 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:46:30,385 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:46:30,387 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:46:43,525 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:46:43,527 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 18:47:02,347 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:47:02,349 Ignore 11 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 18:47:20,762 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:47:20,764 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:47:28,762 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:47:28,764 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:47:42,198 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:47:42,200 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 18:47:47,639 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:47:47,641 Ignore 5 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:47:58,284 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:47:58,286 Ignore 3 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 18:48:13,135 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 18:48:13,137 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:48:28,529 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:48:28,531 Ignore 9 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:48:36,868 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:48:36,870 Ignore 3 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 18:48:51,296 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:48:51,299 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:49:01,533 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:49:01,535 Ignore 4 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:49:08,463 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:49:08,465 Ignore 10 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:49:18,959 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:49:18,961 Ignore 4 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:49:28,555 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:49:28,557 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 18:49:48,029 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:49:48,031 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 18:50:14,762 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:50:14,764 Ignore 36 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:50:21,520 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:50:21,522 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 18:50:38,776 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:50:38,778 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 18:50:52,801 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:50:52,803 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:50:59,675 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:50:59,677 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:51:09,692 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:51:09,694 Ignore 19 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 18:51:16,843 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:51:16,845 Ignore 33 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:51:24,404 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:51:24,406 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:51:40,133 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:51:40,136 Ignore 12 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:51:49,737 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:51:49,739 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 18:52:10,875 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:52:10,878 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 18:52:38,458 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:52:38,461 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:52:51,583 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:52:51,585 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 18:53:18,358 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:53:18,360 Ignore 3 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:53:27,963 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:53:27,965 Ignore 6 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:53:38,034 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:53:38,036 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:53:49,182 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:53:49,184 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 18:54:09,490 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:54:09,492 Ignore 19 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:54:22,742 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:54:22,745 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 18:54:39,451 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:54:39,453 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:54:51,448 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:54:51,450 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:55:01,643 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:55:01,645 Ignore 2 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:55:11,589 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:55:11,590 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:55:24,236 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:55:24,239 Ignore 6 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 18:55:29,857 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:55:29,859 Ignore 23 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 18:55:45,072 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:55:45,075 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 18:55:57,214 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:55:57,216 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:56:10,574 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:56:10,577 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 18:56:25,073 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:56:25,075 Ignore 17 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:56:36,457 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:56:36,459 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:56:49,129 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:56:49,131 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:57:00,098 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:57:00,100 Ignore 2 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 18:57:12,734 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:57:12,736 Ignore 19 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 18:57:20,842 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:57:20,844 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 18:57:35,753 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:57:35,755 Ignore 2 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 18:57:55,164 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:57:55,167 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 18:58:05,845 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:58:05,847 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:58:15,245 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:58:15,247 Ignore 17 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 18:58:24,421 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:58:24,423 Ignore 9 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 18:58:30,902 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:58:30,904 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 18:58:53,434 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 18:58:53,436 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 18:59:15,228 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:59:15,230 Ignore 3 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 18:59:42,745 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:59:42,748 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 18:59:53,084 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 18:59:53,086 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:00:09,760 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:00:09,762 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:00:20,282 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:00:20,284 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:00:27,504 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:00:27,507 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:00:35,511 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:00:35,513 Ignore 150 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:00:49,648 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:00:49,650 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:01:05,954 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:01:05,956 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:01:21,967 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:01:21,969 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:01:39,115 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:01:39,117 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:01:57,060 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:01:57,062 Ignore 15 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:02:10,711 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:02:10,713 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:02:17,822 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:02:17,824 Ignore 14 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:02:24,933 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:02:24,935 Ignore 6 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:02:41,657 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:02:41,659 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:02:58,085 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:02:58,087 Ignore 17 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:03:05,845 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:03:05,847 Ignore 2 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:03:15,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:03:15,195 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:03:31,627 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:03:31,629 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:03:46,753 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:03:46,755 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:03:56,023 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:03:56,025 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 19:04:25,080 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:04:25,082 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:04:33,871 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:04:33,873 Ignore 37 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:04:44,397 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:04:44,400 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 19:05:09,443 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:05:09,445 Ignore 5 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:05:20,270 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:05:20,272 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 19:05:38,955 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:05:38,957 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 19:06:05,664 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:06:05,666 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 19:06:29,272 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:06:29,274 Ignore 10 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:06:40,612 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:06:40,615 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:06:56,757 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:06:56,759 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:07:11,658 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:07:11,660 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 19:07:37,657 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:07:37,659 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:07:55,414 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:07:55,416 Ignore 3 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:08:01,285 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:08:01,287 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:08:10,030 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:08:10,032 Ignore 40 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:08:21,601 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:08:21,603 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:08:37,839 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:08:37,841 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:08:52,832 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:08:52,834 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:09:05,703 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:09:05,705 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:09:16,291 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:09:16,293 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:09:26,594 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:09:26,596 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:09:41,682 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:09:41,684 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:09:55,050 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:09:55,052 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:10:03,374 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:10:03,376 Ignore 10 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:10:09,953 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:10:09,955 Ignore 2 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:10:20,893 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:10:20,895 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 19:10:42,878 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 19:10:42,880 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:10:59,201 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:10:59,203 Ignore 7 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 19:11:28,474 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:11:28,477 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:11:41,433 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:11:41,435 Ignore 9 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:11:49,254 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:11:49,256 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 19:12:12,199 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:12:12,201 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:12:20,734 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:12:20,736 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:12:26,943 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:12:26,945 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:12:45,337 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:12:45,339 Ignore 27 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:12:59,400 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:12:59,402 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:13:14,981 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:13:14,983 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:13:28,597 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:13:28,599 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:13:37,444 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:13:37,445 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 19:14:00,535 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:14:00,537 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 19:14:29,004 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:14:29,006 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:14:35,645 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:14:35,647 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:14:44,223 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:14:44,225 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:14:55,785 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:14:55,787 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:15:11,291 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:15:11,293 Ignore 5 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:15:19,680 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:15:19,682 Ignore 2 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:15:35,023 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:15:35,025 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:15:48,659 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:15:48,661 Ignore 7 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:16:00,656 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:16:00,657 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 19:16:21,972 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:16:21,975 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:16:28,357 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:16:28,359 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 19:16:54,941 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:16:54,943 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:17:10,056 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:17:10,058 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:17:22,198 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:17:22,200 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:17:35,964 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:17:35,966 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:17:47,440 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:17:47,442 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:18:03,942 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:18:03,944 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:18:18,954 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:18:18,956 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 19:18:38,415 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:18:38,417 Ignore 2 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:18:47,806 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:18:47,808 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:18:54,632 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:18:54,634 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:19:11,394 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:19:11,395 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:19:23,582 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:19:23,585 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 19:19:43,313 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:19:43,315 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:20:00,551 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:20:00,553 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:20:11,712 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:20:11,714 Ignore 28 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:20:21,489 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:20:21,491 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:20:37,990 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:20:37,992 Ignore 9 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:20:48,357 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:20:48,359 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:21:01,469 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:21:01,471 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 19:21:24,430 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:21:24,433 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:21:38,903 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:21:38,905 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 19:22:07,885 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:22:07,887 Ignore 11 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:22:17,046 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:22:17,048 Ignore 2 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 19:22:41,920 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:22:41,922 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-05 19:23:13,308 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 19:23:13,311 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:23:27,553 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:23:27,555 Ignore 8 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:23:42,029 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:23:42,031 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:23:50,610 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:23:50,612 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 19:24:09,643 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:24:09,645 Ignore 8 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:24:22,499 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:24:22,501 Ignore 3 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:24:35,618 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:24:35,620 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:24:42,191 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:24:42,194 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:24:51,804 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:24:51,806 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:25:03,362 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:25:03,364 Ignore 3 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:25:17,941 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:25:17,943 Ignore 5 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:25:31,765 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:25:31,767 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:25:42,157 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:25:42,160 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:25:57,674 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:25:57,676 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:26:08,215 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:26:08,217 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:26:20,732 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:26:20,734 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:26:26,947 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:26:26,949 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:26:38,971 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:26:38,973 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:26:48,503 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:26:48,505 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-05 19:27:19,314 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:27:19,317 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:27:33,010 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:27:33,012 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:27:49,661 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:27:49,664 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:28:02,863 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:28:02,866 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:28:17,878 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:28:17,880 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:28:27,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:28:27,804 Ignore 1 sentence(s) with no tokens.\n",
      "35\n",
      "2019-12-05 19:29:02,974 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:29:02,976 Ignore 15 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:29:12,509 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:29:12,511 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:29:26,695 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:29:26,697 Ignore 13 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:29:38,414 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:29:38,417 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:29:47,021 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:29:47,023 Ignore 3 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:29:59,302 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:29:59,304 Ignore 8 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:30:14,047 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:30:14,050 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:30:22,241 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:30:22,243 Ignore 13 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:30:33,764 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:30:33,767 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 19:30:54,923 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:30:54,925 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:31:11,649 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:31:11,651 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:31:21,739 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:31:21,741 Ignore 35 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:31:29,921 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:31:29,923 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 19:31:56,304 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:31:56,306 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:32:06,868 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:32:06,870 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:32:16,066 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:32:16,068 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 19:32:40,020 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:32:40,022 Ignore 4 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:32:51,267 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:32:51,269 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:33:03,433 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:33:03,435 Ignore 84 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:33:14,754 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:33:14,756 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 19:33:34,838 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:33:34,840 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:33:46,542 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:33:46,544 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:34:01,279 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:34:01,282 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:34:08,007 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:34:08,009 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:34:15,855 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 19:34:15,857 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:34:28,511 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:34:28,513 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:34:46,479 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:34:46,481 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:34:58,698 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:34:58,700 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:35:15,066 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:35:15,068 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:35:32,982 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:35:32,984 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:35:41,437 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:35:41,440 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:35:49,602 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:35:49,604 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:35:57,129 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:35:57,131 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:36:08,867 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:36:08,869 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:36:25,764 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:36:25,766 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:36:35,108 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:36:35,110 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:36:42,503 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:36:42,504 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 19:37:16,619 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:37:16,621 Ignore 5 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:37:30,013 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:37:30,015 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:37:39,277 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:37:39,279 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:37:45,293 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:37:45,295 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:38:00,924 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:38:00,927 Ignore 3 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:38:08,403 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:38:08,405 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:38:17,998 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:38:18,000 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:38:29,098 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:38:29,100 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:38:47,305 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:38:47,307 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:38:53,829 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:38:53,832 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:39:01,586 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:39:01,588 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:39:10,990 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:39:10,992 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 19:39:33,475 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:39:33,478 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 19:39:55,018 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:39:55,020 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:40:08,371 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:40:08,373 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:40:24,806 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:40:24,808 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:40:33,138 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:40:33,140 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 19:40:53,008 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:40:53,010 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:41:06,491 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:41:06,493 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:41:19,644 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:41:19,646 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:41:33,190 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:41:33,192 Ignore 6 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:41:40,367 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:41:40,369 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 19:41:45,891 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:41:45,893 Ignore 10 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:41:52,945 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:41:52,947 Ignore 2 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:42:01,813 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:42:01,814 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:42:13,880 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:42:13,882 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:42:28,583 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:42:28,586 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:42:43,689 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:42:43,691 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:42:51,390 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:42:51,393 Ignore 35 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 19:43:07,623 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:43:07,625 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 19:43:26,507 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:43:26,509 Ignore 23 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:43:37,544 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:43:37,547 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:43:45,834 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:43:45,836 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:43:56,347 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:43:56,349 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:44:08,952 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:44:08,954 Ignore 18 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:44:16,346 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:44:16,348 Ignore 35 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:44:22,695 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 19:44:22,697 Ignore 2 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:44:38,135 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:44:38,137 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 19:44:58,100 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:44:58,102 Ignore 3 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:45:07,298 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:45:07,300 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:45:21,015 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:45:21,017 Ignore 10 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:45:28,048 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:45:28,050 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:45:34,796 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:45:34,798 Ignore 5 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:45:41,610 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:45:41,612 Ignore 102 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:45:59,444 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:45:59,446 Ignore 9 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:46:07,919 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:46:07,922 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:46:16,135 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:46:16,137 Ignore 55 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 19:46:21,139 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:46:21,141 Ignore 50 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:46:28,699 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:46:28,701 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:46:43,102 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:46:43,104 Ignore 17 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:46:52,864 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:46:52,866 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:47:05,455 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:47:05,457 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:47:19,288 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:47:19,290 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:47:37,817 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:47:37,820 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 19:48:00,747 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:48:00,749 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 19:48:05,582 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:48:05,585 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:48:18,954 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:48:18,956 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 19:48:34,010 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:48:34,012 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:48:44,263 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:48:44,266 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 19:49:12,153 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:49:12,155 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:49:19,578 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:49:19,580 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:49:32,905 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:49:32,907 Ignore 17 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:49:46,396 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:49:46,398 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:50:04,727 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:50:04,729 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:50:12,935 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:50:12,938 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:50:22,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:50:22,195 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 19:50:41,383 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:50:41,385 Ignore 14 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 19:51:04,443 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:51:04,446 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:51:18,913 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:51:18,915 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 19:51:26,932 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:51:26,934 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 19:51:50,345 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:51:50,347 Ignore 34 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 19:52:10,841 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:52:10,844 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:52:20,478 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:52:20,480 Ignore 6 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 19:52:47,282 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:52:47,284 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 19:52:54,008 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:52:54,010 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 19:53:16,009 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:53:16,011 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:53:33,538 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:53:33,540 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 19:53:42,581 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:53:42,583 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:53:54,387 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:53:54,389 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 19:54:16,808 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:54:16,810 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:54:28,621 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:54:28,624 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:54:41,240 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:54:41,242 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:54:47,703 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:54:47,705 Ignore 3 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:54:58,410 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:54:58,412 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 19:55:17,136 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:55:17,138 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:55:27,555 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 19:55:27,557 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:55:38,679 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:55:38,681 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 19:55:44,086 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:55:44,088 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 19:56:12,069 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:56:12,071 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 19:56:26,574 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:56:26,576 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:56:39,641 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:56:39,643 Ignore 3 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:56:57,513 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:56:57,515 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 19:57:21,641 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:57:21,643 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 19:57:33,058 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:57:33,060 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 19:57:50,211 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:57:50,213 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:58:00,183 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:58:00,185 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 19:58:12,267 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:58:12,270 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 19:58:22,144 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:58:22,146 Ignore 64 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 19:58:56,451 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:58:56,453 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 19:59:14,570 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:59:14,572 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 19:59:36,246 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:59:36,248 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 19:59:48,994 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:59:48,996 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 19:59:55,209 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 19:59:55,211 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:00:13,211 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:00:13,213 Ignore 24 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:00:24,684 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:00:24,686 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 20:00:47,318 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:00:47,320 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:00:55,983 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:00:55,985 Ignore 3 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:01:01,928 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:01:01,930 Ignore 2 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:01:21,245 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:01:21,247 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:01:29,115 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:01:29,117 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:01:36,033 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:01:36,034 Ignore 3 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:01:52,674 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:01:52,676 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:02:05,354 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:02:05,356 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:02:23,913 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:02:23,915 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:02:37,745 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:02:37,747 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:02:47,406 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:02:47,408 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:03:07,507 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:03:07,509 Ignore 13 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:03:20,591 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:03:20,593 Ignore 9 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:03:28,708 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:03:28,710 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 20:03:49,310 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:03:49,312 Ignore 15 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:03:58,182 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:03:58,184 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 20:04:24,341 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:04:24,343 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:04:37,827 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:04:37,829 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:04:54,295 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:04:54,297 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:05:06,687 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:05:06,689 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:05:20,038 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:05:20,040 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 20:05:41,780 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:05:41,782 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:05:55,515 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:05:55,517 Ignore 2 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:06:03,830 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:06:03,832 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 20:06:27,793 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:06:27,795 Ignore 152 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:06:37,503 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:06:37,505 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:06:48,682 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:06:48,684 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:06:55,167 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:06:55,168 Ignore 3 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:07:12,848 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:07:12,851 Ignore 36 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 20:07:39,236 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 20:07:39,238 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:07:47,217 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:07:47,219 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 20:08:08,067 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:08:08,069 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:08:18,241 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:08:18,243 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:08:32,642 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:08:32,644 Ignore 47 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:08:47,570 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:08:47,571 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:08:56,114 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:08:56,116 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:09:05,404 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:09:05,406 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 20:09:29,093 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:09:29,095 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:09:44,424 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:09:44,426 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:09:55,816 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:09:55,818 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:10:06,251 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:10:06,253 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:10:22,372 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:10:22,374 Ignore 8 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:10:32,337 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:10:32,339 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:10:44,620 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:10:44,622 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:11:04,969 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:11:04,972 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:11:14,147 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:11:14,149 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:11:28,443 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:11:28,445 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:11:45,318 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:11:45,320 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:12:01,650 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:12:01,652 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 20:12:06,904 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:12:06,906 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:12:14,796 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:12:14,798 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:12:29,063 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:12:29,065 Ignore 6 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:12:39,270 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:12:39,272 Ignore 3 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 20:13:01,446 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:13:01,448 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:13:16,764 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:13:16,766 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:13:28,490 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:13:28,492 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:13:34,497 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:13:34,499 Ignore 30 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:13:49,338 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:13:49,340 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:13:59,379 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:13:59,381 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:14:06,683 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:14:06,685 Ignore 4 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:14:16,105 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:14:16,107 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:14:26,686 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:14:26,688 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:14:36,651 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:14:36,653 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:14:56,501 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:14:56,503 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:15:12,991 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:15:12,993 Ignore 52 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:15:24,476 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:15:24,479 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:15:44,140 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:15:44,142 Ignore 253 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:15:51,828 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:15:51,830 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:16:09,814 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:16:09,816 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:16:28,203 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:16:28,205 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:16:36,909 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:16:36,911 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:16:49,588 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:16:49,591 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 20:17:12,532 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:17:12,534 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:17:22,987 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:17:22,989 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:17:32,934 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:17:32,936 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:17:45,707 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:17:45,709 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:18:02,960 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:18:02,962 Ignore 17 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:18:21,628 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:18:21,630 Ignore 5 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:18:38,685 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 20:18:38,687 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:18:52,903 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:18:52,905 Ignore 23 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:19:02,305 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:19:02,307 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:19:11,778 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:19:11,780 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:19:22,066 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:19:22,068 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:19:41,446 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:19:41,448 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:19:51,597 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:19:51,599 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:19:59,598 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:19:59,600 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:20:10,439 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:20:10,441 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 20:20:36,863 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:20:36,865 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:20:47,420 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:20:47,422 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 20:21:09,029 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:21:09,031 Ignore 10 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:21:19,658 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:21:19,661 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:21:35,786 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:21:35,789 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:21:52,701 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:21:52,703 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:22:02,417 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:22:02,419 Ignore 22 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:22:11,747 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:22:11,749 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:22:23,767 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:22:23,769 Ignore 44 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:22:30,221 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:22:30,223 Ignore 116 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 20:22:59,550 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:22:59,552 Ignore 43 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:23:08,644 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:23:08,646 Ignore 613 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:23:20,233 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:23:20,235 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:23:34,975 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:23:34,978 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:23:42,311 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:23:42,313 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:24:00,090 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:24:00,092 Ignore 24 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:24:19,509 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:24:19,511 Ignore 2 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:24:34,474 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:24:34,476 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:24:40,972 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:24:40,974 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:24:52,641 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:24:52,644 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 20:25:14,234 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:25:14,236 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:25:23,169 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:25:23,172 Ignore 36 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 20:25:47,637 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:25:47,640 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:26:02,440 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:26:02,442 Ignore 4 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:26:16,015 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:26:16,017 Ignore 8 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:26:22,908 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:26:22,910 Ignore 3 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:26:35,169 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:26:35,171 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:26:45,186 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:26:45,188 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:26:56,865 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:26:56,867 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:27:09,850 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:27:09,852 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 20:27:36,921 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:27:36,923 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:27:48,036 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:27:48,039 Ignore 83 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:27:56,486 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:27:56,489 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:28:06,512 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:28:06,514 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:28:18,335 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:28:18,337 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:28:33,668 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:28:33,670 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 20:29:00,463 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:29:00,465 Ignore 3 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:29:17,632 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:29:17,634 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 20:29:23,186 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:29:23,188 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:29:35,871 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:29:35,873 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:29:45,630 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 20:29:45,632 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:29:54,759 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:29:54,761 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:30:05,690 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:30:05,692 Ignore 51 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 20:30:34,273 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:30:34,275 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:30:46,368 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:30:46,370 Ignore 4 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:30:52,202 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:30:52,204 Ignore 27 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:31:12,415 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:31:12,417 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:31:24,507 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:31:24,509 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:31:39,468 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:31:39,470 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:31:49,238 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:31:49,240 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:32:05,391 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:32:05,393 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:32:23,240 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:32:23,242 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:32:34,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:32:34,804 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:32:54,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:32:54,804 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 20:33:24,341 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:33:24,343 Ignore 72 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:33:43,133 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:33:43,135 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:33:59,431 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:33:59,433 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:34:18,728 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:34:18,730 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 20:34:48,033 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:34:48,036 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:34:59,644 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:34:59,646 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:35:11,353 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:35:11,355 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:35:30,685 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:35:30,687 Ignore 19 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:35:36,384 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:35:36,386 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:35:44,356 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:35:44,358 Ignore 94 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:35:51,556 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:35:51,558 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:36:01,588 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:36:01,590 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 20:36:23,069 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:36:23,071 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:36:31,648 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:36:31,650 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:36:41,471 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:36:41,473 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:36:53,360 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:36:53,362 Ignore 3 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:37:00,703 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:00,705 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:37:15,432 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:15,434 Ignore 7 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:37:21,144 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:21,146 Ignore 6 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:37:33,614 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:33,616 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:37:41,357 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:41,359 Ignore 8 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:37:47,762 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:47,764 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:37:55,254 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:37:55,256 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:38:03,927 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:38:03,929 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:38:17,699 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:38:17,701 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 20:38:22,631 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:38:22,633 Ignore 14 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:38:29,677 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:38:29,679 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:38:39,707 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:38:39,709 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:38:59,652 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:38:59,654 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:39:09,918 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:39:09,920 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 20:39:31,808 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:39:31,810 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:39:42,989 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:39:42,991 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:39:54,112 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:39:54,114 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:40:13,361 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:40:13,363 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:40:27,495 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:40:27,497 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:40:47,748 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 20:40:47,750 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:41:00,462 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:41:00,464 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:41:14,687 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:41:14,689 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:41:31,017 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:41:31,019 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:41:45,288 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:41:45,290 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:42:00,674 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:42:00,676 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:42:16,470 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:42:16,473 Ignore 275 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:42:22,894 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:42:22,897 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:42:32,102 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:42:32,104 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:42:43,306 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:42:43,308 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:42:56,759 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:42:56,761 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:43:05,126 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:43:05,128 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:43:12,664 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:43:12,666 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:43:23,381 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:43:23,383 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 20:43:46,450 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:43:46,451 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:43:55,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:43:55,804 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 20:44:01,326 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:44:01,328 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:44:14,893 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:44:14,895 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:44:22,820 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:44:22,822 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:44:30,117 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:44:30,119 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:44:39,884 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:44:39,886 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:44:49,695 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:44:49,697 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:45:02,289 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:45:02,292 Ignore 2 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 20:45:30,929 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:45:30,931 Ignore 5 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:45:49,832 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:45:49,834 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:46:02,202 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:46:02,204 Ignore 3 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-05 20:46:35,640 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:46:35,642 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:46:44,880 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:46:44,882 Ignore 4 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:47:03,898 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:47:03,900 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 20:47:23,321 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:47:23,323 Ignore 230 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:47:36,965 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:47:36,968 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:47:52,021 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:47:52,023 Ignore 7 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 20:48:14,985 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:48:14,987 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:48:23,608 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:48:23,610 Ignore 11 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:48:31,170 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:48:31,172 Ignore 25 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:48:40,463 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:48:40,465 Ignore 8 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:48:58,651 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:48:58,653 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:49:09,200 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:49:09,202 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:49:18,967 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:49:18,970 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:49:26,762 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:49:26,764 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:49:36,548 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:49:36,550 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 20:49:42,094 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:49:42,096 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 20:49:59,630 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:49:59,632 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:50:08,458 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:50:08,459 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:50:16,556 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:50:16,558 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:50:32,077 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:50:32,079 Ignore 86 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:50:42,219 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:50:42,222 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:50:58,884 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:50:58,887 Ignore 3 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:51:06,351 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:51:06,353 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:51:26,575 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 20:51:26,577 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 20:51:42,564 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:51:42,567 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:51:50,156 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:51:50,158 Ignore 23 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:51:58,276 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:51:58,278 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:52:05,665 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:52:05,667 Ignore 4 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:52:12,099 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:52:12,101 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 20:52:19,303 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:52:19,304 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:52:29,888 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:52:29,890 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:52:39,093 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:52:39,095 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 20:53:06,666 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:53:06,668 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:53:16,866 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:53:16,868 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:53:30,954 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:53:30,957 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:53:47,989 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:53:47,991 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 20:54:01,702 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:01,705 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:54:09,689 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:09,692 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:54:17,922 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:17,924 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:54:27,590 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:27,592 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:54:35,537 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:35,539 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:54:46,959 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:46,961 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 20:54:52,842 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:54:52,844 Ignore 303 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:55:02,052 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:55:02,054 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 20:55:10,298 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:55:10,300 Ignore 3 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 20:55:15,403 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:55:15,405 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 20:55:27,123 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:55:27,125 Ignore 68 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 20:55:47,401 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:55:47,403 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:55:58,763 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:55:58,765 Ignore 2 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 20:56:20,304 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:56:20,306 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:56:35,848 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:56:35,850 Ignore 1 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-05 20:57:12,284 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:57:12,286 Ignore 7 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:57:29,796 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:57:29,798 Ignore 63 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 20:57:40,318 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:57:40,320 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:57:57,166 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:57:57,169 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 20:58:22,329 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:58:22,332 Ignore 219 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 20:58:36,801 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:58:36,803 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 20:58:49,931 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:58:49,933 Ignore 175 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:59:06,259 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:59:06,261 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 20:59:14,790 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:59:14,791 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:59:24,868 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:59:24,870 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 20:59:41,639 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:59:41,641 Ignore 107 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 20:59:52,400 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 20:59:52,402 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:00:11,071 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:00:11,073 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:00:23,397 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:00:23,399 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:00:35,592 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:00:35,594 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:00:54,344 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:00:54,346 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:01:08,004 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:01:08,006 Ignore 19 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:01:14,456 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:01:14,459 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:01:24,035 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:01:24,038 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:01:39,797 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:01:39,799 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:01:49,676 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:01:49,678 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:02:07,853 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 21:02:07,855 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 21:02:28,246 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:02:28,248 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:02:39,836 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:02:39,838 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:02:47,916 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:02:47,918 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:03:04,040 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:03:04,042 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:03:19,389 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:03:19,391 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:03:32,880 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:03:32,882 Ignore 10 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:03:39,695 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:03:39,697 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 21:04:04,517 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:04:04,519 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:04:14,094 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:04:14,096 Ignore 26 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 21:04:31,332 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:04:31,334 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:04:42,862 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:04:42,864 Ignore 4 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:04:55,531 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:04:55,533 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:05:06,678 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:05:06,680 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:05:18,761 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:05:18,764 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:05:33,399 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:05:33,401 Ignore 5 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:05:43,338 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:05:43,340 Ignore 16 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:05:53,650 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:05:53,652 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:06:04,109 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:06:04,111 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:06:17,910 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:06:17,912 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:06:26,985 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:06:26,987 Ignore 207 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:06:34,939 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:06:34,941 Ignore 17 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:06:44,376 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:06:44,379 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:06:53,945 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:06:53,947 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:07:19,672 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:07:19,674 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:07:25,938 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:07:25,940 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:07:35,803 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:07:35,805 Ignore 2 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:07:50,629 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:07:50,632 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:08:03,699 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:08:03,701 Ignore 18 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:08:19,931 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:08:19,933 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 21:08:40,840 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:08:40,842 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:08:58,621 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:08:58,623 Ignore 51 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 21:09:22,564 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:09:22,566 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:09:38,935 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:09:38,937 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:09:55,243 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:09:55,246 Ignore 37 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:10:03,831 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:10:03,833 Ignore 23 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:10:22,788 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:10:22,790 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:10:30,685 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:10:30,688 Ignore 2 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:10:36,891 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:10:36,893 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:10:50,196 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:10:50,198 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:10:58,420 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:10:58,422 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:11:14,829 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:11:14,831 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:11:24,943 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:11:24,945 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:11:33,346 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:11:33,348 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:11:41,885 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:11:41,887 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:11:50,711 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:11:50,713 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:12:10,128 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:12:10,129 Ignore 3 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:12:35,964 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:12:35,966 Ignore 2 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:12:43,587 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:12:43,589 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:12:59,116 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 21:12:59,118 Ignore 20 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:13:10,585 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:13:10,587 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 21:13:40,085 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:13:40,087 Ignore 1 sentence(s) with no tokens.\n",
      "48\n",
      "2019-12-05 21:14:28,125 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:14:28,127 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:14:41,760 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:14:41,762 Ignore 2 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:14:56,249 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:14:56,251 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 21:15:15,886 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:15:15,888 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:15:23,514 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:15:23,516 Ignore 19 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:15:32,587 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:15:32,589 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:15:48,940 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:15:48,942 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:16:00,035 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:16:00,036 Ignore 29 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:16:12,297 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:16:12,299 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 21:16:36,160 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:16:36,163 Ignore 13 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 21:16:59,164 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:16:59,166 Ignore 17 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:17:11,185 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:17:11,187 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:17:27,240 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:17:27,242 Ignore 5 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:17:34,778 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:17:34,780 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:17:49,826 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:17:49,828 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:17:56,296 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:17:56,299 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:18:15,636 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:18:15,638 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:18:26,715 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:18:26,716 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:18:38,208 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:18:38,210 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:18:48,779 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:18:48,781 Ignore 1 sentence(s) with no tokens.\n",
      "48\n",
      "2019-12-05 21:19:37,259 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:19:37,261 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:19:44,036 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:19:44,038 Ignore 9 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:20:02,251 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:20:02,253 Ignore 17 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 21:20:19,510 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:20:19,512 Ignore 30 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:20:30,378 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:20:30,380 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:20:41,511 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:20:41,513 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 21:21:03,296 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:21:03,298 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:21:10,684 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:21:10,686 Ignore 326 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:21:18,832 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:21:18,835 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:21:30,116 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:21:30,119 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:21:47,846 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:21:47,848 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:21:57,157 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:21:57,159 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:22:10,928 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:22:10,930 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:22:30,499 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:22:30,501 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 21:22:52,583 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:22:52,585 Ignore 27 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:23:04,113 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:23:04,115 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:23:11,831 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:23:11,833 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 21:23:28,492 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:23:28,494 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 21:23:49,768 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:23:49,770 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:24:07,335 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:24:07,337 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:24:21,362 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:24:21,364 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:24:30,392 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:24:30,394 Ignore 2 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:24:41,286 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:24:41,288 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-05 21:25:14,230 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:25:14,232 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:25:27,443 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:25:27,446 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:25:39,913 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:25:39,916 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:25:48,947 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 21:25:48,949 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:26:01,277 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:26:01,279 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 21:26:28,565 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:26:28,567 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:26:38,209 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:26:38,211 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:26:45,455 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:26:45,457 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:26:57,827 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:26:57,829 Ignore 2 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:27:08,177 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:27:08,179 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:27:25,848 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:27:25,850 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 21:27:55,874 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:27:55,877 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 21:28:19,004 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:28:19,006 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:28:34,775 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:28:34,777 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:28:45,878 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:28:45,879 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 21:29:07,748 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:29:07,750 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:29:22,317 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:29:22,319 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:29:33,644 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:29:33,646 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:29:42,804 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:29:42,806 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:29:56,700 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:29:56,701 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:30:02,526 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:30:02,528 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 21:30:25,942 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:30:25,944 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:30:41,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:30:41,804 Ignore 2 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:30:56,952 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:30:56,954 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:31:04,498 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:31:04,500 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:31:16,611 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:31:16,613 Ignore 4 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:31:32,406 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:31:32,408 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-05 21:32:12,525 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:32:12,527 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:32:27,410 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:32:27,412 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:32:41,373 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:32:41,375 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:32:54,548 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:32:54,551 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:33:06,296 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:33:06,298 Ignore 42 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:33:32,228 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:33:32,230 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:33:41,558 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:33:41,560 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:33:50,130 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:33:50,132 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:34:05,344 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:34:05,346 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 21:34:33,529 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:34:33,531 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:34:47,712 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:34:47,714 Ignore 9 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:35:00,961 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:35:00,963 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:35:14,809 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:35:14,811 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 21:35:19,961 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:35:19,963 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:35:37,468 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:35:37,470 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:35:50,125 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:35:50,127 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:36:01,989 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:36:01,991 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:36:16,979 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:36:16,981 Ignore 9 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:36:23,777 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:36:23,779 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:36:41,277 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:36:41,279 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 21:37:10,898 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:37:10,900 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:37:25,317 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:37:25,319 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:37:32,500 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:37:32,502 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 21:37:56,604 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:37:56,606 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:38:12,873 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:38:12,875 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 21:38:34,098 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 21:38:34,100 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:38:41,618 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:38:41,620 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 21:39:01,257 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:39:01,259 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:39:13,246 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:39:13,248 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:39:22,333 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:39:22,335 Ignore 5 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 21:39:41,826 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:39:41,828 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 21:39:56,746 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:39:56,748 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 21:40:20,408 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:40:20,410 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 21:40:40,953 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:40:40,955 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:40:49,268 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:40:49,270 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 21:41:10,769 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:41:10,772 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:41:26,405 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:41:26,407 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 21:41:54,506 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:41:54,508 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:42:07,013 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:42:07,015 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 21:42:12,495 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:42:12,497 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:42:20,747 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:42:20,749 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:42:36,154 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:42:36,156 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:42:44,545 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:42:44,547 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:42:56,622 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:42:56,624 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:43:09,573 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:43:09,575 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 21:43:38,266 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:43:38,268 Ignore 1 sentence(s) with no tokens.\n",
      "41\n",
      "2019-12-05 21:44:19,517 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:44:19,519 Ignore 1 sentence(s) with no tokens.\n",
      "41\n",
      "2019-12-05 21:45:00,760 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:45:00,762 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 21:45:23,269 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:45:23,271 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 21:45:53,097 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:45:53,099 Ignore 2 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:46:07,177 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:46:07,179 Ignore 6 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 21:46:37,016 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:46:37,018 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 21:47:04,520 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:47:04,522 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 21:47:12,017 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:47:12,020 Ignore 1 sentence(s) with no tokens.\n",
      "45\n",
      "2019-12-05 21:47:57,405 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:47:57,407 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:48:23,786 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:48:23,789 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:48:34,788 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:48:34,790 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:48:44,348 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:48:44,350 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 21:49:06,356 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:49:06,359 Ignore 27 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:49:32,896 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:49:32,898 Ignore 1 sentence(s) with no tokens.\n",
      "47\n",
      "2019-12-05 21:50:19,467 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:50:19,469 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 21:50:36,144 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:50:36,146 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:50:47,624 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:50:47,626 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:50:53,601 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:50:53,603 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:51:06,084 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:51:06,086 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:51:12,316 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:51:12,318 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:51:22,290 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:51:22,292 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 21:51:43,440 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:51:43,442 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 21:52:06,018 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:52:06,020 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 21:52:25,772 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:52:25,774 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 21:52:53,887 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:52:53,889 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:53:03,572 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:53:03,574 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 21:53:25,279 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:53:25,281 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 21:53:42,461 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:53:42,464 Ignore 1 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-05 21:54:18,834 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 21:54:18,837 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:54:45,209 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:54:45,211 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:54:55,583 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:54:55,585 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:55:08,547 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:55:08,549 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:55:26,299 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:55:26,301 Ignore 10 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 21:55:38,663 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:55:38,665 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:55:52,320 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:55:52,323 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:56:10,143 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:56:10,145 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 21:56:22,791 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:56:22,793 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:56:31,524 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:56:31,526 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:56:49,828 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:56:49,830 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 21:56:58,593 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:56:58,596 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 21:57:09,434 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:57:09,437 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 21:57:17,732 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:57:17,734 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 21:57:45,402 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:57:45,404 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:58:11,082 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:58:11,084 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:58:24,792 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:58:24,794 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 21:58:38,830 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:58:38,833 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 21:58:48,434 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:58:48,436 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 21:59:15,073 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:59:15,075 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 21:59:32,402 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:59:32,404 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 21:59:48,831 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:59:48,833 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 21:59:54,497 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 21:59:54,499 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:00:07,038 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:00:07,039 Ignore 2 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:00:19,823 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:00:19,825 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 22:00:45,310 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:00:45,313 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:00:58,094 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:00:58,097 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:01:13,822 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:01:13,824 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-05 22:01:51,108 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:01:51,110 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:02:12,671 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:02:12,674 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:02:35,987 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:02:35,989 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:02:57,253 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:02:57,255 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:03:10,333 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:03:10,335 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 22:03:36,326 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:03:36,328 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:03:57,137 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:03:57,139 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-05 22:04:35,479 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:04:35,481 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 22:05:04,085 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:05:04,087 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 22:05:38,075 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:05:38,077 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 22:06:08,349 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:06:08,352 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:06:20,253 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:06:20,255 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 22:06:24,837 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:06:24,839 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:06:32,500 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:06:32,502 Ignore 1 sentence(s) with no tokens.\n",
      "35\n",
      "2019-12-05 22:07:07,953 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:07:07,955 Ignore 3 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 22:07:37,452 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:07:37,454 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:07:50,346 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:07:50,348 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:08:07,079 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:08:07,081 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:08:17,761 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:08:17,763 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:08:34,556 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:08:34,558 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:08:49,213 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:08:49,215 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:08:55,257 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 22:08:55,259 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:09:09,899 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:09:09,902 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:09:24,104 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:09:24,107 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:09:32,395 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:09:32,397 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 22:09:51,174 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:09:51,176 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:10:01,321 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:10:01,323 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:10:24,544 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:10:24,546 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 22:10:43,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:10:43,194 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:10:50,037 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:10:50,039 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 22:11:19,475 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:11:19,477 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:11:37,351 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:11:37,353 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:12:00,429 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:12:00,431 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:12:21,567 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:12:21,569 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:12:35,826 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:12:35,829 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:12:52,146 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:12:52,148 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:13:05,478 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:13:05,480 Ignore 24 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:13:23,056 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:13:23,058 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:13:34,035 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:13:34,038 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 22:13:38,920 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:13:38,922 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:13:54,330 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:13:54,332 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:14:05,227 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:14:05,229 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:14:16,779 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:14:16,781 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:14:30,030 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:14:30,032 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:14:43,591 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:14:43,594 Ignore 17 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:14:50,332 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:14:50,334 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:14:59,682 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:14:59,684 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 22:15:27,504 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:15:27,506 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:15:47,837 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:15:47,839 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:16:02,613 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:16:02,615 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:16:15,258 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:16:15,260 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:16:21,391 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:16:21,393 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:16:32,791 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:16:32,793 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:16:47,626 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:16:47,628 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:16:56,096 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:16:56,097 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:17:11,900 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:17:11,902 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:17:25,236 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:17:25,238 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 22:17:52,851 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:17:52,853 Ignore 31 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:18:01,054 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:18:01,056 Ignore 11 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:18:12,600 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:18:12,602 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:18:19,152 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:18:19,154 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:18:39,204 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:18:39,206 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 22:19:06,579 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:19:06,581 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:19:24,798 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:19:24,800 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 22:19:52,148 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:19:52,151 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:20:09,945 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:20:09,947 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:20:24,697 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:20:24,700 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:20:41,796 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:20:41,798 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:20:55,242 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:20:55,244 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 22:21:19,597 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:21:19,599 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:21:35,696 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 22:21:35,698 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:21:46,364 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:21:46,366 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:21:58,786 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:21:58,788 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:22:10,062 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:22:10,064 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 22:22:28,834 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:22:28,836 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:22:43,485 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:22:43,487 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:22:51,114 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:22:51,116 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:23:00,037 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:23:00,040 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:23:10,287 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:23:10,289 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:23:20,596 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:23:20,598 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:23:37,056 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:23:37,058 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:23:47,045 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:23:47,047 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 22:24:12,326 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:24:12,328 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:24:25,456 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:24:25,458 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:24:32,797 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:24:32,799 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:24:47,244 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:24:47,246 Ignore 13 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:24:57,213 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:24:57,215 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:25:09,218 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:25:09,220 Ignore 9 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:25:20,823 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:25:20,825 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:25:28,020 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:25:28,022 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:25:45,527 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:25:45,530 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 22:26:04,836 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:26:04,837 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:26:14,977 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:26:14,979 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:26:32,387 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:26:32,389 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:26:39,282 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:26:39,284 Ignore 43 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:26:47,867 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:26:47,869 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:27:02,705 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:27:02,707 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 22:27:27,455 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:27:27,457 Ignore 31 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:27:36,328 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:27:36,330 Ignore 22 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 22:28:03,358 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:28:03,360 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:28:13,210 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:28:13,212 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:28:27,495 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:28:27,497 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:28:35,630 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:28:35,632 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:28:55,559 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:28:55,561 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:29:18,840 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:29:18,842 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:29:32,671 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:29:32,673 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:29:50,812 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:29:50,814 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:29:59,811 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:29:59,813 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:30:07,934 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:30:07,936 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:30:17,437 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:30:17,439 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:30:33,075 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:30:33,077 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:30:46,762 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:30:46,764 Ignore 199 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:30:57,735 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:30:57,738 Ignore 8 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:31:08,789 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:31:08,792 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:31:19,140 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:31:19,142 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:31:40,343 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:31:40,345 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:31:58,156 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:31:58,158 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:32:04,323 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:32:04,325 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:32:21,590 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:32:21,592 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:32:32,049 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 22:32:32,051 Ignore 161 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:32:47,875 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:32:47,877 Ignore 139 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:32:56,661 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:32:56,663 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:33:07,604 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:33:07,606 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:33:30,323 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:33:30,325 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:33:41,002 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:33:41,004 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:33:47,964 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:33:47,966 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 22:34:15,424 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:34:15,426 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:34:23,168 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:34:23,170 Ignore 5 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:34:30,740 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:34:30,743 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:34:39,639 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:34:39,641 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:34:47,534 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:34:47,536 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:34:54,242 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:34:54,244 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:35:14,019 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:35:14,021 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:35:27,320 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:35:27,323 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:35:45,372 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:35:45,374 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:35:55,935 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:35:55,937 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:36:09,128 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:36:09,131 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:36:21,019 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:36:21,021 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:36:29,781 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:36:29,784 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:36:47,909 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:36:47,912 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:36:55,785 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:36:55,787 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 22:37:21,750 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:37:21,752 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:37:30,367 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:37:30,369 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:37:41,838 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:37:41,840 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:37:48,333 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:37:48,335 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 22:38:13,119 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:38:13,121 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:38:27,182 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:38:27,184 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:38:32,743 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:38:32,745 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:38:46,311 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:38:46,313 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:38:58,830 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:38:58,832 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:39:09,472 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:39:09,474 Ignore 5 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:39:21,275 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:39:21,277 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:39:44,015 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:39:44,018 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:40:01,176 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:40:01,178 Ignore 31 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:40:08,046 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:40:08,048 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:40:23,671 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:40:23,673 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:40:44,081 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:40:44,083 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:40:57,763 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:40:57,765 Ignore 2 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:41:10,798 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:41:10,800 Ignore 4 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:41:20,417 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:41:20,420 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 22:41:25,261 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:41:25,263 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:41:37,483 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:41:37,485 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:41:48,544 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:41:48,546 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:42:05,170 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:42:05,172 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:42:14,918 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:42:14,920 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-05 22:42:45,951 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:42:45,952 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:42:52,395 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:42:52,397 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:43:05,545 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:43:05,547 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:43:23,073 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 22:43:23,075 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:43:43,661 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:43:43,663 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:43:53,245 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:43:53,247 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:44:06,519 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:44:06,521 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:44:24,699 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:44:24,701 Ignore 22 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:44:33,696 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:44:33,698 Ignore 3 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:44:51,765 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:44:51,767 Ignore 19 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:45:04,115 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:45:04,117 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:45:26,704 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:45:26,706 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:45:35,860 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:45:35,863 Ignore 33 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-05 22:46:06,666 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:46:06,668 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:46:17,148 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:46:17,150 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:46:23,950 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:46:23,953 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:46:34,498 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:46:34,500 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 22:46:52,963 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:46:52,965 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:47:07,293 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:47:07,295 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 22:47:26,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:47:26,194 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:47:34,852 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:47:34,854 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:47:54,697 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:47:54,699 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:48:12,246 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:48:12,248 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:48:25,853 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:48:25,855 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:48:38,516 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:48:38,519 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:48:51,795 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:48:51,797 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:49:04,265 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:49:04,267 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:49:17,525 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:49:17,527 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:49:23,171 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:49:23,173 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:49:35,775 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:49:35,776 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:49:43,046 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:49:43,048 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:49:53,194 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:49:53,196 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:50:00,853 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:50:00,855 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:50:12,578 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:50:12,581 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:50:18,913 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:50:18,915 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:50:25,698 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:50:25,700 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 22:50:48,599 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:50:48,601 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 22:50:54,348 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:50:54,350 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:51:06,368 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:51:06,370 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 22:51:27,947 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:51:27,949 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-05 22:52:08,438 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:52:08,441 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:52:17,540 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:52:17,542 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:52:28,899 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:52:28,901 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:52:46,327 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:52:46,328 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:53:06,480 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:53:06,482 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:53:15,541 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:53:15,543 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 22:53:28,708 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:53:28,710 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 22:53:49,081 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:53:49,083 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:54:00,694 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:54:00,696 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-05 22:54:31,705 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:54:31,707 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:54:39,608 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:54:39,610 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:54:48,256 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:54:48,258 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 22:55:00,360 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 22:55:00,362 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 22:55:14,311 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:55:14,313 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 22:55:25,522 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:55:25,524 Ignore 9 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 22:55:33,541 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:55:33,543 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:55:43,107 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:55:43,109 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 22:55:52,042 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:55:52,044 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-05 22:56:24,439 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:56:24,441 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:56:31,627 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:56:31,629 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 22:56:38,501 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:56:38,503 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 22:56:43,846 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:56:43,848 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-05 22:57:25,571 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:57:25,573 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:57:40,317 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:57:40,319 Ignore 9 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 22:57:56,571 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:57:56,573 Ignore 3 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 22:58:17,518 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:58:17,520 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 22:58:42,365 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:58:42,367 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 22:58:56,883 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:58:56,885 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 22:59:16,258 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:59:16,260 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 22:59:26,490 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:59:26,492 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 22:59:43,619 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 22:59:43,621 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:00:08,763 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:00:08,765 Ignore 87 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:00:19,528 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:00:19,531 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 23:00:49,818 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:00:49,820 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:01:03,576 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:01:03,578 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 23:01:33,755 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:01:33,757 Ignore 19 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:01:41,179 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:01:41,181 Ignore 2 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:02:05,937 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:02:05,939 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:02:20,894 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:02:20,897 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:02:34,703 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:02:34,705 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:02:48,822 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:02:48,825 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:03:00,739 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:03:00,741 Ignore 23 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:03:05,953 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:03:05,955 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:03:11,363 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:03:11,365 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:03:29,918 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:03:29,920 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:03:45,106 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:03:45,108 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:04:10,518 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:04:10,520 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 23:04:31,471 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:04:31,473 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:04:39,895 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:04:39,897 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 23:05:06,201 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:05:06,203 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:05:23,623 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:05:23,625 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:05:37,456 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:05:37,459 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:05:46,775 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:05:46,777 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:05:56,590 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:05:56,592 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:06:09,667 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:06:09,669 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:06:25,281 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:06:25,283 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:06:42,184 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:06:42,186 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:06:55,991 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:06:55,993 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:07:12,164 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:07:12,166 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 23:07:31,616 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:07:31,618 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:07:45,510 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:07:45,512 Ignore 2 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:07:53,810 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 23:07:53,812 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:08:18,234 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:08:18,236 Ignore 20 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:08:28,231 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:08:28,233 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:08:40,824 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:08:40,826 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:08:50,767 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:08:50,769 Ignore 4 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:08:57,759 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:08:57,761 Ignore 2 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:09:13,313 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:09:13,315 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-05 23:09:55,513 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:09:55,516 Ignore 15 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:10:06,634 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:10:06,636 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:10:14,841 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:10:14,843 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 23:10:49,428 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:10:49,430 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 23:11:15,232 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:11:15,234 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:11:31,655 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:11:31,657 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:11:56,253 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:11:56,256 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:12:12,330 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:12:12,333 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:12:19,966 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:12:19,968 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-05 23:12:57,651 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:12:57,653 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:13:05,531 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:13:05,533 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:13:10,826 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:13:10,828 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:13:35,484 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:13:35,486 Ignore 26 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-05 23:14:03,018 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:14:03,020 Ignore 1 sentence(s) with no tokens.\n",
      "41\n",
      "2019-12-05 23:14:44,346 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:14:44,348 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:14:50,899 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:14:50,902 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:14:56,100 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:14:56,102 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:15:04,328 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:15:04,331 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:15:14,927 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:15:14,929 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:15:27,339 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:15:27,341 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:15:33,274 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:15:33,276 Ignore 1 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-05 23:16:16,437 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:16:16,439 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:16:24,206 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:16:24,209 Ignore 1 sentence(s) with no tokens.\n",
      "44\n",
      "2019-12-05 23:17:07,650 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:17:07,652 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 23:17:27,258 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:17:27,260 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:17:34,940 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:17:34,942 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 23:17:54,237 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:17:54,239 Ignore 1 sentence(s) with no tokens.\n",
      "41\n",
      "2019-12-05 23:18:35,595 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:18:35,597 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:18:52,308 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:18:52,310 Ignore 2 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 23:19:18,536 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:19:18,538 Ignore 6 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:19:27,752 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:19:27,754 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-05 23:20:06,846 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:20:06,848 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:20:19,645 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:20:19,647 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 23:20:42,249 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:20:42,251 Ignore 2 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:21:00,312 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:21:00,315 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:21:05,474 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:21:05,476 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:21:13,314 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:21:13,316 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:21:25,909 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:21:25,911 Ignore 2 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:21:36,144 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:21:36,146 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:21:43,260 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:21:43,262 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 23:22:05,130 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:22:05,132 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 23:22:27,771 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:22:27,773 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:22:36,394 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 23:22:36,396 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:22:45,790 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:22:45,790 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:22:50,447 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:22:50,449 Ignore 24 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:22:57,544 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:22:57,546 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:23:04,071 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:23:04,073 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:23:14,874 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:23:14,876 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:23:28,928 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:23:28,930 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:23:52,581 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:23:52,583 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:24:09,113 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:24:09,116 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 23:24:35,557 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:24:35,559 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 23:24:54,208 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:24:54,210 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 23:25:23,756 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:25:23,758 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:25:38,458 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:25:38,460 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:25:51,521 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:25:51,523 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:25:59,782 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:25:59,784 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:26:17,935 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:26:17,937 Ignore 3 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:26:23,522 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:26:23,524 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:26:39,859 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:26:39,861 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:26:48,015 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:26:48,017 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:26:57,771 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:26:57,774 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:27:11,624 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:27:11,626 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:27:25,261 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:27:25,263 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:27:32,368 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:27:32,370 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:27:38,502 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:27:38,504 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:28:02,319 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:28:02,321 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:28:13,468 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:28:13,470 Ignore 461 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:28:31,051 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:28:31,052 Ignore 2 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:28:42,795 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:28:42,797 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 23:29:16,927 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:29:16,929 Ignore 5 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:29:34,240 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:29:34,242 Ignore 16 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:29:42,932 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:29:42,934 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:30:06,807 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:30:06,809 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:30:14,694 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:30:14,696 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:30:29,174 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:30:29,176 Ignore 16 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-05 23:30:55,551 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:30:55,553 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:31:03,765 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:31:03,767 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:31:15,167 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:31:15,169 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:31:26,490 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:31:26,492 Ignore 4 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-05 23:32:00,254 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:32:00,256 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:32:06,525 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:32:06,527 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:32:19,754 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:32:19,756 Ignore 2 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:32:35,147 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:32:35,149 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:32:40,649 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:32:40,651 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:32:48,075 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:32:48,076 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:33:00,089 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:33:00,091 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 23:33:20,303 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:33:20,305 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-05 23:33:58,070 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:33:58,072 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:34:09,862 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:34:09,864 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:34:33,700 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:34:33,702 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 23:34:55,280 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 23:34:55,282 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:35:10,864 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:35:10,866 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:35:21,609 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:35:21,611 Ignore 6 sentence(s) with no tokens.\n",
      "4\n",
      "2019-12-05 23:35:25,958 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:35:25,960 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-05 23:35:58,330 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:35:58,332 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:36:15,439 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:36:15,441 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-05 23:36:43,139 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:36:43,141 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:37:08,257 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:37:08,259 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:37:32,045 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:37:32,047 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:37:42,020 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:37:42,022 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:37:57,441 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:37:57,443 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:38:04,448 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:38:04,450 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:38:12,027 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:38:12,029 Ignore 9 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:38:28,478 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:38:28,480 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:38:34,743 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:38:34,745 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:38:52,563 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:38:52,565 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:39:01,860 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:39:01,862 Ignore 2 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:39:20,088 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:39:20,090 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-05 23:39:35,627 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:39:35,629 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:39:45,087 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:39:45,089 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:39:56,467 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:39:56,469 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:40:04,721 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:40:04,724 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:40:12,173 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:40:12,175 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:40:20,249 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:40:20,252 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:40:30,816 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:40:30,818 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:40:42,354 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:40:42,356 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:40:55,483 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:40:55,485 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:41:08,310 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:41:08,313 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:41:21,970 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:41:21,972 Ignore 364 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:41:29,098 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:41:29,100 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-05 23:41:58,171 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:41:58,173 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:42:05,133 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:42:05,135 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:42:30,780 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:42:30,782 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:42:41,910 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:42:41,912 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:42:56,111 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:42:56,113 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:43:13,675 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:43:13,678 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:43:37,419 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:43:37,421 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:43:45,292 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:43:45,294 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:44:00,260 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:44:00,262 Ignore 19 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-05 23:44:25,128 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:44:25,130 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:44:42,719 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:44:42,721 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:44:54,086 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:44:54,088 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:45:04,246 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:45:04,248 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:45:13,440 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:45:13,442 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:45:20,202 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:45:20,205 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:45:29,039 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:45:29,041 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 23:45:50,950 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:45:50,952 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:46:05,999 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:46:06,001 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:46:19,614 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:46:19,616 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:46:32,654 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 23:46:32,656 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:46:45,063 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:46:45,064 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:46:54,797 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:46:54,799 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 23:47:16,898 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:47:16,900 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:47:23,401 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:47:23,403 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:47:36,448 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:47:36,451 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-05 23:47:59,978 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:47:59,980 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:48:11,961 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:48:11,962 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:48:22,565 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:48:22,568 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:48:36,181 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:48:36,183 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:48:49,296 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:48:49,298 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:49:03,089 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:49:03,091 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-05 23:49:11,859 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:49:11,861 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:49:26,411 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:49:26,413 Ignore 27 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:49:38,038 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:49:38,040 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-05 23:49:44,635 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:49:44,637 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:49:57,788 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:49:57,790 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 23:50:16,597 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:50:16,599 Ignore 5 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:50:29,412 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:50:29,414 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:50:39,608 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:50:39,610 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:50:52,411 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:50:52,413 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 23:51:14,178 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:51:14,180 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:51:27,000 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:51:27,002 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-05 23:51:56,865 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:51:56,867 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-05 23:52:03,406 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:52:03,408 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-05 23:52:11,481 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:52:11,483 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:52:22,019 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:52:22,021 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:52:27,395 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:52:27,397 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-05 23:52:46,227 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:52:46,229 Ignore 7 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:52:59,734 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:52:59,736 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:53:10,732 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:53:10,734 Ignore 25 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 23:53:31,931 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:53:31,933 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:53:42,284 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:53:42,286 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-05 23:54:02,870 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:54:02,872 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:54:15,974 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:54:15,977 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:54:30,598 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:54:30,600 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-05 23:54:40,646 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:54:40,648 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-05 23:55:02,724 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:55:02,726 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 23:55:22,880 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:55:22,882 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-05 23:56:03,484 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:56:03,486 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:56:18,023 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:56:18,026 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:56:30,955 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:56:30,958 Ignore 7 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-05 23:56:41,883 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:56:41,885 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-05 23:56:57,112 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:56:57,114 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-05 23:57:09,857 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:57:09,859 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-05 23:57:23,926 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:57:23,928 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-05 23:57:29,111 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:57:29,113 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-05 23:57:52,052 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:57:52,054 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-05 23:58:08,683 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:58:08,685 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-05 23:58:21,201 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 23:58:21,203 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-05 23:58:53,654 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:58:53,656 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-05 23:59:11,232 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:59:11,234 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 23:59:31,312 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:59:31,314 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-05 23:59:50,965 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-05 23:59:50,967 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 00:00:22,086 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:00:22,088 Ignore 21 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:00:29,705 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:00:29,707 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:00:41,767 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:00:41,770 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 00:01:00,451 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:01:00,453 Ignore 2 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:01:09,307 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:01:09,309 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:01:23,531 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:01:23,534 Ignore 2 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:01:32,100 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:01:32,102 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:01:44,078 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:01:44,080 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:01:55,867 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:01:55,869 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:02:09,471 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:02:09,473 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:02:21,230 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:02:21,232 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 00:02:34,492 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:02:34,494 Ignore 8 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:02:44,960 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:02:44,962 Ignore 34 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:03:02,694 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:03:02,696 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:03:11,214 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:03:11,216 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:03:23,327 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:03:23,329 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 00:03:34,539 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:03:34,541 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:03:42,558 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:03:42,560 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:04:02,111 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:04:02,113 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 00:04:08,724 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:04:08,726 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:04:21,029 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:04:21,031 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:04:29,283 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:04:29,285 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 00:04:46,412 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:04:46,414 Ignore 2 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 00:05:03,309 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:05:03,311 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:05:17,568 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:05:17,570 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 00:05:28,547 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:05:28,550 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:05:36,059 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:05:36,061 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 00:05:58,825 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:05:58,828 Ignore 13 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-06 00:06:04,104 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:06:04,106 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:06:09,549 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:06:09,552 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 00:06:28,859 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:06:28,861 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:06:54,513 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:06:54,516 Ignore 1 sentence(s) with no tokens.\n",
      "0\n",
      "2019-12-06 00:06:54,694 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:06:54,696 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 00:07:14,060 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:07:14,061 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 00:07:43,675 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:07:43,677 Ignore 11 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:08:01,664 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:08:01,666 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 00:08:40,341 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:08:40,343 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 00:08:55,134 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:08:55,136 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:09:21,145 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:09:21,147 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 00:09:36,340 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:09:36,342 Ignore 2 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:09:48,576 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:09:48,578 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:09:54,685 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:09:54,687 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:10:00,798 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:10:00,801 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:10:10,766 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:10:10,768 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:10:37,061 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 00:10:37,064 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:10:45,820 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:10:45,821 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 00:11:06,868 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:11:06,870 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 00:11:30,114 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:11:30,116 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:11:44,345 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:11:44,347 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:11:52,870 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:11:52,872 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 00:12:00,301 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:12:00,303 Ignore 2 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:12:10,629 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:12:10,631 Ignore 5 sentence(s) with no tokens.\n",
      "4\n",
      "2019-12-06 00:12:15,151 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:12:15,153 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 00:12:40,285 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:12:40,287 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 00:12:47,074 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:12:47,076 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:13:12,835 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:13:12,837 Ignore 2 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 00:13:42,045 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:13:42,047 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 00:13:54,691 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:13:54,693 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 00:14:24,008 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:14:24,010 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:14:43,939 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:14:43,941 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 00:14:55,240 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:14:55,242 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 00:15:18,324 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:15:18,326 Ignore 2 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 00:15:48,108 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:15:48,110 Ignore 8 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:15:58,135 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:15:58,137 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 00:16:29,034 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:16:29,036 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:16:34,611 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:16:34,614 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 00:17:06,664 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:17:06,666 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:17:15,558 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:17:15,560 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 00:17:43,401 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:17:43,403 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:18:09,582 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:18:09,584 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 00:18:32,281 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:18:32,283 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 00:18:43,828 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:18:43,830 Ignore 1 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-06 00:19:26,965 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:19:26,968 Ignore 2 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:19:32,551 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:19:32,553 Ignore 2 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 00:19:51,327 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:19:51,329 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:20:01,752 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:20:01,754 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 00:20:25,196 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:20:25,198 Ignore 3 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:20:33,761 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:20:33,763 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 00:20:54,973 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:20:54,975 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:21:12,381 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:21:12,383 Ignore 155 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:21:28,534 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:21:28,536 Ignore 3 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:21:34,573 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:21:34,575 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 00:21:50,101 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:21:50,103 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 00:22:01,363 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:22:01,365 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 00:22:33,684 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:22:33,687 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:22:51,249 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:22:51,251 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:23:05,302 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:23:05,303 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 00:23:21,745 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:23:21,747 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:23:30,397 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:23:30,399 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 00:24:08,473 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:24:08,475 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 00:24:36,309 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:24:36,311 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 00:24:58,211 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:24:58,213 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:25:16,308 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:25:16,310 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:25:25,864 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 00:25:25,866 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:25:51,268 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:25:51,270 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:26:07,683 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:26:07,685 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:26:27,894 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:26:27,897 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-06 00:27:09,760 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:27:09,762 Ignore 3 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 00:27:56,417 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:27:56,419 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 00:28:42,222 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:28:42,224 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:29:08,342 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:29:08,344 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 00:29:30,437 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:29:30,439 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 00:29:45,012 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:29:45,014 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:29:54,575 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:29:54,577 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 00:30:05,994 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:30:05,996 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:30:13,862 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:30:13,864 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 00:30:43,610 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:30:43,612 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 00:31:14,591 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:31:14,593 Ignore 1 sentence(s) with no tokens.\n",
      "51\n",
      "2019-12-06 00:32:05,521 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:32:05,524 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 00:32:37,910 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:32:37,912 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 00:32:55,457 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:32:55,459 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:33:04,601 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:33:04,603 Ignore 3 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:33:12,346 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:33:12,348 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:33:32,639 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:33:32,641 Ignore 1 sentence(s) with no tokens.\n",
      "57\n",
      "2019-12-06 00:34:30,112 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:34:30,114 Ignore 1 sentence(s) with no tokens.\n",
      "64\n",
      "2019-12-06 00:35:34,622 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:35:34,624 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:35:52,500 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:35:52,502 Ignore 1 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-06 00:36:28,224 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:36:28,226 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 00:37:01,458 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:37:01,460 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 00:37:41,155 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:37:41,158 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 00:38:02,450 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:38:02,452 Ignore 10 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-06 00:38:37,847 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:38:37,849 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 00:39:04,557 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:39:04,559 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 00:39:28,844 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:39:28,846 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 00:39:36,591 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:39:36,593 Ignore 178 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 00:40:10,367 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:40:10,369 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:40:19,612 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:40:19,614 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 00:40:34,383 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:40:34,385 Ignore 1 sentence(s) with no tokens.\n",
      "47\n",
      "2019-12-06 00:41:21,343 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:41:21,345 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 00:41:47,270 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:41:47,272 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 00:42:18,350 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:42:18,352 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:42:38,415 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:42:38,417 Ignore 5 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-06 00:42:43,984 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:42:43,986 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:42:59,798 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:42:59,800 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 00:43:06,956 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:43:06,958 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:43:16,989 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:43:16,991 Ignore 1 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-06 00:44:00,149 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:44:00,151 Ignore 12 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:44:15,912 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:44:15,915 Ignore 1 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-06 00:44:52,280 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:44:52,282 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 00:45:38,644 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:45:38,646 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:45:58,183 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:45:58,185 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 00:46:26,382 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:46:26,384 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:46:35,514 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 00:46:35,516 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:46:53,794 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:46:53,797 Ignore 1 sentence(s) with no tokens.\n",
      "56\n",
      "2019-12-06 00:47:49,837 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:47:49,839 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 00:48:02,868 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:48:02,870 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 00:48:12,702 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:48:12,704 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:48:31,190 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:48:31,192 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 00:48:58,326 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:48:58,328 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 00:49:11,605 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:49:11,606 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 00:49:32,035 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:49:32,037 Ignore 2 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:49:50,119 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:49:50,121 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 00:50:24,380 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:50:24,383 Ignore 5 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:50:38,497 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:50:38,499 Ignore 1 sentence(s) with no tokens.\n",
      "60\n",
      "2019-12-06 00:51:37,969 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:51:37,971 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 00:51:55,201 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:51:55,203 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 00:52:09,018 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:52:09,020 Ignore 9 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 00:52:27,307 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:52:27,309 Ignore 12 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 00:52:55,561 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:52:55,563 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 00:53:24,233 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:53:24,236 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 00:53:54,637 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:53:54,639 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 00:54:09,648 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:54:09,650 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 00:54:16,797 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:54:16,799 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-06 00:54:59,004 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:54:59,006 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 00:55:33,503 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:55:33,505 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:55:49,445 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:55:49,448 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 00:56:02,489 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:56:02,492 Ignore 29 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 00:56:26,441 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:56:26,443 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:56:32,666 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:56:32,668 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:56:52,335 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:56:52,337 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:57:08,646 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:57:08,648 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 00:57:21,351 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:57:21,353 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 00:57:58,936 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:57:58,938 Ignore 2 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 00:58:07,917 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:58:07,919 Ignore 3 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-06 00:58:13,167 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:58:13,170 Ignore 73 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 00:58:33,311 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:58:33,313 Ignore 5 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 00:59:10,472 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:59:10,474 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 00:59:25,901 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:59:25,903 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 00:59:32,512 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:59:32,513 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 00:59:43,662 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 00:59:43,664 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 01:00:00,085 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:00:00,088 Ignore 17 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:00:09,977 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:00:09,979 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 01:00:17,230 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:00:17,233 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 01:00:34,119 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:00:34,121 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 01:00:53,123 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:00:53,124 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 01:01:07,387 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:01:07,389 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 01:01:15,651 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:01:15,654 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 01:01:27,742 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:01:27,744 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-06 01:02:10,343 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:02:10,346 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 01:02:28,577 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:02:28,579 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 01:02:46,989 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:02:46,991 Ignore 2 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 01:03:18,888 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 01:03:18,890 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 01:03:46,970 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:03:46,972 Ignore 1 sentence(s) with no tokens.\n",
      "53\n",
      "2019-12-06 01:04:40,469 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:04:40,471 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 01:04:52,679 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:04:52,681 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 01:05:08,964 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:05:08,966 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 01:05:39,181 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:05:39,184 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 01:05:48,289 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:05:48,292 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 01:06:15,912 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:06:15,914 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 01:06:27,837 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:06:27,839 Ignore 1 sentence(s) with no tokens.\n",
      "56\n",
      "2019-12-06 01:07:23,899 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:07:23,901 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 01:07:40,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:07:40,195 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:07:50,293 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:07:50,295 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 01:08:27,245 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:08:27,247 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 01:08:42,509 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:08:42,511 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:08:52,423 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:08:52,425 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 01:09:21,370 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:09:21,372 Ignore 1 sentence(s) with no tokens.\n",
      "67\n",
      "2019-12-06 01:10:28,380 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:10:28,382 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 01:11:02,304 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:11:02,306 Ignore 11 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 01:11:31,600 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:11:31,602 Ignore 1 sentence(s) with no tokens.\n",
      "35\n",
      "2019-12-06 01:12:06,255 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:12:06,257 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 01:12:27,714 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:12:27,716 Ignore 1 sentence(s) with no tokens.\n",
      "55\n",
      "2019-12-06 01:13:22,707 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:13:22,709 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 01:13:39,767 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:13:39,770 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 01:14:19,172 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:14:19,175 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 01:14:58,936 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:14:58,938 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 01:15:31,490 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:15:31,493 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 01:15:47,526 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:15:47,528 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 01:16:15,537 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:16:15,539 Ignore 1 sentence(s) with no tokens.\n",
      "54\n",
      "2019-12-06 01:17:09,348 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:17:09,350 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 01:17:20,613 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:17:20,615 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:17:31,279 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:17:31,281 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 01:18:17,529 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:18:17,531 Ignore 1 sentence(s) with no tokens.\n",
      "50\n",
      "2019-12-06 01:19:08,201 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:19:08,203 Ignore 1 sentence(s) with no tokens.\n",
      "70\n",
      "2019-12-06 01:20:18,484 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:20:18,486 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 01:20:45,801 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:20:45,802 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 01:21:31,259 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:21:31,261 Ignore 1 sentence(s) with no tokens.\n",
      "41\n",
      "2019-12-06 01:22:12,040 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:22:12,042 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 01:22:41,106 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:22:41,108 Ignore 7 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 01:23:01,214 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:23:01,216 Ignore 1 sentence(s) with no tokens.\n",
      "65\n",
      "2019-12-06 01:24:06,084 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:24:06,086 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 01:24:18,360 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:24:18,362 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 01:24:47,224 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:24:47,226 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 01:25:24,737 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:25:24,740 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 01:25:41,417 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:25:41,420 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 01:25:53,792 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:25:53,795 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 01:26:24,121 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:26:24,123 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 01:27:00,858 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:27:00,861 Ignore 1 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-06 01:27:43,511 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:27:43,513 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 01:27:58,956 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:27:58,958 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 01:28:21,581 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 01:28:21,583 Ignore 2 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 01:28:28,117 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:28:28,119 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 01:28:52,864 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:28:52,866 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 01:29:12,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:29:12,804 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 01:29:28,198 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:29:28,200 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 01:29:46,618 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:29:46,620 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 01:30:19,657 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:30:19,660 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 01:30:53,458 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:30:53,461 Ignore 1 sentence(s) with no tokens.\n",
      "69\n",
      "2019-12-06 01:32:02,895 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:32:02,897 Ignore 1 sentence(s) with no tokens.\n",
      "119\n",
      "2019-12-06 01:34:02,246 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:34:02,248 Ignore 1 sentence(s) with no tokens.\n",
      "58\n",
      "2019-12-06 01:35:00,097 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:35:00,099 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 01:35:10,880 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:35:10,882 Ignore 1 sentence(s) with no tokens.\n",
      "44\n",
      "2019-12-06 01:35:54,828 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:35:54,830 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:36:04,498 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:36:04,501 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:36:14,482 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:36:14,484 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 01:36:53,873 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:36:53,875 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 01:37:06,019 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:37:06,021 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:37:15,665 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:37:15,667 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 01:37:44,393 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:37:44,395 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 01:37:57,011 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:37:57,013 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 01:38:23,827 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:38:23,829 Ignore 1 sentence(s) with no tokens.\n",
      "53\n",
      "2019-12-06 01:39:16,905 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:39:16,907 Ignore 1 sentence(s) with no tokens.\n",
      "54\n",
      "2019-12-06 01:40:11,278 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:40:11,280 Ignore 1 sentence(s) with no tokens.\n",
      "72\n",
      "2019-12-06 01:41:23,042 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:41:23,044 Ignore 1 sentence(s) with no tokens.\n",
      "48\n",
      "2019-12-06 01:42:10,829 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:42:10,832 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 01:42:23,656 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:42:23,658 Ignore 4 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-06 01:43:06,453 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:43:06,455 Ignore 5 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 01:43:33,602 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:43:33,604 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 01:44:13,426 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:44:13,428 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 01:44:38,226 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:44:38,228 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 01:44:53,319 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:44:53,321 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-06 01:45:35,016 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:45:35,018 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 01:45:52,702 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:45:52,704 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 01:46:16,503 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:46:16,505 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 01:46:23,726 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:46:23,728 Ignore 1 sentence(s) with no tokens.\n",
      "76\n",
      "2019-12-06 01:47:39,874 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:47:39,876 Ignore 1 sentence(s) with no tokens.\n",
      "35\n",
      "2019-12-06 01:48:14,900 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:48:14,902 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 01:48:38,416 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:48:38,418 Ignore 1 sentence(s) with no tokens.\n",
      "111\n",
      "2019-12-06 01:50:29,878 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:50:29,880 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 01:50:39,951 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:50:39,953 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 01:51:03,412 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:51:03,414 Ignore 1 sentence(s) with no tokens.\n",
      "52\n",
      "2019-12-06 01:51:55,624 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:51:55,627 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 01:52:10,619 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:52:10,621 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 01:52:35,379 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:52:35,381 Ignore 4 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 01:53:21,076 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:53:21,079 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 01:53:52,149 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:53:52,151 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 01:54:08,255 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:54:08,257 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 01:54:39,504 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:54:39,507 Ignore 1 sentence(s) with no tokens.\n",
      "77\n",
      "2019-12-06 01:55:56,268 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:55:56,270 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 01:56:11,267 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 01:56:11,269 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 01:56:32,766 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:56:32,768 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 01:57:00,068 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:57:00,070 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 01:57:37,949 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:57:37,951 Ignore 6 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 01:58:00,815 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:58:00,817 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 01:58:22,243 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:58:22,245 Ignore 76 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 01:58:53,110 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:58:53,112 Ignore 1 sentence(s) with no tokens.\n",
      "51\n",
      "2019-12-06 01:59:43,775 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 01:59:43,778 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 02:00:21,429 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:00:21,431 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 02:00:47,166 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:00:47,168 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 02:01:18,217 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:01:18,219 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 02:01:41,554 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:01:41,557 Ignore 1 sentence(s) with no tokens.\n",
      "44\n",
      "2019-12-06 02:02:25,737 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:02:25,739 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 02:02:38,799 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:02:38,801 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 02:03:00,805 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:03:00,807 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 02:03:33,909 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:03:33,911 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 02:03:43,406 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:03:43,409 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 02:04:05,970 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:04:05,972 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 02:04:33,985 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:04:33,988 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 02:04:43,925 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:04:43,927 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 02:04:54,344 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:04:54,347 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 02:05:25,176 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:05:25,177 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 02:06:05,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:06:05,194 Ignore 5 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 02:06:15,296 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:06:15,298 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 02:06:44,799 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:06:44,802 Ignore 1 sentence(s) with no tokens.\n",
      "45\n",
      "2019-12-06 02:07:29,445 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:07:29,447 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 02:07:43,191 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:07:43,193 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 02:08:00,084 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:08:00,086 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 02:08:25,527 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:08:25,529 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 02:08:39,739 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:08:39,741 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 02:09:01,029 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:09:01,031 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 02:09:12,834 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:09:12,836 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 02:09:40,062 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:09:40,065 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 02:10:10,117 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:10:10,119 Ignore 1 sentence(s) with no tokens.\n",
      "51\n",
      "2019-12-06 02:11:00,932 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:11:00,935 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 02:11:13,213 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:11:13,215 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 02:11:31,729 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:11:31,732 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 02:11:52,387 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:11:52,388 Ignore 2 sentence(s) with no tokens.\n",
      "70\n",
      "2019-12-06 02:13:02,225 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:13:02,227 Ignore 1 sentence(s) with no tokens.\n",
      "72\n",
      "2019-12-06 02:14:14,443 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:14:14,445 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 02:14:29,392 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:14:29,394 Ignore 9 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 02:14:51,960 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:14:51,962 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 02:15:19,505 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:15:19,507 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 02:15:47,737 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:15:47,739 Ignore 1 sentence(s) with no tokens.\n",
      "71\n",
      "2019-12-06 02:16:58,867 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:16:58,870 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 02:17:08,956 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:17:08,959 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 02:17:38,047 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:17:38,049 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 02:17:45,215 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:17:45,217 Ignore 1 sentence(s) with no tokens.\n",
      "77\n",
      "2019-12-06 02:19:01,827 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:19:01,829 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 02:19:23,708 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 02:19:23,710 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 02:19:40,928 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:19:40,930 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 02:19:56,013 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:19:56,014 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 02:20:36,206 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:20:36,208 Ignore 62 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 02:20:52,383 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:20:52,385 Ignore 1 sentence(s) with no tokens.\n",
      "68\n",
      "2019-12-06 02:22:00,497 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:22:00,500 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 02:22:21,579 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:22:21,581 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 02:22:39,911 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:22:39,913 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 02:23:25,941 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:23:25,943 Ignore 1 sentence(s) with no tokens.\n",
      "62\n",
      "2019-12-06 02:24:28,325 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:24:28,327 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 02:25:01,793 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:25:01,795 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-06 02:25:43,642 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:25:43,644 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 02:26:17,380 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:26:17,382 Ignore 1 sentence(s) with no tokens.\n",
      "52\n",
      "2019-12-06 02:27:08,966 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:27:08,968 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 02:27:25,127 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:27:25,129 Ignore 1 sentence(s) with no tokens.\n",
      "47\n",
      "2019-12-06 02:28:12,074 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:28:12,076 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 02:28:26,423 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:28:26,425 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 02:28:44,192 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:28:44,194 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 02:29:30,327 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:29:30,330 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 02:29:46,523 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:29:46,525 Ignore 117 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 02:29:59,008 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:29:59,010 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 02:30:13,505 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:30:13,508 Ignore 1 sentence(s) with no tokens.\n",
      "49\n",
      "2019-12-06 02:31:02,233 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:31:02,235 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 02:31:09,817 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:31:09,819 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 02:31:29,094 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:31:29,096 Ignore 1 sentence(s) with no tokens.\n",
      "72\n",
      "2019-12-06 02:32:41,274 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:32:41,276 Ignore 1 sentence(s) with no tokens.\n",
      "58\n",
      "2019-12-06 02:33:38,909 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:33:38,912 Ignore 1 sentence(s) with no tokens.\n",
      "59\n",
      "2019-12-06 02:34:37,579 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:34:37,581 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 02:35:09,651 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:35:09,653 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 02:35:18,147 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:35:18,149 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 02:35:27,571 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:35:27,573 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 02:35:58,596 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:35:58,597 Ignore 1 sentence(s) with no tokens.\n",
      "35\n",
      "2019-12-06 02:36:34,147 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:36:34,149 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 02:36:59,275 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:36:59,278 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 02:37:32,731 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:37:32,732 Ignore 1 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-06 02:38:08,306 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:38:08,309 Ignore 37 sentence(s) with no tokens.\n",
      "49\n",
      "2019-12-06 02:38:57,676 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:38:57,678 Ignore 1 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-06 02:39:40,811 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:39:40,813 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 02:40:01,502 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:40:01,504 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 02:40:15,166 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:40:15,168 Ignore 12 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 02:40:28,476 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:40:28,478 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 02:40:55,302 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:40:55,304 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 02:41:08,719 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:41:08,721 Ignore 1 sentence(s) with no tokens.\n",
      "56\n",
      "2019-12-06 02:42:04,711 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:42:04,713 Ignore 1 sentence(s) with no tokens.\n",
      "60\n",
      "2019-12-06 02:43:04,600 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:43:04,602 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 02:43:15,086 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:43:15,088 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 02:43:28,125 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:43:28,128 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 02:43:36,614 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:43:36,616 Ignore 1 sentence(s) with no tokens.\n",
      "5\n",
      "2019-12-06 02:43:41,208 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:43:41,210 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 02:43:51,367 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 02:43:51,369 Ignore 1 sentence(s) with no tokens.\n",
      "45\n",
      "2019-12-06 02:44:36,465 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:44:36,467 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 02:44:47,773 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:44:47,775 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 02:44:57,798 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:44:57,800 Ignore 1 sentence(s) with no tokens.\n",
      "92\n",
      "2019-12-06 02:46:29,394 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:46:29,396 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 02:46:59,339 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:46:59,341 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 02:47:27,645 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:47:27,647 Ignore 1 sentence(s) with no tokens.\n",
      "94\n",
      "2019-12-06 02:49:01,515 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:49:01,517 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 02:49:14,800 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:49:14,802 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 02:49:41,221 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:49:41,223 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 02:49:48,842 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:49:48,844 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 02:50:26,343 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:50:26,345 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 02:50:42,857 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:50:42,861 Ignore 416 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 02:51:23,077 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:51:23,079 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 02:51:42,478 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:51:42,480 Ignore 1 sentence(s) with no tokens.\n",
      "58\n",
      "2019-12-06 02:52:40,486 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:52:40,488 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 02:53:02,622 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:53:02,624 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 02:53:12,105 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:53:12,107 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 02:53:40,583 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:53:40,585 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 02:54:03,446 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:54:03,448 Ignore 1 sentence(s) with no tokens.\n",
      "45\n",
      "2019-12-06 02:54:48,231 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:54:48,233 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 02:54:56,751 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:54:56,753 Ignore 1 sentence(s) with no tokens.\n",
      "97\n",
      "2019-12-06 02:56:33,488 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:56:33,491 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 02:57:19,580 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:57:19,583 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 02:57:46,198 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:57:46,200 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 02:57:58,439 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:57:58,441 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 02:58:06,422 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:58:06,424 Ignore 1 sentence(s) with no tokens.\n",
      "44\n",
      "2019-12-06 02:58:50,714 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:58:50,716 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 02:59:22,664 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:59:22,667 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 02:59:43,665 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 02:59:43,667 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 03:00:07,908 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:00:07,910 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 03:00:38,435 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:00:38,437 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 03:01:07,544 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:01:07,547 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 03:01:46,834 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:01:46,836 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 03:02:12,412 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:02:12,414 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 03:02:58,186 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:02:58,189 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 03:03:17,651 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:03:17,652 Ignore 73 sentence(s) with no tokens.\n",
      "58\n",
      "2019-12-06 03:04:15,278 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:04:15,281 Ignore 1 sentence(s) with no tokens.\n",
      "58\n",
      "2019-12-06 03:05:13,445 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:05:13,448 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 03:05:30,879 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:05:30,881 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 03:05:48,317 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:05:48,319 Ignore 33 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 03:05:54,381 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:05:54,383 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 03:06:34,666 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:06:34,668 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 03:07:04,544 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:07:04,546 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 03:07:33,571 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:07:33,573 Ignore 1 sentence(s) with no tokens.\n",
      "62\n",
      "2019-12-06 03:08:35,782 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:08:35,784 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 03:08:49,054 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:08:49,056 Ignore 1 sentence(s) with no tokens.\n",
      "61\n",
      "2019-12-06 03:09:49,852 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:09:49,854 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 03:10:17,425 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:10:17,428 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 03:10:28,840 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 03:10:28,842 Ignore 7 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 03:10:44,687 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:10:44,689 Ignore 214 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 03:10:55,658 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:10:55,660 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 03:11:20,601 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:11:20,603 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 03:11:48,830 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:11:48,832 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 03:12:06,289 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:12:06,291 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 03:12:21,225 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:12:21,228 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 03:13:00,143 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:13:00,145 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 03:13:12,417 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:13:12,419 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 03:13:27,700 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:13:27,702 Ignore 2 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 03:14:06,087 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:14:06,089 Ignore 1 sentence(s) with no tokens.\n",
      "57\n",
      "2019-12-06 03:15:02,941 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:15:02,943 Ignore 1 sentence(s) with no tokens.\n",
      "51\n",
      "2019-12-06 03:15:54,352 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:15:54,354 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 03:16:07,232 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:16:07,234 Ignore 1 sentence(s) with no tokens.\n",
      "61\n",
      "2019-12-06 03:17:07,945 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:17:07,947 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 03:17:32,926 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:17:32,928 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 03:18:04,144 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:18:04,146 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 03:18:10,750 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:18:10,752 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 03:18:17,913 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:18:17,916 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 03:18:55,673 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:18:55,674 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 03:19:33,386 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:19:33,388 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 03:19:50,924 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:19:50,926 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 03:20:27,625 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:20:27,627 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 03:20:56,429 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:20:56,432 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 03:21:15,703 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:21:15,705 Ignore 1 sentence(s) with no tokens.\n",
      "42\n",
      "2019-12-06 03:21:57,861 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:21:57,864 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 03:22:36,896 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:22:36,898 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 03:22:48,093 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:22:48,094 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 03:23:27,515 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:23:27,517 Ignore 7 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 03:23:47,357 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:23:47,360 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 03:24:06,941 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:24:06,943 Ignore 1 sentence(s) with no tokens.\n",
      "53\n",
      "2019-12-06 03:24:59,323 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:24:59,326 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 03:25:13,033 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:25:13,036 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 03:25:41,236 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:25:41,238 Ignore 2 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 03:26:02,386 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:26:02,388 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:26:16,613 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:26:16,615 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 03:26:27,148 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:26:27,150 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 03:26:54,796 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:26:54,798 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 03:27:10,697 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:27:10,699 Ignore 1 sentence(s) with no tokens.\n",
      "8\n",
      "2019-12-06 03:27:19,017 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:27:19,020 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 03:27:49,921 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:27:49,924 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 03:27:56,262 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:27:56,264 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 03:28:23,991 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:28:23,993 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 03:28:56,527 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:28:56,529 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 03:29:33,565 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:29:33,567 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 03:29:50,775 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:29:50,777 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 03:30:24,972 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:30:24,974 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 03:30:53,311 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:30:53,313 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:31:07,851 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:31:07,853 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 03:31:44,813 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 03:31:44,815 Ignore 1 sentence(s) with no tokens.\n",
      "56\n",
      "2019-12-06 03:32:40,590 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:32:40,592 Ignore 4 sentence(s) with no tokens.\n",
      "41\n",
      "2019-12-06 03:33:21,200 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:33:21,202 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 03:33:52,321 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:33:52,323 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 03:33:59,242 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:33:59,245 Ignore 1 sentence(s) with no tokens.\n",
      "39\n",
      "2019-12-06 03:34:38,790 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:34:38,792 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 03:34:54,274 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:34:54,277 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:35:08,679 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:35:08,681 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:35:22,783 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:35:22,785 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 03:35:32,297 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:35:32,299 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 03:35:58,466 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:35:58,468 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 03:36:09,155 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:36:09,157 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 03:36:29,186 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:36:29,188 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:36:43,508 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:36:43,510 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 03:37:13,966 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:37:13,968 Ignore 1 sentence(s) with no tokens.\n",
      "25\n",
      "2019-12-06 03:37:39,460 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:37:39,462 Ignore 1 sentence(s) with no tokens.\n",
      "40\n",
      "2019-12-06 03:38:19,369 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:38:19,371 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 03:38:29,564 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:38:29,566 Ignore 1 sentence(s) with no tokens.\n",
      "37\n",
      "2019-12-06 03:39:06,404 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:39:06,406 Ignore 3 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 03:39:16,287 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:39:16,289 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 03:40:02,087 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:40:02,089 Ignore 1 sentence(s) with no tokens.\n",
      "56\n",
      "2019-12-06 03:40:58,037 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:40:58,040 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 03:41:29,640 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:41:29,642 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 03:41:45,452 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:41:45,454 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 03:41:58,621 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:41:58,623 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 03:42:27,369 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:42:27,371 Ignore 3 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 03:42:51,884 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:42:51,886 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:43:05,669 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:43:05,671 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 03:43:21,863 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:43:21,865 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 03:43:52,252 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:43:52,254 Ignore 4 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 03:44:15,507 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:44:15,509 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 03:44:32,056 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:44:32,059 Ignore 1 sentence(s) with no tokens.\n",
      "52\n",
      "2019-12-06 03:45:24,616 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:45:24,618 Ignore 1 sentence(s) with no tokens.\n",
      "80\n",
      "2019-12-06 03:46:44,802 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:46:44,805 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 03:47:11,695 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:47:11,697 Ignore 1 sentence(s) with no tokens.\n",
      "48\n",
      "2019-12-06 03:47:59,659 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:47:59,661 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 03:48:08,448 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:48:08,450 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 03:48:15,154 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:48:15,156 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 03:48:46,579 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:48:46,581 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 03:48:56,178 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:48:56,181 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:49:10,650 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:49:10,651 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 03:49:33,065 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:49:33,067 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 03:50:07,169 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:50:07,171 Ignore 1 sentence(s) with no tokens.\n",
      "62\n",
      "2019-12-06 03:51:09,065 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:51:09,067 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 03:51:41,833 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:51:41,835 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:51:56,375 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:51:56,378 Ignore 1 sentence(s) with no tokens.\n",
      "48\n",
      "2019-12-06 03:52:44,517 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:52:44,519 Ignore 1 sentence(s) with no tokens.\n",
      "74\n",
      "2019-12-06 03:53:58,595 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:53:58,597 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 03:54:08,663 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:54:08,666 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 03:54:28,601 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 03:54:28,604 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 03:54:50,159 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:54:50,162 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 03:55:14,629 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:55:14,630 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 03:55:44,978 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:55:44,980 Ignore 1 sentence(s) with no tokens.\n",
      "45\n",
      "2019-12-06 03:56:30,405 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:56:30,407 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 03:56:46,713 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:56:46,715 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 03:56:55,550 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:56:55,553 Ignore 1 sentence(s) with no tokens.\n",
      "34\n",
      "2019-12-06 03:57:29,326 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:57:29,328 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 03:57:43,304 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:57:43,306 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 03:57:57,903 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:57:57,905 Ignore 1 sentence(s) with no tokens.\n",
      "36\n",
      "2019-12-06 03:58:33,453 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:58:33,455 Ignore 1 sentence(s) with no tokens.\n",
      "20\n",
      "2019-12-06 03:58:54,113 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:58:54,116 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 03:59:03,960 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 03:59:03,963 Ignore 1 sentence(s) with no tokens.\n",
      "81\n",
      "2019-12-06 04:00:25,144 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:00:25,146 Ignore 1 sentence(s) with no tokens.\n",
      "49\n",
      "2019-12-06 04:01:13,833 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:01:13,835 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 04:01:23,447 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:01:23,449 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 04:01:49,538 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:01:49,540 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 04:01:55,753 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:01:55,755 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 04:02:42,166 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:02:42,168 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 04:03:15,126 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:03:15,128 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 04:03:32,789 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:03:32,791 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 04:03:40,127 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:03:40,129 Ignore 1 sentence(s) with no tokens.\n",
      "28\n",
      "2019-12-06 04:04:08,372 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:04:08,375 Ignore 1 sentence(s) with no tokens.\n",
      "43\n",
      "2019-12-06 04:04:51,540 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:04:51,543 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 04:05:10,275 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:05:10,277 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 04:05:24,789 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:05:24,791 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 04:05:48,400 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:05:48,402 Ignore 1 sentence(s) with no tokens.\n",
      "70\n",
      "2019-12-06 04:06:58,414 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:06:58,416 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 04:07:09,540 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:07:09,542 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 04:07:32,618 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:07:32,620 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 04:07:42,301 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:07:42,304 Ignore 2 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 04:07:52,783 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:07:52,785 Ignore 233 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 04:08:24,547 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:08:24,551 Ignore 1085 sentence(s) with no tokens.\n",
      "47\n",
      "2019-12-06 04:09:11,406 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:09:11,408 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 04:09:32,645 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:09:32,647 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 04:09:58,488 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:09:58,490 Ignore 1 sentence(s) with no tokens.\n",
      "15\n",
      "2019-12-06 04:10:13,557 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:10:13,559 Ignore 1 sentence(s) with no tokens.\n",
      "23\n",
      "2019-12-06 04:10:36,198 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:10:36,200 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 04:10:57,610 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:10:57,613 Ignore 1 sentence(s) with no tokens.\n",
      "47\n",
      "2019-12-06 04:11:44,870 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:11:44,873 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 04:12:17,759 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:12:17,761 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 04:12:28,420 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:12:28,422 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 04:13:00,788 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:13:00,790 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 04:13:23,125 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:13:23,127 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 04:13:53,657 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:13:53,659 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 04:14:12,557 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:14:12,559 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 04:14:24,868 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:14:24,870 Ignore 1 sentence(s) with no tokens.\n",
      "16\n",
      "2019-12-06 04:14:41,163 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:14:41,165 Ignore 70 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 04:14:51,603 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:14:51,605 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 04:15:03,614 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-06 04:15:03,616 Ignore 1 sentence(s) with no tokens.\n",
      "19\n",
      "2019-12-06 04:15:23,069 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:15:23,071 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 04:15:39,843 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:15:39,845 Ignore 1 sentence(s) with no tokens.\n",
      "52\n",
      "2019-12-06 04:16:31,266 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:16:31,268 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 04:16:44,797 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:16:44,800 Ignore 1 sentence(s) with no tokens.\n",
      "6\n",
      "2019-12-06 04:16:51,133 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:16:51,135 Ignore 1 sentence(s) with no tokens.\n",
      "54\n",
      "2019-12-06 04:17:45,255 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:17:45,257 Ignore 1 sentence(s) with no tokens.\n",
      "57\n",
      "2019-12-06 04:18:42,550 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:18:42,552 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 04:19:12,529 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:19:12,531 Ignore 1 sentence(s) with no tokens.\n",
      "32\n",
      "2019-12-06 04:19:44,426 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:19:44,428 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 04:20:02,508 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:20:02,510 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 04:20:17,106 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:20:17,108 Ignore 1 sentence(s) with no tokens.\n",
      "13\n",
      "2019-12-06 04:20:30,489 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:20:30,491 Ignore 1 sentence(s) with no tokens.\n",
      "14\n",
      "2019-12-06 04:20:44,997 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:20:44,999 Ignore 1 sentence(s) with no tokens.\n",
      "46\n",
      "2019-12-06 04:21:31,687 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:21:31,689 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 04:22:01,990 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:22:01,992 Ignore 1 sentence(s) with no tokens.\n",
      "33\n",
      "2019-12-06 04:22:35,024 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:22:35,026 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 04:22:46,976 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:22:46,978 Ignore 27 sentence(s) with no tokens.\n",
      "65\n",
      "2019-12-06 04:23:52,164 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:23:52,166 Ignore 1 sentence(s) with no tokens.\n",
      "24\n",
      "2019-12-06 04:24:16,858 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:24:16,860 Ignore 1 sentence(s) with no tokens.\n",
      "54\n",
      "2019-12-06 04:25:10,982 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:25:10,985 Ignore 1 sentence(s) with no tokens.\n",
      "11\n",
      "2019-12-06 04:25:21,678 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:25:21,680 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 04:25:31,650 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:25:31,652 Ignore 1 sentence(s) with no tokens.\n",
      "27\n",
      "2019-12-06 04:25:58,890 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:25:58,892 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 04:26:16,753 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:26:16,755 Ignore 1 sentence(s) with no tokens.\n",
      "44\n",
      "2019-12-06 04:27:01,147 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:27:01,149 Ignore 1 sentence(s) with no tokens.\n",
      "18\n",
      "2019-12-06 04:27:19,887 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:27:19,889 Ignore 1 sentence(s) with no tokens.\n",
      "10\n",
      "2019-12-06 04:27:29,263 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:27:29,265 Ignore 1 sentence(s) with no tokens.\n",
      "9\n",
      "2019-12-06 04:27:38,069 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:27:38,070 Ignore 1 sentence(s) with no tokens.\n",
      "17\n",
      "2019-12-06 04:27:54,792 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:27:54,794 Ignore 1 sentence(s) with no tokens.\n",
      "30\n",
      "2019-12-06 04:28:24,851 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:28:24,853 Ignore 1 sentence(s) with no tokens.\n",
      "26\n",
      "2019-12-06 04:28:50,894 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:28:50,896 Ignore 1 sentence(s) with no tokens.\n",
      "12\n",
      "2019-12-06 04:29:02,698 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:29:02,700 Ignore 3 sentence(s) with no tokens.\n",
      "45\n",
      "2019-12-06 04:29:47,553 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:29:47,556 Ignore 1 sentence(s) with no tokens.\n",
      "22\n",
      "2019-12-06 04:30:09,871 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:30:09,872 Ignore 1 sentence(s) with no tokens.\n",
      "7\n",
      "2019-12-06 04:30:16,231 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:30:16,233 Ignore 1 sentence(s) with no tokens.\n",
      "38\n",
      "2019-12-06 04:30:54,267 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:30:54,269 Ignore 1 sentence(s) with no tokens.\n",
      "48\n",
      "2019-12-06 04:31:42,457 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:31:42,459 Ignore 1 sentence(s) with no tokens.\n",
      "21\n",
      "2019-12-06 04:32:03,975 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:32:03,977 Ignore 1 sentence(s) with no tokens.\n",
      "29\n",
      "2019-12-06 04:32:33,462 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:32:33,464 Ignore 1 sentence(s) with no tokens.\n",
      "31\n",
      "2019-12-06 04:33:04,260 ACHTUNG: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2019-12-06 04:33:04,262 Ignore 1 sentence(s) with no tokens.\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "article_path = '/nfs/gns/literature/machine-learning/evaluation/time_complexity/articles/'\n",
    "all_files = sorted(glob.glob(article_path + '*.txt*'))\n",
    "result_json_dump_path = '/nfs/gns/literature/machine-learning/evaluation/time_complexity/flair/'\n",
    "\n",
    "offset = 26\n",
    "\n",
    "already_processed_files = sorted(glob.glob(result_json_dump_path + '*.json*'))\n",
    "names = [os.path.basename(x) for x in already_processed_files]\n",
    "already_processed_PMC_ids = [x[:-5]+'.json' for x in names]\n",
    "\n",
    "# article_file_path = article_path+'PMC3649237_sentences.txt'\n",
    "\n",
    "for article_file_path in all_files:\n",
    "    \n",
    "    \n",
    "    result_file_name = os.path.basename(article_file_path)[:-4] + '.json'\n",
    "    \n",
    "    if not result_file_name in already_processed_PMC_ids:\n",
    "        with open(article_file_path, 'r') as f:\n",
    "            article_contents = f.read()\n",
    "\n",
    "            tstart = time.time()\n",
    "            sentences = []\n",
    "            for each_sentence in article_contents.split('\\n'):\n",
    "                sentences.append(Sentence(each_sentence, use_tokenizer=custom_tokenizer)) \n",
    "\n",
    "#             predicted_sentences = flair_model.predict(sentences)\n",
    "            predicted_sentences = flair_model.predict(sentences, mini_batch_size=16)\n",
    "            entity_dict={}\n",
    "            all_entities = []\n",
    "            list_names = ['exact', 'prefix','postfix','entity','ground']\n",
    "\n",
    "            for i in range(0,len(sentences)):\n",
    "                entities = predicted_sentences[i].to_dict(tag_type='ner')['entities']\n",
    "                if entities:\n",
    "                    tagged_sents = predicted_sentences[i].to_dict(tag_type='ner')\n",
    "                    text = tagged_sents['text']\n",
    "                    for root_node in tagged_sents['entities']:\n",
    "                        exact = root_node['text']\n",
    "                        prefix = text[root_node['start_pos']-offset:root_node['start_pos']-1]\n",
    "                        postfix = text[root_node['end_pos']+1:root_node['end_pos']+offset]\n",
    "                        entity = root_node['type']\n",
    "                        normalise = ground_annotation(exact,entity)\n",
    "                        data_names = [exact, prefix,postfix,entity,normalise]\n",
    "\n",
    "                        all_entities.append(dict(zip(list_names,data_names)))\n",
    "\n",
    "            tend = time.time()\n",
    "            t_elapsed = round(tend - tstart)\n",
    "            print(t_elapsed) \n",
    "\n",
    "            entity_dict['tagged_entities'] = all_entities\n",
    "            entity_dict['time_taken'] = t_elapsed\n",
    "\n",
    "            with open(result_json_dump_path+result_file_name, 'w') as outfile:\n",
    "                json.dump(entity_dict, outfile)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tagged_entities': [{'exact': 'chronic illnesses',\n",
       "   'prefix': 'ead to people living with',\n",
       "   'postfix': 'gaining control of their ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009801'},\n",
       "  {'exact': 'chronically ill',\n",
       "   'prefix': 'of older [9] and severely',\n",
       "   'postfix': 'people [10].',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007348'},\n",
       "  {'exact': 'lung diseases',\n",
       "   'prefix': 'es studied were heart and',\n",
       "   'postfix': ' chronic wounds, diabetes',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003818'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'diseases, chronic wounds,',\n",
       "   'postfix': ' cancer, and stroke.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'chronic wounds, diabetes,',\n",
       "   'postfix': ' and stroke.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'ds, diabetes, cancer, and',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'infectious diseases',\n",
       "   'prefix': 'itions were, for example,',\n",
       "   'postfix': ' spinal cord injuries, an',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0005741'},\n",
       "  {'exact': 'chronic illnesses',\n",
       "   'prefix': 'm both people living with',\n",
       "   'postfix': 'and healthcare profession',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009801'},\n",
       "  {'exact': 'chronic illnesses',\n",
       "   'prefix': 'w that people living with',\n",
       "   'postfix': 'and healthcare profession',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009801'},\n",
       "  {'exact': 'chronic illnesses',\n",
       "   'prefix': 'upport people living with',\n",
       "   'postfix': 'gaining control of their ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009801'},\n",
       "  {'exact': 'Chronically ill',\n",
       "   'prefix': 'ed home telecare services',\n",
       "   'postfix': 'patients could use medica',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007348'},\n",
       "  {'exact': 'human',\n",
       "   'prefix': 'for more efficient use of',\n",
       "   'postfix': 'resources and cost effect',\n",
       "   'entity': 'OG',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/NCBITaxon_145856'},\n",
       "  {'exact': 'BP',\n",
       "   'prefix': 'c home BPLink monitor and',\n",
       "   'postfix': 'monitoring services.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/NCBITaxon_197221'},\n",
       "  {'exact': 'ischemic heart failure',\n",
       "   'prefix': 'ypass graft patients with',\n",
       "   'postfix': ' using a device called th',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': ' for patients with severe',\n",
       "   'postfix': 'using aggressive remote t',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'g of patients with severe',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'of these technologies and',\n",
       "   'postfix': 'management by an advanced',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'chronic illnesses',\n",
       "   'prefix': 'decreasing the effects of',\n",
       "   'postfix': 'and functional decline.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009801'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'charge from the hospital,',\n",
       "   'postfix': 'patients with new ostomie',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 've the self-management of',\n",
       "   'postfix': 'for older adults who were',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'ge and self-management of',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'elivered to patients with',\n",
       "   'postfix': 'and diabetes using three ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'ts with heart failure and',\n",
       "   'postfix': 'using three different mod',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': '',\n",
       "   'postfix': 'and receiving more in-per',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'he homes of patients with',\n",
       "   'postfix': ' and they were trained in',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': '1c for the residents with',\n",
       "   'postfix': ' but there was no signifi',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': '',\n",
       "   'postfix': 'and hypertension, self-ef',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'hypertension',\n",
       "   'prefix': 'Knowledge of diabetes and',\n",
       "   'postfix': ' self-efficacy, and perce',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000537'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'wo initial home visits to',\n",
       "   'postfix': 'patients at home and foll',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'oduced at the time of the',\n",
       "   'postfix': \"survivors' discharge, whe\",\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'to provide individualized',\n",
       "   'postfix': 'care management and to ha',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'followup, to manage their',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'th a recent admission for',\n",
       "   'postfix': 'and left ventricular ejec',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'of selected patients with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'dementia',\n",
       "   'prefix': 'telephone-linked care for',\n",
       "   'postfix': 'was conducted.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/HP_0000726'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': '',\n",
       "   'postfix': 'received the Health Buddy',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'ents questions related to',\n",
       "   'postfix': 'including symptoms, self-',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'lth on self-management of',\n",
       "   'postfix': 'in a sample of older adul',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'chronic heart failure',\n",
       "   'prefix': ' weight, of patients with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'Chronic Heart Failure',\n",
       "   'prefix': 'n the quality of life and',\n",
       "   'postfix': 'Questionnaire scores betw',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'depression',\n",
       "   'prefix': 'a significant decrease in',\n",
       "   'postfix': 'among caregivers receivin',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003761'},\n",
       "  {'exact': 'chronically ill',\n",
       "   'prefix': 'ome health care nurse and',\n",
       "   'postfix': 'patients at home can impr',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007348'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': '',\n",
       "   'postfix': 'were reflecting on issues',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'power and surveillance in',\n",
       "   'postfix': 'care.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': '',\n",
       "   'postfix': 'care at home reported pos',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'chronic leg ulcers',\n",
       "   'prefix': 'nagement of patients with',\n",
       "   'postfix': 'by homecare nurses were e',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_1001923'},\n",
       "  {'exact': 'chronic leg ulcers',\n",
       "   'prefix': '',\n",
       "   'postfix': 'of different origin were ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_1001923'},\n",
       "  {'exact': 'chronic obstructive pulmonary disease',\n",
       "   'prefix': 'ients living at home with',\n",
       "   'postfix': '(COPD) by a home care tea',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'COPD',\n",
       "   'prefix': 'uctive pulmonary disease ',\n",
       "   'postfix': ' by a home care team usin',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'COPD',\n",
       "   'prefix': 'es in practice can impact',\n",
       "   'postfix': 'care.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'chronic diseases',\n",
       "   'prefix': '',\n",
       "   'postfix': 'and high healthcare utili',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_1000179'},\n",
       "  {'exact': 'congestive heart failure',\n",
       "   'prefix': ' care models for reducing',\n",
       "   'postfix': 'related readmission charg',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'congestive heart failure',\n",
       "   'prefix': '-care models for reducing',\n",
       "   'postfix': '(CHF) readmission charges',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'congestive heart failure ',\n",
       "   'postfix': ' readmission charges duri',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': '',\n",
       "   'postfix': 'hospitalizations and allo',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'congestive heart failure',\n",
       "   'prefix': 'missions for persons with',\n",
       "   'postfix': '(CHF), but the interventi',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'congestive heart failure ',\n",
       "   'postfix': ', but the intervention co',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'type 2 diabetes mellitus',\n",
       "   'prefix': 'ed by a male patient with',\n",
       "   'postfix': 'to see whether it would e',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0001360'},\n",
       "  {'exact': 'haemoglobin',\n",
       "   'prefix': ' glucose and glycosylated',\n",
       "   'postfix': '(HbA1c) and in blood pres',\n",
       "   'entity': 'GP',\n",
       "   'ground': 'not-grounded'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'eceiving chemotherapy for',\n",
       "   'postfix': 'was evaluated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'ly symptom reports to the',\n",
       "   'postfix': 'centre and receive instan',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'caregivers of people with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'rnment service (23%), and',\n",
       "   'postfix': 'and related issues in dea',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'ed issues in dealing with',\n",
       "   'postfix': '(58%).',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'heart failure disease',\n",
       "   'prefix': 'easibility of providing a',\n",
       "   'postfix': 'management programme was ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'depression',\n",
       "   'prefix': 'icacy, functional status,',\n",
       "   'postfix': ' and health-related quali',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003761'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'r ability to manage their',\n",
       "   'postfix': ' whereas all other groups',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'depression',\n",
       "   'prefix': 'es for functional status,',\n",
       "   'postfix': ' or health-related qualit',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003761'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': '',\n",
       "   'postfix': 'used a Health Buddy for s',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'ven questions daily about',\n",
       "   'postfix': 'symptom status and abilit',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'ed, taught, and supported',\n",
       "   'postfix': 'self-management; and that',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'diabetic foot ulcers',\n",
       "   'prefix': '',\n",
       "   'postfix': 'were offered three video-',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_1001459'},\n",
       "  {'exact': 'HIV',\n",
       "   'prefix': 'manage their caseloads of',\n",
       "   'postfix': 'AIDs clients, increase re',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007311'},\n",
       "  {'exact': 'AIDs',\n",
       "   'prefix': 'ge their caseloads of HIV',\n",
       "   'postfix': 'clients, increase respons',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000765'},\n",
       "  {'exact': 'Asthma',\n",
       "   'prefix': 'g out of the intervention',\n",
       "   'postfix': 'care mobile service (ACMS',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': 'MS is a care platform for',\n",
       "   'postfix': 'patients that uses mobile',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': ' mobile phones to monitor',\n",
       "   'postfix': \"patients' real-time condi\",\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': '',\n",
       "   'postfix': 'event occurred, it was po',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'alth system for assessing',\n",
       "   'postfix': \"patients' physical functi\",\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'depression',\n",
       "   'prefix': \"ents' physical functions,\",\n",
       "   'postfix': ' fear of falling, and the',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003761'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'fy postdischarge needs of',\n",
       "   'postfix': 'patients; their caregiver',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'ld be beneficial to their',\n",
       "   'postfix': 'recovery at home, and tha',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'ir caregivers in managing',\n",
       "   'postfix': 'recovery across the conti',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'chronic obstructive pulmonary disease',\n",
       "   'prefix': 'ing acute exacerbation of',\n",
       "   'postfix': '(COPD) was conducted.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'COPD',\n",
       "   'prefix': 'uctive pulmonary disease ',\n",
       "   'postfix': ' was conducted.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'acute infections',\n",
       "   'prefix': '',\n",
       "   'postfix': 'transitioning in the home',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_1001303'},\n",
       "  {'exact': 'acutely ill',\n",
       "   'prefix': ' a support when they were',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007348'},\n",
       "  {'exact': 'acute infection',\n",
       "   'prefix': 'als transitioning from an',\n",
       "   'postfix': 'in their home.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/MONDO_0000166'},\n",
       "  {'exact': 'acute infection',\n",
       "   'prefix': 'hen an individual with an',\n",
       "   'postfix': 'was discharged from the h',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/MONDO_0000166'},\n",
       "  {'exact': 'colorectal cancer',\n",
       "   'prefix': 'nts with lung, breast, or',\n",
       "   'postfix': 'was evaluated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0005842'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'istants (PDAs) for use by',\n",
       "   'postfix': 'outpatients in their dail',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': ' send these data to their',\n",
       "   'postfix': 'centre.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': '',\n",
       "   'postfix': 'care nurses were alerted ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': ' bypass graft (CABG) with',\n",
       "   'postfix': ' which delivers “daily se',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'type 2 diabetes',\n",
       "   'prefix': 'dicare beneficiaries with',\n",
       "   'postfix': 'were estimated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0001360'},\n",
       "  {'exact': 'Diabetes',\n",
       "   'prefix': '',\n",
       "   'postfix': 'Education and Telemedicin',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'congestive heart failure',\n",
       "   'prefix': 'the care of patients with',\n",
       "   'postfix': 'was examined.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'chronically ill',\n",
       "   'prefix': '(ICT) to communicate with',\n",
       "   'postfix': 'people in their homes wer',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007348'},\n",
       "  {'exact': 'chronically ill',\n",
       "   'prefix': 'he DN to better support a',\n",
       "   'postfix': 'person at home, leading t',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0007348'},\n",
       "  {'exact': 'chronic illnesses',\n",
       "   'prefix': '',\n",
       "   'postfix': 'who used information and ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009801'},\n",
       "  {'exact': 'infection',\n",
       "   'prefix': ' to detect early signs of',\n",
       "   'postfix': 'and or rejection.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000544'},\n",
       "  {'exact': 'infection',\n",
       "   'prefix': ' (general, lifestyle, and',\n",
       "   'postfix': ', goals, timing, techniqu',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000544'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'ivers of individuals with',\n",
       "   'postfix': 'was developed to provide ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'aregivers of persons with',\n",
       "   'postfix': 'during the first year aft',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'nal needs of survivors of',\n",
       "   'postfix': 'and their caregivers were',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'ventricular tachycardia',\n",
       "   'prefix': 'd due to the detection of',\n",
       "   'postfix': ' ventricular fibrillation',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0005306'},\n",
       "  {'exact': 'ventricular fibrillation',\n",
       "   'prefix': ' ventricular tachycardia,',\n",
       "   'postfix': ' ineffective defibrillati',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0004287'},\n",
       "  {'exact': 'supraventricular tachycardia',\n",
       "   'prefix': ' with maximal energy, and',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/HP_0004755'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 've care for patients with',\n",
       "   'postfix': 'enrolled in a home health',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'on, decreased symptoms of',\n",
       "   'postfix': ' and increased quality of',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'ng care for patients with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': '',\n",
       "   'postfix': 'such as fatigue, shortnes',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'he care for patients with',\n",
       "   'postfix': 'in a more effective and e',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'prostate cancer',\n",
       "   'prefix': ' caregiving functions for',\n",
       "   'postfix': 'and provide tailored skil',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/MONDO_0008315'},\n",
       "  {'exact': 'cancer',\n",
       "   'prefix': 'and family members from a',\n",
       "   'postfix': 'center on perceived needs',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000311'},\n",
       "  {'exact': 'prostate cancer',\n",
       "   'prefix': 'rticularly in the area of',\n",
       "   'postfix': 'caregiving, is clearly va',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://purl.obolibrary.org/obo/MONDO_0008315'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': '',\n",
       "   'postfix': 'were provided with a spec',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'diabetes',\n",
       "   'prefix': 'mproved glycemic control,',\n",
       "   'postfix': 'self-care, and other heal',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000400'},\n",
       "  {'exact': 'angiotensin-converting enzyme',\n",
       "   'prefix': 'ta blocker, diuretic, and',\n",
       "   'postfix': '(ACE)-inhibitor therapy.',\n",
       "   'entity': 'GP',\n",
       "   'ground': ['Q9BYF1']},\n",
       "  {'exact': 'ACE',\n",
       "   'prefix': 'tensin-converting enzyme ',\n",
       "   'postfix': '-inhibitor therapy.',\n",
       "   'entity': 'GP',\n",
       "   'ground': ['Q9NDG8']},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'n problems connected with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'chronic heart failure',\n",
       "   'prefix': 'diology for patients with',\n",
       "   'postfix': '(CHF) was assessed.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'th chronic heart failure ',\n",
       "   'postfix': ' was assessed.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'iography (ECG) monitoring',\n",
       "   'postfix': 'patients were enrolled in',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': '',\n",
       "   'postfix': 'patients using a nurse-le',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'HF',\n",
       "   'prefix': 'mission for patients with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009258'},\n",
       "  {'exact': 'HF',\n",
       "   'prefix': 'nitoring of patients with',\n",
       "   'postfix': 'to better target those wh',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009258'},\n",
       "  {'exact': 'obstructive sleep apnea',\n",
       "   'prefix': 'echanical ventilators for',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003918'},\n",
       "  {'exact': 'sleep apnea',\n",
       "   'prefix': 'e (CPAP) by patients with',\n",
       "   'postfix': 'was tested.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003877'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'me-based intervention for',\n",
       "   'postfix': 'was evaluated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'hypertension',\n",
       "   'prefix': 'd a promising approach in',\n",
       "   'postfix': 'treatment but needs some ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000537'},\n",
       "  {'exact': 'chronic obstructive pulmonary disease',\n",
       "   'prefix': 'program for patients with',\n",
       "   'postfix': '(COPD) and/or congestive ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'COPD',\n",
       "   'prefix': 'uctive pulmonary disease ',\n",
       "   'postfix': ' and/or congestive heart ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'congestive heart failure',\n",
       "   'prefix': 'ary disease (COPD) and/or',\n",
       "   'postfix': '(CHF) was evaluated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'congestive heart failure ',\n",
       "   'postfix': ' was evaluated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'COPD',\n",
       "   'prefix': '',\n",
       "   'postfix': 'and/or CHF who were presc',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'CHF',\n",
       "   'prefix': 'iagnosed with COPD and/or',\n",
       "   'postfix': 'who were prescribed home ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000373'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': 'ared with regular care in',\n",
       "   'postfix': 'was evaluated.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': 'ntervention group used an',\n",
       "   'postfix': 'monitor with modem at hom',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': 'th modem at home, with an',\n",
       "   'postfix': 'nurse as the main caregiv',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': '',\n",
       "   'postfix': 'symptoms and medical cons',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'asthma',\n",
       "   'prefix': 'hould be a key element in',\n",
       "   'postfix': 'tele-monitoring programme',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000270'},\n",
       "  {'exact': 'stroke',\n",
       "   'prefix': 'functional assessments of',\n",
       "   'postfix': 'subjects using a collecti',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000712'},\n",
       "  {'exact': 'insulin',\n",
       "   'prefix': 'c temperature, or draw up',\n",
       "   'postfix': 'in a syringe.',\n",
       "   'entity': 'GP',\n",
       "   'ground': ['Q54JQ2']},\n",
       "  {'exact': 'chronic respiratory failure',\n",
       "   'prefix': 'nitoring of patients with',\n",
       "   'postfix': '(CRF) discharged from hos',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009686'},\n",
       "  {'exact': 'CRF',\n",
       "   'prefix': 'onic respiratory failure ',\n",
       "   'postfix': ' discharged from hospital',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0002679'},\n",
       "  {'exact': 'chronic respiratory failure',\n",
       "   'prefix': 'ce (TA) for patients with',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009686'},\n",
       "  {'exact': 'COPD',\n",
       "   'prefix': 'P calls, or exacerbations',\n",
       "   'postfix': 'patients, as a separate g',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'chronic respiratory failure',\n",
       "   'prefix': '',\n",
       "   'postfix': 'patients on oxygen or hom',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0009686'},\n",
       "  {'exact': 'chronic obstructive pulmonary disease',\n",
       "   'prefix': '',\n",
       "   'postfix': 'group seems to have a gre',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0000341'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'l status in patients with',\n",
       "   'postfix': 'or angina was tested.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'angina',\n",
       "   'prefix': 'nts with heart failure or',\n",
       "   'postfix': 'was tested.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003913'},\n",
       "  {'exact': 'angina',\n",
       "   'prefix': 'ospital for patients with',\n",
       "   'postfix': 'and improved quality of l',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003913'},\n",
       "  {'exact': 'heart failure',\n",
       "   'prefix': 'l status in patients with',\n",
       "   'postfix': 'or angina.',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003144'},\n",
       "  {'exact': 'angina',\n",
       "   'prefix': 'nts with heart failure or',\n",
       "   'postfix': '',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003913'},\n",
       "  {'exact': 'heart disease',\n",
       "   'prefix': 'nitoring to patients with',\n",
       "   'postfix': 'at high risk of hospital ',\n",
       "   'entity': 'DS',\n",
       "   'ground': 'http://www.ebi.ac.uk/efo/EFO_0003777'}],\n",
       " 'time_taken': 49}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 - 284/27\n",
    "8 - 182/18\n",
    "16 - 128/19\n",
    "32 - 109/136/13\n",
    "128 - 152\n",
    "\n",
    "nothing - 134/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def ground_annotation(exact,entity):\n",
    "    grounded_value = 'not-grounded'\n",
    "    \n",
    "    root_url = 'https://www.ebi.ac.uk/ols/api/search?'\n",
    "    URL = root_url\n",
    "    \n",
    "    if entity == 'DS':\n",
    "        URL = root_url+'q='+exact+'&exact=false&ontology=efo'\n",
    "    elif entity == 'OG':\n",
    "        URL = root_url+'q='+exact+'&exact=false&ontology=ncbitaxon'\n",
    "    elif entity == 'GP':\n",
    "        URL = 'http://10.7.35.118:8157/solr/Genes/select?q='+exact\n",
    "    else:\n",
    "#         print(URL)\n",
    "        return 'URL missing'\n",
    "    \n",
    "    r = requests.get(URL)\n",
    "\n",
    "    if r.status_code ==200:\n",
    "        json_data = r.json()\n",
    "    else:\n",
    "        return grounded_value\n",
    "\n",
    "\n",
    "    if json_data['response']['numFound']!=0:\n",
    "        if entity in ['DS', 'OG']:\n",
    "            grounded_value = json_data['response']['docs'][0]['iri']\n",
    "        elif entity in ['GP']:\n",
    "            grounded_value = json_data['response']['docs'][0]['ID']\n",
    "    \n",
    "    return grounded_value    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
