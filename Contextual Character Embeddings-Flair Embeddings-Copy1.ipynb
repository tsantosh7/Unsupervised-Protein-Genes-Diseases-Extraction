{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flair.models import TextClassifier\n",
    "# from flair.data import Sentence\n",
    "# classifier = TextClassifier.load('en-sentiment')\n",
    "# sentence = Sentence('Flair is pretty neat!')\n",
    "# classifier.predict(sentence)\n",
    "# # print sentence with predicted labels\n",
    "# print('Sentence above is: ', sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import codecs\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "data_path = os.getcwd()+'/Datasets/'\n",
    "# os.path.abspath(os.path.join(os.path.dirname( '__file__' ), '..', 'Datasets'))+'/'\n",
    "\n",
    "# Although the dataset says csv, it is tab delimited. In addition to this, they have severe codels problems. \n",
    "# So best to parse throught codes first. \n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfc in position 2: invalid start byte\n",
    "\n",
    "#open for reading with \"universal\" type set\n",
    "\n",
    "import codecs\n",
    "\n",
    "doc_d_t = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_target'+'.csv','rU','UTF-8') \n",
    "EUADR_drug_target = pd.read_csv(doc_d_t, sep='\\t', na_filter = False)\n",
    "EUADR_drug_target['CLASS'] = 'drug_gene'\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_target_disease'+'.csv','rU','UTF-8',errors='ignore') \n",
    "EUADR_target_disease = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "EUADR_target_disease['CLASS'] = 'gene_disease'\n",
    "       \n",
    "doc_d_d = codecs.open(data_path+'EUADR_Corpus_IBIgroup/'+'EUADR_drug_disease'+'.csv','rU','UTF-8')                       \n",
    "EUADR_drug_disease = pd.read_csv(doc_d_d, sep='\\t', na_filter = False)\n",
    "EUADR_drug_disease['CLASS'] = 'drug_disease'\n",
    "\n",
    "\n",
    "EUADR_temp = EUADR_drug_target.append(EUADR_target_disease).append(EUADR_drug_disease)\n",
    "\n",
    "EUADR_temp_1 = EUADR_temp[EUADR_temp['ASSOCIATION_TYPE'] == 'PA']\n",
    "EUADR_temp_2 = EUADR_temp[EUADR_temp['ASSOCIATION_TYPE'] == 'NA']\n",
    "EUADR_temp = EUADR_temp_1.append(EUADR_temp_2)\n",
    "EUADR_temp.rename(columns={\"SENTENCE\": \"text\", \"ASSOCIATION_TYPE\": \"label\"}, inplace=True)\n",
    "\n",
    "EUADR_temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GAD dataset\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'GAD_Corpus_IBIgroup/'+'GAD_Y_N'+'.csv','rU','UTF-8',errors='ignore') \n",
    "GAD_target_disease_Y_N = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "GAD_target_disease_Y_N['CLASS'] = 'gene_disease'\n",
    "\n",
    "doc_t_d = codecs.open(data_path+'GAD_Corpus_IBIgroup/'+'GAD_F'+'.csv','rU','UTF-8',errors='ignore') \n",
    "GAD_target_disease_F = pd.read_csv(doc_t_d, sep='\\t', na_filter = False)\n",
    "GAD_target_disease_F['CLASS'] = 'gene_disease'\n",
    "\n",
    "GAD_temp = GAD_target_disease_Y_N\n",
    "\n",
    "\n",
    "\n",
    "GAD_temp['GAD_ASSOC'] = GAD_temp['GAD_ASSOC'].apply(lambda x: x.replace('Y', 'PA').replace('N', 'NA').replace('F', 'FA'))\n",
    "\n",
    "GAD_temp.rename(columns={\"GAD_ASSOC\": \"label\", \"GAD_CONCLUSION\": \"text\"}, inplace=True)\n",
    "GAD_temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = EUADR_temp[['label','text']].append(GAD_temp[['label','text']])\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"index\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(data_path+'CoMAGC/'+'CoMAGC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '/home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD/'\n",
    "\n",
    "data = df\n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "data.iloc[0:int(len(data)*0.8)].to_csv(data_loc+'train.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv(data_loc+'test.csv', sep='\\t', index = False, header = False)\n",
    "data.iloc[int(len(data)*0.9):].to_csv(data_loc+'dev.csv', sep='\\t', index = False, header = False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 14:59:06,321 Reading data from /home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD\n",
      "2019-08-28 14:59:06,323 Train: /home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD/train.csv\n",
      "2019-08-28 14:59:06,324 Dev: /home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD/dev.csv\n",
      "2019-08-28 14:59:06,325 Test: /home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stirunag/anaconda3/envs/flair/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/stirunag/anaconda3/envs/flair/lib/python3.7/site-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "/home/stirunag/anaconda3/envs/flair/lib/python3.7/site-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n",
      "/home/stirunag/anaconda3/envs/flair/lib/python3.7/site-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  max_tokens_per_doc=max_tokens_per_doc,\n"
     ]
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_loc), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:00:54,821 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/pubmed-2015-fw-lm.pt not found in cache, downloading to /tmp/tmpfuvsou6k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111081366/111081366 [00:02<00:00, 46460973.66B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:00:57,402 copying /tmp/tmpfuvsou6k to cache at /home/stirunag/.flair/embeddings/pubmed-2015-fw-lm.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:00:57,546 removing temp file /tmp/tmpfuvsou6k\n",
      "2019-08-28 15:00:57,843 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/pubmed-2015-bw-lm.pt not found in cache, downloading to /tmp/tmpdx5holkv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111081366/111081366 [00:02<00:00, 45003076.24B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:01:00,519 copying /tmp/tmpdx5holkv to cache at /home/stirunag/.flair/embeddings/pubmed-2015-bw-lm.pt\n",
      "2019-08-28 15:01:00,602 removing temp file /tmp/tmpdx5holkv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast'), FlairEmbeddings('pubmed-forward'), \n",
    "FlairEmbeddings('pubmed-backward')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                   rnn_type = \"LSTM\",\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:01:07,453 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2688/2688 [00:00<00:00, 142813.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:01:07,478 [b'PA', b'NA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:01:18,861 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:18,863 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_3): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.5, inplace=False)\n",
      "          (encoder): Embedding(275, 200)\n",
      "          (rnn): LSTM(200, 1150, num_layers=3, dropout=0.5)\n",
      "          (decoder): Linear(in_features=1150, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_4): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.5, inplace=False)\n",
      "          (encoder): Embedding(275, 200)\n",
      "          (rnn): LSTM(200, 1150, num_layers=3, dropout=0.5)\n",
      "          (decoder): Linear(in_features=1150, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=4448, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-08-28 15:01:18,864 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:18,865 Corpus: \"Corpus: 2688 train + 336 dev + 336 test sentences\"\n",
      "2019-08-28 15:01:18,865 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:18,866 Parameters:\n",
      "2019-08-28 15:01:18,868  - learning_rate: \"0.1\"\n",
      "2019-08-28 15:01:18,869  - mini_batch_size: \"32\"\n",
      "2019-08-28 15:01:18,870  - patience: \"5\"\n",
      "2019-08-28 15:01:18,871  - anneal_factor: \"0.5\"\n",
      "2019-08-28 15:01:18,872  - max_epochs: \"10\"\n",
      "2019-08-28 15:01:18,873  - shuffle: \"True\"\n",
      "2019-08-28 15:01:18,874  - train_with_dev: \"False\"\n",
      "2019-08-28 15:01:18,874 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:18,875 Model training base path: \"/home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD\"\n",
      "2019-08-28 15:01:18,876 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:18,877 Device: cpu\n",
      "2019-08-28 15:01:18,879 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:18,880 Embeddings storage mode: cpu\n",
      "2019-08-28 15:01:18,883 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:01:23,233 epoch 1 - iter 0/84 - loss 0.68167895 - samples/sec: 58.90\n",
      "2019-08-28 15:02:01,425 epoch 1 - iter 8/84 - loss 0.57745743 - samples/sec: 6.71\n",
      "2019-08-28 15:02:37,214 epoch 1 - iter 16/84 - loss 0.57892828 - samples/sec: 7.16\n",
      "2019-08-28 15:03:17,320 epoch 1 - iter 24/84 - loss 0.58949974 - samples/sec: 6.39\n",
      "2019-08-28 15:03:51,467 epoch 1 - iter 32/84 - loss 0.59745201 - samples/sec: 7.50\n",
      "2019-08-28 15:04:26,885 epoch 1 - iter 40/84 - loss 0.59447556 - samples/sec: 7.23\n",
      "2019-08-28 15:04:59,068 epoch 1 - iter 48/84 - loss 0.59788306 - samples/sec: 7.96\n",
      "2019-08-28 15:05:30,200 epoch 1 - iter 56/84 - loss 0.59616712 - samples/sec: 8.23\n",
      "2019-08-28 15:05:59,257 epoch 1 - iter 64/84 - loss 0.59586056 - samples/sec: 8.81\n",
      "2019-08-28 15:06:36,089 epoch 1 - iter 72/84 - loss 0.59594606 - samples/sec: 6.95\n",
      "2019-08-28 15:07:15,903 epoch 1 - iter 80/84 - loss 0.59331519 - samples/sec: 6.43\n",
      "2019-08-28 15:07:31,990 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:07:31,991 EPOCH 1 done: loss 0.5949 - lr 0.1000\n",
      "2019-08-28 15:08:01,111 DEV : loss 0.6471119523048401 - score 0.628\n",
      "2019-08-28 15:08:01,156 BAD EPOCHS (no improvement): 0\n",
      "2019-08-28 15:08:03,712 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:04,067 epoch 2 - iter 0/84 - loss 0.53921843 - samples/sec: 726.79\n",
      "2019-08-28 15:08:05,551 epoch 2 - iter 8/84 - loss 0.59200417 - samples/sec: 174.05\n",
      "2019-08-28 15:08:07,135 epoch 2 - iter 16/84 - loss 0.57968885 - samples/sec: 163.14\n",
      "2019-08-28 15:08:08,480 epoch 2 - iter 24/84 - loss 0.56410921 - samples/sec: 193.20\n",
      "2019-08-28 15:08:10,017 epoch 2 - iter 32/84 - loss 0.55203804 - samples/sec: 168.88\n",
      "2019-08-28 15:08:11,632 epoch 2 - iter 40/84 - loss 0.55982715 - samples/sec: 160.02\n",
      "2019-08-28 15:08:12,976 epoch 2 - iter 48/84 - loss 0.56311370 - samples/sec: 192.36\n",
      "2019-08-28 15:08:14,405 epoch 2 - iter 56/84 - loss 0.56501404 - samples/sec: 181.59\n",
      "2019-08-28 15:08:16,263 epoch 2 - iter 64/84 - loss 0.56451827 - samples/sec: 138.73\n",
      "2019-08-28 15:08:17,698 epoch 2 - iter 72/84 - loss 0.56373921 - samples/sec: 181.23\n",
      "2019-08-28 15:08:19,302 epoch 2 - iter 80/84 - loss 0.56641150 - samples/sec: 161.76\n",
      "2019-08-28 15:08:19,986 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:19,987 EPOCH 2 done: loss 0.5668 - lr 0.1000\n",
      "2019-08-28 15:08:20,386 DEV : loss 0.6153796315193176 - score 0.6815\n",
      "2019-08-28 15:08:20,433 BAD EPOCHS (no improvement): 0\n",
      "2019-08-28 15:08:23,002 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:23,188 epoch 3 - iter 0/84 - loss 0.56714880 - samples/sec: 1394.54\n",
      "2019-08-28 15:08:25,189 epoch 3 - iter 8/84 - loss 0.50673016 - samples/sec: 129.32\n",
      "2019-08-28 15:08:26,552 epoch 3 - iter 16/84 - loss 0.53665633 - samples/sec: 189.67\n",
      "2019-08-28 15:08:28,090 epoch 3 - iter 24/84 - loss 0.53379644 - samples/sec: 168.03\n",
      "2019-08-28 15:08:29,780 epoch 3 - iter 32/84 - loss 0.53865161 - samples/sec: 153.52\n",
      "2019-08-28 15:08:31,689 epoch 3 - iter 40/84 - loss 0.53864420 - samples/sec: 135.14\n",
      "2019-08-28 15:08:33,433 epoch 3 - iter 48/84 - loss 0.53059208 - samples/sec: 147.94\n",
      "2019-08-28 15:08:34,944 epoch 3 - iter 56/84 - loss 0.53036417 - samples/sec: 171.42\n",
      "2019-08-28 15:08:36,621 epoch 3 - iter 64/84 - loss 0.53055327 - samples/sec: 154.00\n",
      "2019-08-28 15:08:38,149 epoch 3 - iter 72/84 - loss 0.53096356 - samples/sec: 169.54\n",
      "2019-08-28 15:08:39,624 epoch 3 - iter 80/84 - loss 0.53049640 - samples/sec: 175.74\n",
      "2019-08-28 15:08:40,387 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:40,387 EPOCH 3 done: loss 0.5391 - lr 0.1000\n",
      "2019-08-28 15:08:40,805 DEV : loss 0.6565684676170349 - score 0.5833\n",
      "2019-08-28 15:08:40,850 BAD EPOCHS (no improvement): 1\n",
      "2019-08-28 15:08:40,851 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:41,007 epoch 4 - iter 0/84 - loss 0.53428930 - samples/sec: 1653.85\n",
      "2019-08-28 15:08:42,530 epoch 4 - iter 8/84 - loss 0.56789857 - samples/sec: 169.86\n",
      "2019-08-28 15:08:44,129 epoch 4 - iter 16/84 - loss 0.56945073 - samples/sec: 162.06\n",
      "2019-08-28 15:08:45,609 epoch 4 - iter 24/84 - loss 0.53454652 - samples/sec: 174.72\n",
      "2019-08-28 15:08:47,112 epoch 4 - iter 32/84 - loss 0.53144894 - samples/sec: 172.03\n",
      "2019-08-28 15:08:48,688 epoch 4 - iter 40/84 - loss 0.51218117 - samples/sec: 163.88\n",
      "2019-08-28 15:08:50,150 epoch 4 - iter 48/84 - loss 0.50572716 - samples/sec: 176.59\n",
      "2019-08-28 15:08:52,065 epoch 4 - iter 56/84 - loss 0.50339870 - samples/sec: 134.67\n",
      "2019-08-28 15:08:54,241 epoch 4 - iter 64/84 - loss 0.51175227 - samples/sec: 118.32\n",
      "2019-08-28 15:08:55,774 epoch 4 - iter 72/84 - loss 0.51665604 - samples/sec: 168.42\n",
      "2019-08-28 15:08:57,747 epoch 4 - iter 80/84 - loss 0.51104485 - samples/sec: 130.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:08:58,508 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:58,509 EPOCH 4 done: loss 0.5191 - lr 0.1000\n",
      "2019-08-28 15:08:58,939 DEV : loss 1.0172265768051147 - score 0.628\n",
      "2019-08-28 15:08:58,983 BAD EPOCHS (no improvement): 2\n",
      "2019-08-28 15:08:58,984 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:08:59,201 epoch 5 - iter 0/84 - loss 0.83982742 - samples/sec: 1188.69\n",
      "2019-08-28 15:09:00,813 epoch 5 - iter 8/84 - loss 0.52840422 - samples/sec: 160.13\n",
      "2019-08-28 15:09:02,395 epoch 5 - iter 16/84 - loss 0.51962238 - samples/sec: 163.59\n",
      "2019-08-28 15:09:03,927 epoch 5 - iter 24/84 - loss 0.49948559 - samples/sec: 168.66\n",
      "2019-08-28 15:09:05,572 epoch 5 - iter 32/84 - loss 0.49489446 - samples/sec: 157.19\n",
      "2019-08-28 15:09:07,090 epoch 5 - iter 40/84 - loss 0.49645779 - samples/sec: 170.19\n",
      "2019-08-28 15:09:08,679 epoch 5 - iter 48/84 - loss 0.48451136 - samples/sec: 163.37\n",
      "2019-08-28 15:09:10,449 epoch 5 - iter 56/84 - loss 0.48269652 - samples/sec: 145.72\n",
      "2019-08-28 15:09:12,074 epoch 5 - iter 64/84 - loss 0.48047931 - samples/sec: 159.17\n",
      "2019-08-28 15:09:13,671 epoch 5 - iter 72/84 - loss 0.48765207 - samples/sec: 161.75\n",
      "2019-08-28 15:09:15,230 epoch 5 - iter 80/84 - loss 0.49090479 - samples/sec: 165.59\n",
      "2019-08-28 15:09:15,807 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:09:15,808 EPOCH 5 done: loss 0.4884 - lr 0.1000\n",
      "2019-08-28 15:09:16,255 DEV : loss 0.5821824073791504 - score 0.6696\n",
      "2019-08-28 15:09:16,300 BAD EPOCHS (no improvement): 3\n",
      "2019-08-28 15:09:16,302 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:09:16,495 epoch 6 - iter 0/84 - loss 0.49394614 - samples/sec: 1331.67\n",
      "2019-08-28 15:09:17,933 epoch 6 - iter 8/84 - loss 0.50425853 - samples/sec: 179.89\n",
      "2019-08-28 15:09:19,465 epoch 6 - iter 16/84 - loss 0.50108236 - samples/sec: 168.72\n",
      "2019-08-28 15:09:21,222 epoch 6 - iter 24/84 - loss 0.47612993 - samples/sec: 147.05\n",
      "2019-08-28 15:09:22,700 epoch 6 - iter 32/84 - loss 0.47703237 - samples/sec: 174.91\n",
      "2019-08-28 15:09:24,136 epoch 6 - iter 40/84 - loss 0.48773967 - samples/sec: 180.11\n",
      "2019-08-28 15:09:25,872 epoch 6 - iter 48/84 - loss 0.48382498 - samples/sec: 149.23\n",
      "2019-08-28 15:09:27,635 epoch 6 - iter 56/84 - loss 0.48181833 - samples/sec: 146.51\n",
      "2019-08-28 15:09:29,279 epoch 6 - iter 64/84 - loss 0.48126443 - samples/sec: 157.65\n",
      "2019-08-28 15:09:30,831 epoch 6 - iter 72/84 - loss 0.47815812 - samples/sec: 166.49\n",
      "2019-08-28 15:09:32,346 epoch 6 - iter 80/84 - loss 0.47882119 - samples/sec: 170.47\n",
      "2019-08-28 15:09:33,051 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:09:33,052 EPOCH 6 done: loss 0.4743 - lr 0.1000\n",
      "2019-08-28 15:09:33,502 DEV : loss 0.4838353097438812 - score 0.8065\n",
      "2019-08-28 15:09:33,546 BAD EPOCHS (no improvement): 0\n",
      "2019-08-28 15:09:36,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:09:36,379 epoch 7 - iter 0/84 - loss 0.38542202 - samples/sec: 891.36\n",
      "2019-08-28 15:09:37,997 epoch 7 - iter 8/84 - loss 0.45133363 - samples/sec: 159.62\n",
      "2019-08-28 15:09:39,739 epoch 7 - iter 16/84 - loss 0.48280224 - samples/sec: 148.78\n",
      "2019-08-28 15:09:41,190 epoch 7 - iter 24/84 - loss 0.46372348 - samples/sec: 178.22\n",
      "2019-08-28 15:09:42,673 epoch 7 - iter 32/84 - loss 0.45494920 - samples/sec: 174.39\n",
      "2019-08-28 15:09:43,913 epoch 7 - iter 40/84 - loss 0.44959703 - samples/sec: 209.02\n",
      "2019-08-28 15:09:45,640 epoch 7 - iter 48/84 - loss 0.47594740 - samples/sec: 149.52\n",
      "2019-08-28 15:09:47,053 epoch 7 - iter 56/84 - loss 0.46914320 - samples/sec: 183.35\n",
      "2019-08-28 15:09:48,804 epoch 7 - iter 64/84 - loss 0.46179736 - samples/sec: 147.35\n",
      "2019-08-28 15:09:50,168 epoch 7 - iter 72/84 - loss 0.45489155 - samples/sec: 189.82\n",
      "2019-08-28 15:09:51,568 epoch 7 - iter 80/84 - loss 0.46445410 - samples/sec: 184.76\n",
      "2019-08-28 15:09:52,295 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:09:52,296 EPOCH 7 done: loss 0.4649 - lr 0.1000\n",
      "2019-08-28 15:09:52,737 DEV : loss 0.6335316896438599 - score 0.6488\n",
      "2019-08-28 15:09:52,782 BAD EPOCHS (no improvement): 1\n",
      "2019-08-28 15:09:52,783 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:09:52,954 epoch 8 - iter 0/84 - loss 0.65160257 - samples/sec: 1500.59\n",
      "2019-08-28 15:09:54,599 epoch 8 - iter 8/84 - loss 0.49123203 - samples/sec: 157.08\n",
      "2019-08-28 15:09:56,242 epoch 8 - iter 16/84 - loss 0.44991003 - samples/sec: 157.79\n",
      "2019-08-28 15:09:57,534 epoch 8 - iter 24/84 - loss 0.42742203 - samples/sec: 200.94\n",
      "2019-08-28 15:09:59,124 epoch 8 - iter 32/84 - loss 0.42950640 - samples/sec: 162.88\n",
      "2019-08-28 15:10:00,504 epoch 8 - iter 40/84 - loss 0.41707762 - samples/sec: 187.36\n",
      "2019-08-28 15:10:02,512 epoch 8 - iter 48/84 - loss 0.42263172 - samples/sec: 128.42\n",
      "2019-08-28 15:10:04,254 epoch 8 - iter 56/84 - loss 0.42554854 - samples/sec: 148.19\n",
      "2019-08-28 15:10:06,045 epoch 8 - iter 64/84 - loss 0.42977233 - samples/sec: 144.14\n",
      "2019-08-28 15:10:07,652 epoch 8 - iter 72/84 - loss 0.43022595 - samples/sec: 160.70\n",
      "2019-08-28 15:10:09,173 epoch 8 - iter 80/84 - loss 0.43306761 - samples/sec: 169.68\n",
      "2019-08-28 15:10:09,737 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:10:09,738 EPOCH 8 done: loss 0.4317 - lr 0.1000\n",
      "2019-08-28 15:10:10,178 DEV : loss 0.44570061564445496 - score 0.7827\n",
      "2019-08-28 15:10:10,223 BAD EPOCHS (no improvement): 2\n",
      "2019-08-28 15:10:10,224 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:10:10,457 epoch 9 - iter 0/84 - loss 0.34434173 - samples/sec: 1105.89\n",
      "2019-08-28 15:10:12,232 epoch 9 - iter 8/84 - loss 0.47087094 - samples/sec: 145.52\n",
      "2019-08-28 15:10:13,861 epoch 9 - iter 16/84 - loss 0.44124234 - samples/sec: 158.43\n",
      "2019-08-28 15:10:15,564 epoch 9 - iter 24/84 - loss 0.43087579 - samples/sec: 151.47\n",
      "2019-08-28 15:10:16,937 epoch 9 - iter 32/84 - loss 0.42080652 - samples/sec: 188.80\n",
      "2019-08-28 15:10:18,488 epoch 9 - iter 40/84 - loss 0.43755689 - samples/sec: 166.80\n",
      "2019-08-28 15:10:20,007 epoch 9 - iter 48/84 - loss 0.42180390 - samples/sec: 170.05\n",
      "2019-08-28 15:10:21,305 epoch 9 - iter 56/84 - loss 0.42322257 - samples/sec: 199.36\n",
      "2019-08-28 15:10:22,984 epoch 9 - iter 64/84 - loss 0.43089810 - samples/sec: 153.82\n",
      "2019-08-28 15:10:24,617 epoch 9 - iter 72/84 - loss 0.42838777 - samples/sec: 158.12\n",
      "2019-08-28 15:10:26,343 epoch 9 - iter 80/84 - loss 0.42855846 - samples/sec: 150.17\n",
      "2019-08-28 15:10:27,010 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:10:27,011 EPOCH 9 done: loss 0.4264 - lr 0.1000\n",
      "2019-08-28 15:10:27,475 DEV : loss 0.41167691349983215 - score 0.8512\n",
      "2019-08-28 15:10:27,522 BAD EPOCHS (no improvement): 0\n",
      "2019-08-28 15:10:30,091 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:10:30,332 epoch 10 - iter 0/84 - loss 0.27137926 - samples/sec: 1073.21\n",
      "2019-08-28 15:10:32,252 epoch 10 - iter 8/84 - loss 0.44268503 - samples/sec: 134.88\n",
      "2019-08-28 15:10:34,302 epoch 10 - iter 16/84 - loss 0.45460984 - samples/sec: 125.69\n",
      "2019-08-28 15:10:35,547 epoch 10 - iter 24/84 - loss 0.43123032 - samples/sec: 207.91\n",
      "2019-08-28 15:10:37,254 epoch 10 - iter 32/84 - loss 0.43422354 - samples/sec: 151.30\n",
      "2019-08-28 15:10:38,914 epoch 10 - iter 40/84 - loss 0.43977431 - samples/sec: 155.61\n",
      "2019-08-28 15:10:40,557 epoch 10 - iter 48/84 - loss 0.42917464 - samples/sec: 157.30\n",
      "2019-08-28 15:10:42,188 epoch 10 - iter 56/84 - loss 0.42838104 - samples/sec: 158.21\n",
      "2019-08-28 15:10:43,544 epoch 10 - iter 64/84 - loss 0.42514155 - samples/sec: 190.93\n",
      "2019-08-28 15:10:44,838 epoch 10 - iter 72/84 - loss 0.41913944 - samples/sec: 200.49\n",
      "2019-08-28 15:10:46,331 epoch 10 - iter 80/84 - loss 0.41604725 - samples/sec: 173.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-28 15:10:47,045 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:10:47,047 EPOCH 10 done: loss 0.4109 - lr 0.1000\n",
      "2019-08-28 15:10:47,485 DEV : loss 0.48136597871780396 - score 0.7202\n",
      "2019-08-28 15:10:47,530 BAD EPOCHS (no improvement): 1\n",
      "2019-08-28 15:10:50,015 ----------------------------------------------------------------------------------------------------\n",
      "2019-08-28 15:10:50,017 Testing using best model ...\n",
      "2019-08-28 15:10:50,019 loading file /home/stirunag/Work/Unsupervised-Protein-Genes-Diseases-Extraction/Datasets/EU-ADR+GAD/best-model.pt\n",
      "2019-08-28 15:11:20,623 0.7619\t0.7619\t0.7619\n",
      "2019-08-28 15:11:20,623 \n",
      "MICRO_AVG: acc 0.6154 - f1-score 0.7619\n",
      "MACRO_AVG: acc 0.5446 - f1-score 0.68745\n",
      "NA         tp: 46 - fp: 19 - fn: 61 - tn: 210 - precision: 0.7077 - recall: 0.4299 - accuracy: 0.3651 - f1-score: 0.5349\n",
      "PA         tp: 210 - fp: 61 - fn: 19 - tn: 46 - precision: 0.7749 - recall: 0.9170 - accuracy: 0.7241 - f1-score: 0.8400\n",
      "2019-08-28 15:11:20,624 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.7619,\n",
       " 'dev_score_history': [0.628,\n",
       "  0.6815,\n",
       "  0.5833,\n",
       "  0.628,\n",
       "  0.6696,\n",
       "  0.8065,\n",
       "  0.6488,\n",
       "  0.7827,\n",
       "  0.8512,\n",
       "  0.7202],\n",
       " 'train_loss_history': [0.5948715245439893,\n",
       "  0.5668406681645484,\n",
       "  0.539126393163488,\n",
       "  0.5190899801396188,\n",
       "  0.48838955022039865,\n",
       "  0.4743121841124126,\n",
       "  0.4649090130059492,\n",
       "  0.4317438288458756,\n",
       "  0.4263987237853663,\n",
       "  0.41086282385956674],\n",
       " 'dev_loss_history': [tensor(0.6471),\n",
       "  tensor(0.6154),\n",
       "  tensor(0.6566),\n",
       "  tensor(1.0172),\n",
       "  tensor(0.5822),\n",
       "  tensor(0.4838),\n",
       "  tensor(0.6335),\n",
       "  tensor(0.4457),\n",
       "  tensor(0.4117),\n",
       "  tensor(0.4814)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. start the training\n",
    "# trainer.train(data_loc, max_epochs=10)\n",
    "trainer.train(data_loc,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load(data_loc+'best-model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('The FCRL3 polymorphisms associated with rheumatoid arthritis in a Japanese population are not associated per se with rheumatoid arthritis in a Spanish population.')\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "predicted_label = []\n",
    "for index, rows in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if rows['label'] == 'NA':\n",
    "       ground_truth.append('Negative')\n",
    "    else:\n",
    "       ground_truth.append('Positive')\n",
    "    sentence = Sentence(rows['text'])\n",
    "    classifier.predict(sentence)\n",
    "    predicted_label.append(sentence.labels[0].value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "f1_score(ground_truth, predicted_label, average='micro') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
